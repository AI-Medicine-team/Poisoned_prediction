{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1024e15e",
   "metadata": {},
   "source": [
    "## 1. data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f2bbd",
   "metadata": {},
   "source": [
    "- Replace new data file (categorical variables have been mapped to values and changed to descriptive): updated albumin wash data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f573e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ======================\n",
    "# 1. Read Data\n",
    "# ======================\n",
    "df1 = pd.read_csv('/home/mailiyi/Poisoning_Prediction/all_poisoning_data_wide_clean_albumin_20251106.csv')\n",
    "\n",
    "# ======================\n",
    "# 2. Define Features\n",
    "# ======================\n",
    "x_features_continuous = ['Age',\n",
    " 'Length of Stay',\n",
    " 'Weight',\n",
    " 'Systolic Blood Pressure',\n",
    " 'Diastolic Blood Pressure',\n",
    " 'Respiratory Rate', \n",
    " 'Heart Rate',\n",
    " 'White Blood Cell Count',\n",
    " 'Red Blood Cell Count',\n",
    " 'Hemoglobin Concentration',\n",
    " 'Mean Corpuscular Volume',\n",
    " 'Mean Corpuscular Hemoglobin',\n",
    " 'Mean Corpuscular Hemoglobin Concentration',\n",
    " 'Platelet Count',\n",
    " 'Mean Platelet Volume',\n",
    " 'Alanine Aminotransferase (ALT)',\n",
    " 'Total Bilirubin',\n",
    " 'Direct Bilirubin',\n",
    " 'Lactate Dehydrogenase (LDH)',\n",
    " 'Urea',\n",
    " 'Serum Creatinine',\n",
    " 'Uric Acid',\n",
    " 'Creatine Kinase (CK)',\n",
    " 'Creatine Kinase-MB Isoenzyme',\n",
    " 'Troponin I',\n",
    " 'High-Sensitivity C-Reactive Protein (hs-CRP)',\n",
    " 'Homocysteine',\n",
    " 'Potassium',\n",
    " 'Sodium',\n",
    " 'Chloride',\n",
    " 'Carbon Dioxide',\n",
    " 'Prothrombin Time',\n",
    " 'D-Dimer',\n",
    " 'Lactate',\n",
    " 'Blood Cholinesterase Test Results',\n",
    " 'Albumin (First Measurement)',\n",
    " 'Albumin (Last Measurement)',\n",
    " 'Number of Hemoperfusion Sessions',\n",
    " 'Number of Blood Purification Sessions',\n",
    " 'Hyperbaric Oxygen Therapy Duration and Frequency',\n",
    " 'Atropine Dosage',\n",
    " 'Long-acting Nitroglycerin Dosage',\n",
    " 'Pralidoxime Dosage',\n",
    " ] \n",
    "x_features_categorical = ['Gender','Education Level','Type of Poisoning','Hypertension','Hyperlipidemia','Diabetes Mellitus','Cerebrovascular Disease','Heart Disease','Allergy History','Cancer','Poisoning','degree of poisoning','Smoking Status','Alcohol Consumption Status','Shortness of Breath','Chest Pain','Cough','Pre-syncope','Altered Consciousness or Syncope','Sore Throat','Fever','Fatigue','Lower Limb Edema','Palpitations','Vomiting','Nausea','Weakness','Headache','Residence'] # ÂàÜÁ±ªÂèòÈáèÂàóË°®\n",
    "\n",
    "\n",
    "# y_column = 'Outcome_other' \n",
    "y_column = 'Outcome' \n",
    "\n",
    "# ======================\n",
    "# 3. Shuffle Data\n",
    "# ======================\n",
    "df2 = df1.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# missing_summary = df2[x_features_continuous].isna().sum()\n",
    "# print(\"ÂéüÂßãÊï∞ÊçÆÂê´Áº∫Â§±ÂÄºÁöÑËøûÁª≠ÁâπÂæÅÔºö\")\n",
    "# print(missing_summary[missing_summary > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a36ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcome_other ÂàÜÂ∏ÉÔºàÊòØÂê¶Ê≠ª‰∫°ÔºâÔºö\n",
      "Outcome_other\n",
      "0    889\n",
      "1     82\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome ÂàÜÂ∏ÉÔºàÊòØÂê¶Êú™Ê≤ªÊÑàÔºâÔºö\n",
      "Outcome\n",
      "0    731\n",
      "1    240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Statistics Distribution of Outcome_other and Outcome\n",
    "\n",
    "print(df2[\"Outcome_other\"].value_counts(dropna=False))\n",
    "\n",
    "print(df2[\"Outcome\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85870d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂèòÈáèÁº∫Â§±ÊØî‰æãÔºà%Ôºâ:\n",
      "Lactate             96.81\n",
      "Carbon Dioxide      94.95\n",
      "Sodium              94.75\n",
      "Potassium           94.75\n",
      "Chloride            94.75\n",
      "                    ...  \n",
      "Lower Limb Edema     0.00\n",
      "Vomiting             0.00\n",
      "Nausea               0.00\n",
      "Weakness             0.00\n",
      "Headache             0.00\n",
      "Length: 72, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Calculate the missing ratio of continuous variables\n",
    "\n",
    "missing_ratios = df2[x_features_continuous+x_features_categorical].isnull().mean()\n",
    "\n",
    "missing_summary = (missing_ratios * 100).round(2).sort_values(ascending=False)\n",
    "\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e75e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Áº∫Â§±Áéá > 90% ÁöÑËøûÁª≠ÂèòÈáè:\n",
      "Potassium: 94.75%\n",
      "Sodium: 94.75%\n",
      "Chloride: 94.75%\n",
      "Carbon Dioxide: 94.95%\n",
      "Prothrombin Time: 94.64%\n",
      "D-Dimer: 94.64%\n",
      "Lactate: 96.81%\n",
      "Hyperbaric Oxygen Therapy Duration and Frequency: 92.38%\n",
      "Atropine Dosage: 93.92%\n",
      "Long-acting Nitroglycerin Dosage: 92.48%\n",
      "Pralidoxime Dosage: 92.17%\n"
     ]
    }
   ],
   "source": [
    "# Select feature names with missing rate > 90%\n",
    "high_missing_features = missing_ratios[missing_ratios > 0.90].index.tolist()\n",
    "\n",
    "for feat in high_missing_features:\n",
    "    print(f\"{feat}: {missing_ratios[feat]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66acbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "11\n",
      "32\n",
      "(971, 95)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_features_continuous))\n",
    "print(len(high_missing_features))\n",
    "x_features_continuous = [feat for feat in x_features_continuous if feat not in high_missing_features]\n",
    "print(len(x_features_continuous))\n",
    "\n",
    "df2 = df2.drop(columns=high_missing_features)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ba8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‰ªçÂê´Áº∫Â§±ÂÄºÁöÑËøûÁª≠ÁâπÂæÅÔºö\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Ê†áÂáÜÂåñÂêéÈÉ®ÂàÜËøûÁª≠ÁâπÂæÅÂùáÂÄº‰∏éÊ†áÂáÜÂ∑ÆÔºàÂ∫îÊé•Ëøë0‰∏é1Ôºâ:\n",
      "                          mean    std\n",
      "Age                        0.0  1.001\n",
      "Length of Stay            -0.0  1.001\n",
      "Weight                     0.0  1.001\n",
      "Systolic Blood Pressure   -0.0  1.001\n",
      "Diastolic Blood Pressure   0.0  1.001\n",
      "Respiratory Rate           0.0  1.001\n",
      "Heart Rate                -0.0  1.001\n",
      "White Blood Cell Count     0.0  1.001\n",
      "Red Blood Cell Count      -0.0  1.001\n",
      "Hemoglobin Concentration   0.0  1.001\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# 4. Fill missing values with the median of all samples\n",
    "# ======================\n",
    "median_values = df2[x_features_continuous].median()\n",
    "df2[x_features_continuous] = df2[x_features_continuous].fillna(median_values)\n",
    "\n",
    "missing_summary = df2[x_features_continuous].isna().sum()\n",
    "print(missing_summary[missing_summary > 0])\n",
    "\n",
    "# ======================\n",
    "# 5. Normalize (standardize) each column of continuous variables\n",
    "# ======================\n",
    "scaler = StandardScaler()\n",
    "df2[x_features_continuous] = scaler.fit_transform(df2[x_features_continuous])\n",
    "\n",
    "check_means = df2[x_features_continuous].mean().round(3)\n",
    "check_stds = df2[x_features_continuous].std().round(3)\n",
    "print(pd.DataFrame({'mean': check_means.head(10), 'std': check_stds.head(10)}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf8714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÂéüÂßãÁâπÂæÅÊï∞: 61\n",
      "One-Hot ÂêéÁâπÂæÅÊï∞: 107\n",
      "Ê†∑Êú¨Èáè: 971\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## First, fill missing values in categorical variables with \"Unknown\"\n",
    "for col in x_features_categorical:\n",
    "    if col in df2.columns:\n",
    "        df2[col] = df2[col].fillna('Unknown')\n",
    "\n",
    "# ======================\n",
    "# 6. One-Hot Encoding\n",
    "# ======================\n",
    "x_columns = x_features_categorical + x_features_continuous\n",
    "datax = df2[x_columns]\n",
    "datay = df2[y_column]\n",
    "\n",
    "datax_encoded = pd.get_dummies(datax, columns=x_features_categorical, drop_first=False)\n",
    "\n",
    "datax_encoded = datax_encoded.astype(float)\n",
    "print(f\"\\nOriginal number of features: {len(x_columns)}\")\n",
    "print(f\"Number of features after One-Hot Encoding: {datax_encoded.shape[1]}\")\n",
    "print(f\"Number of samples: {datax_encoded.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942b917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor ÂΩ¢Áä∂ÔºöX=torch.Size([971, 107]), y=torch.Size([971, 1])\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# 7. conversion tensor\n",
    "# ======================\n",
    "X_tensor = torch.tensor(datax_encoded.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(datay.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(f\"\\nTensor formÔºöX={X_tensor.shape}, y={y_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d7068",
   "metadata": {},
   "source": [
    "## 2.  5-fold cross validation: Divide 1/8 of the training set into validation sets (i.e. 70% training set, 10% validation set, 20% test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aed883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed fixed as 42\n",
      "Using device: cuda\n",
      "\n",
      "===== Fold 1 =====\n",
      "Random seed fixed as 43\n",
      "Fold 1: pos_weight = 2.99\n",
      "Epoch 001 | Loss: 1.0434 | Val AUROC: 0.4937 | LR=0.000500\n",
      "Epoch 002 | Loss: 1.0229 | Val AUROC: 0.6147 | LR=0.000500\n",
      "Epoch 003 | Loss: 0.9959 | Val AUROC: 0.6461 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.9800 | Val AUROC: 0.6507 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.9292 | Val AUROC: 0.6627 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.8940 | Val AUROC: 0.6644 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.8557 | Val AUROC: 0.6632 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.8201 | Val AUROC: 0.6724 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.7630 | Val AUROC: 0.6689 | LR=0.000500\n",
      "Epoch 010 | Loss: 0.7251 | Val AUROC: 0.6775 | LR=0.000500\n",
      "Epoch 011 | Loss: 0.7290 | Val AUROC: 0.6855 | LR=0.000500\n",
      "Epoch 012 | Loss: 0.6816 | Val AUROC: 0.6918 | LR=0.000500\n",
      "Epoch 013 | Loss: 0.6745 | Val AUROC: 0.6861 | LR=0.000500\n",
      "Epoch 014 | Loss: 0.6275 | Val AUROC: 0.6941 | LR=0.000500\n",
      "Epoch 015 | Loss: 0.6425 | Val AUROC: 0.7015 | LR=0.000500\n",
      "Epoch 016 | Loss: 0.5990 | Val AUROC: 0.7078 | LR=0.000500\n",
      "Epoch 017 | Loss: 0.6002 | Val AUROC: 0.7095 | LR=0.000500\n",
      "Epoch 018 | Loss: 0.5642 | Val AUROC: 0.7112 | LR=0.000500\n",
      "Epoch 019 | Loss: 0.5830 | Val AUROC: 0.7112 | LR=0.000500\n",
      "Epoch 020 | Loss: 0.5374 | Val AUROC: 0.7015 | LR=0.000500\n",
      "Epoch 021 | Loss: 0.5520 | Val AUROC: 0.7015 | LR=0.000500\n",
      "Epoch 022 | Loss: 0.5107 | Val AUROC: 0.7100 | LR=0.000250\n",
      "Epoch 023 | Loss: 0.4905 | Val AUROC: 0.7146 | LR=0.000250\n",
      "Epoch 024 | Loss: 0.4706 | Val AUROC: 0.7123 | LR=0.000250\n",
      "Epoch 025 | Loss: 0.4740 | Val AUROC: 0.7083 | LR=0.000250\n",
      "Epoch 026 | Loss: 0.5045 | Val AUROC: 0.7095 | LR=0.000250\n",
      "Epoch 027 | Loss: 0.5439 | Val AUROC: 0.7123 | LR=0.000125\n",
      "Epoch 028 | Loss: 0.5493 | Val AUROC: 0.7118 | LR=0.000125\n",
      "Epoch 029 | Loss: 0.4738 | Val AUROC: 0.7146 | LR=0.000125\n",
      "Epoch 030 | Loss: 0.4792 | Val AUROC: 0.7118 | LR=0.000125\n",
      "Epoch 031 | Loss: 0.4827 | Val AUROC: 0.7049 | LR=0.000063\n",
      "Epoch 032 | Loss: 0.4734 | Val AUROC: 0.7135 | LR=0.000063\n",
      "Epoch 033 | Loss: 0.4404 | Val AUROC: 0.7135 | LR=0.000063\n",
      "Epoch 034 | Loss: 0.4406 | Val AUROC: 0.7123 | LR=0.000063\n",
      "Epoch 035 | Loss: 0.5276 | Val AUROC: 0.7100 | LR=0.000031\n",
      "Early stopping at epoch 35 (best Val AUROC=0.7146)\n",
      "[Fold 1] Test AUROC: 0.7657, AUPRC: 0.6070\n",
      "\n",
      "===== Fold 2 =====\n",
      "Random seed fixed as 44\n",
      "Fold 2: pos_weight = 2.99\n",
      "Epoch 001 | Loss: 1.0354 | Val AUROC: 0.6455 | LR=0.000500\n",
      "Epoch 002 | Loss: 1.0061 | Val AUROC: 0.7693 | LR=0.000500\n",
      "Epoch 003 | Loss: 1.0089 | Val AUROC: 0.8203 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.9598 | Val AUROC: 0.8351 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.9519 | Val AUROC: 0.8384 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.9231 | Val AUROC: 0.8312 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.8981 | Val AUROC: 0.8241 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.8376 | Val AUROC: 0.8334 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.8353 | Val AUROC: 0.8241 | LR=0.000250\n",
      "Epoch 010 | Loss: 0.8002 | Val AUROC: 0.8285 | LR=0.000250\n",
      "Epoch 011 | Loss: 0.8009 | Val AUROC: 0.8290 | LR=0.000250\n",
      "Epoch 012 | Loss: 0.7873 | Val AUROC: 0.8400 | LR=0.000250\n",
      "Epoch 013 | Loss: 0.8182 | Val AUROC: 0.8411 | LR=0.000250\n",
      "Epoch 014 | Loss: 0.7641 | Val AUROC: 0.8400 | LR=0.000250\n",
      "Epoch 015 | Loss: 0.7579 | Val AUROC: 0.8427 | LR=0.000250\n",
      "Epoch 016 | Loss: 0.7650 | Val AUROC: 0.8400 | LR=0.000250\n",
      "Epoch 017 | Loss: 0.7359 | Val AUROC: 0.8312 | LR=0.000250\n",
      "Epoch 018 | Loss: 0.7033 | Val AUROC: 0.8395 | LR=0.000250\n",
      "Epoch 019 | Loss: 0.6753 | Val AUROC: 0.8345 | LR=0.000125\n",
      "Epoch 020 | Loss: 0.6965 | Val AUROC: 0.8307 | LR=0.000125\n",
      "Epoch 021 | Loss: 0.7119 | Val AUROC: 0.8356 | LR=0.000125\n",
      "Epoch 022 | Loss: 0.6741 | Val AUROC: 0.8318 | LR=0.000125\n",
      "Epoch 023 | Loss: 0.6745 | Val AUROC: 0.8274 | LR=0.000063\n",
      "Epoch 024 | Loss: 0.6552 | Val AUROC: 0.8285 | LR=0.000063\n",
      "Epoch 025 | Loss: 0.6650 | Val AUROC: 0.8279 | LR=0.000063\n",
      "Epoch 026 | Loss: 0.6690 | Val AUROC: 0.8334 | LR=0.000063\n",
      "Epoch 027 | Loss: 0.6582 | Val AUROC: 0.8329 | LR=0.000031\n",
      "Early stopping at epoch 27 (best Val AUROC=0.8427)\n",
      "[Fold 2] Test AUROC: 0.8283, AUPRC: 0.7375\n",
      "\n",
      "===== Fold 3 =====\n",
      "Random seed fixed as 45\n",
      "Fold 3: pos_weight = 3.12\n",
      "Epoch 001 | Loss: 1.0532 | Val AUROC: 0.5056 | LR=0.000500\n",
      "Epoch 002 | Loss: 1.0359 | Val AUROC: 0.6436 | LR=0.000500\n",
      "Epoch 003 | Loss: 0.9997 | Val AUROC: 0.6948 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.9910 | Val AUROC: 0.7055 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.9479 | Val AUROC: 0.7111 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.9244 | Val AUROC: 0.7128 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.8756 | Val AUROC: 0.7264 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.8405 | Val AUROC: 0.7342 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.8137 | Val AUROC: 0.7382 | LR=0.000500\n",
      "Epoch 010 | Loss: 0.7912 | Val AUROC: 0.7331 | LR=0.000500\n",
      "Epoch 011 | Loss: 0.7567 | Val AUROC: 0.7387 | LR=0.000500\n",
      "Epoch 012 | Loss: 0.7224 | Val AUROC: 0.7477 | LR=0.000500\n",
      "Epoch 013 | Loss: 0.6989 | Val AUROC: 0.7444 | LR=0.000500\n",
      "Epoch 014 | Loss: 0.6706 | Val AUROC: 0.7432 | LR=0.000500\n",
      "Epoch 015 | Loss: 0.6942 | Val AUROC: 0.7477 | LR=0.000500\n",
      "Epoch 016 | Loss: 0.6947 | Val AUROC: 0.7568 | LR=0.000500\n",
      "Epoch 017 | Loss: 0.6394 | Val AUROC: 0.7477 | LR=0.000500\n",
      "Epoch 018 | Loss: 0.5796 | Val AUROC: 0.7461 | LR=0.000500\n",
      "Epoch 019 | Loss: 0.5809 | Val AUROC: 0.7410 | LR=0.000500\n",
      "Epoch 020 | Loss: 0.5370 | Val AUROC: 0.7421 | LR=0.000250\n",
      "Epoch 021 | Loss: 0.6194 | Val AUROC: 0.7354 | LR=0.000250\n",
      "Epoch 022 | Loss: 0.5250 | Val AUROC: 0.7348 | LR=0.000250\n",
      "Epoch 023 | Loss: 0.5360 | Val AUROC: 0.7387 | LR=0.000250\n",
      "Epoch 024 | Loss: 0.5393 | Val AUROC: 0.7337 | LR=0.000125\n",
      "Epoch 025 | Loss: 0.5568 | Val AUROC: 0.7331 | LR=0.000125\n",
      "Epoch 026 | Loss: 0.5195 | Val AUROC: 0.7303 | LR=0.000125\n",
      "Epoch 027 | Loss: 0.5475 | Val AUROC: 0.7275 | LR=0.000125\n",
      "Epoch 028 | Loss: 0.4917 | Val AUROC: 0.7337 | LR=0.000063\n",
      "Early stopping at epoch 28 (best Val AUROC=0.7568)\n",
      "[Fold 3] Test AUROC: 0.7854, AUPRC: 0.6512\n",
      "\n",
      "===== Fold 4 =====\n",
      "Random seed fixed as 46\n",
      "Fold 4: pos_weight = 3.09\n",
      "Epoch 001 | Loss: 1.0532 | Val AUROC: 0.6025 | LR=0.000500\n",
      "Epoch 002 | Loss: 1.0331 | Val AUROC: 0.6554 | LR=0.000500\n",
      "Epoch 003 | Loss: 0.9788 | Val AUROC: 0.6774 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.9526 | Val AUROC: 0.6959 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.9398 | Val AUROC: 0.7196 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.8877 | Val AUROC: 0.7399 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.8474 | Val AUROC: 0.7517 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.8632 | Val AUROC: 0.7579 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.8000 | Val AUROC: 0.7652 | LR=0.000500\n",
      "Epoch 010 | Loss: 0.7796 | Val AUROC: 0.7652 | LR=0.000500\n",
      "Epoch 011 | Loss: 0.7416 | Val AUROC: 0.7815 | LR=0.000500\n",
      "Epoch 012 | Loss: 0.7266 | Val AUROC: 0.7843 | LR=0.000500\n",
      "Epoch 013 | Loss: 0.7019 | Val AUROC: 0.7939 | LR=0.000500\n",
      "Epoch 014 | Loss: 0.6728 | Val AUROC: 0.7866 | LR=0.000500\n",
      "Epoch 015 | Loss: 0.6558 | Val AUROC: 0.7900 | LR=0.000500\n",
      "Epoch 016 | Loss: 0.6592 | Val AUROC: 0.7939 | LR=0.000500\n",
      "Epoch 017 | Loss: 0.7042 | Val AUROC: 0.7860 | LR=0.000250\n",
      "Epoch 018 | Loss: 0.6223 | Val AUROC: 0.7905 | LR=0.000250\n",
      "Epoch 019 | Loss: 0.5914 | Val AUROC: 0.7934 | LR=0.000250\n",
      "Epoch 020 | Loss: 0.6141 | Val AUROC: 0.7956 | LR=0.000250\n",
      "Epoch 021 | Loss: 0.5992 | Val AUROC: 0.7934 | LR=0.000250\n",
      "Epoch 022 | Loss: 0.5512 | Val AUROC: 0.7979 | LR=0.000250\n",
      "Epoch 023 | Loss: 0.5591 | Val AUROC: 0.7956 | LR=0.000250\n",
      "Epoch 024 | Loss: 0.5690 | Val AUROC: 0.7995 | LR=0.000250\n",
      "Epoch 025 | Loss: 0.5499 | Val AUROC: 0.8007 | LR=0.000250\n",
      "Epoch 026 | Loss: 0.5605 | Val AUROC: 0.7990 | LR=0.000250\n",
      "Epoch 027 | Loss: 0.6021 | Val AUROC: 0.7990 | LR=0.000250\n",
      "Epoch 028 | Loss: 0.5806 | Val AUROC: 0.7911 | LR=0.000250\n",
      "Epoch 029 | Loss: 0.5827 | Val AUROC: 0.7995 | LR=0.000125\n",
      "Epoch 030 | Loss: 0.5012 | Val AUROC: 0.8069 | LR=0.000125\n",
      "Epoch 031 | Loss: 0.5293 | Val AUROC: 0.8007 | LR=0.000125\n",
      "Epoch 032 | Loss: 0.5163 | Val AUROC: 0.7984 | LR=0.000125\n",
      "Epoch 033 | Loss: 0.5213 | Val AUROC: 0.7995 | LR=0.000125\n",
      "Epoch 034 | Loss: 0.4685 | Val AUROC: 0.8046 | LR=0.000063\n",
      "Epoch 035 | Loss: 0.5134 | Val AUROC: 0.8052 | LR=0.000063\n",
      "Epoch 036 | Loss: 0.4968 | Val AUROC: 0.8024 | LR=0.000063\n",
      "Epoch 037 | Loss: 0.4883 | Val AUROC: 0.8046 | LR=0.000063\n",
      "Epoch 038 | Loss: 0.4714 | Val AUROC: 0.8012 | LR=0.000031\n",
      "Epoch 039 | Loss: 0.4995 | Val AUROC: 0.8001 | LR=0.000031\n",
      "Epoch 040 | Loss: 0.4867 | Val AUROC: 0.8024 | LR=0.000031\n",
      "Epoch 041 | Loss: 0.4938 | Val AUROC: 0.8046 | LR=0.000031\n",
      "Epoch 042 | Loss: 0.4686 | Val AUROC: 0.8041 | LR=0.000016\n",
      "Early stopping at epoch 42 (best Val AUROC=0.8069)\n",
      "[Fold 4] Test AUROC: 0.7640, AUPRC: 0.6571\n",
      "\n",
      "===== Fold 5 =====\n",
      "Random seed fixed as 47\n",
      "Fold 5: pos_weight = 3.04\n",
      "Epoch 001 | Loss: 1.0442 | Val AUROC: 0.6273 | LR=0.000500\n",
      "Epoch 002 | Loss: 1.0287 | Val AUROC: 0.7027 | LR=0.000500\n",
      "Epoch 003 | Loss: 0.9991 | Val AUROC: 0.7416 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.9795 | Val AUROC: 0.7354 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.9408 | Val AUROC: 0.7449 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.9272 | Val AUROC: 0.7489 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.8839 | Val AUROC: 0.7675 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.8493 | Val AUROC: 0.7793 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.8180 | Val AUROC: 0.7697 | LR=0.000500\n",
      "Epoch 010 | Loss: 0.8215 | Val AUROC: 0.7905 | LR=0.000500\n",
      "Epoch 011 | Loss: 0.7812 | Val AUROC: 0.8041 | LR=0.000500\n",
      "Epoch 012 | Loss: 0.7605 | Val AUROC: 0.8041 | LR=0.000500\n",
      "Epoch 013 | Loss: 0.7553 | Val AUROC: 0.8102 | LR=0.000500\n",
      "Epoch 014 | Loss: 0.7415 | Val AUROC: 0.8052 | LR=0.000500\n",
      "Epoch 015 | Loss: 0.7345 | Val AUROC: 0.7967 | LR=0.000500\n",
      "Epoch 016 | Loss: 0.7206 | Val AUROC: 0.8080 | LR=0.000500\n",
      "Epoch 017 | Loss: 0.6687 | Val AUROC: 0.7934 | LR=0.000250\n",
      "Epoch 018 | Loss: 0.6437 | Val AUROC: 0.7810 | LR=0.000250\n",
      "Epoch 019 | Loss: 0.6560 | Val AUROC: 0.7883 | LR=0.000250\n",
      "Epoch 020 | Loss: 0.6336 | Val AUROC: 0.7821 | LR=0.000250\n",
      "Epoch 021 | Loss: 0.6611 | Val AUROC: 0.7877 | LR=0.000125\n",
      "Epoch 022 | Loss: 0.6241 | Val AUROC: 0.7776 | LR=0.000125\n",
      "Epoch 023 | Loss: 0.6204 | Val AUROC: 0.7770 | LR=0.000125\n",
      "Epoch 024 | Loss: 0.6401 | Val AUROC: 0.7815 | LR=0.000125\n",
      "Epoch 025 | Loss: 0.6036 | Val AUROC: 0.7787 | LR=0.000063\n",
      "Early stopping at epoch 25 (best Val AUROC=0.8102)\n",
      "[Fold 5] Test AUROC: 0.7818, AUPRC: 0.6556\n",
      "\n",
      "===== ‰∫îÊäò‰∫§ÂèâÈ™åËØÅÁªìÊûú (Bootstrap) =====\n",
      "AUROC: Mean = 0.7724, 95% CI = (0.7366, 0.8087)\n",
      "AUPRC: Mean = 0.6402, 95% CI = (0.5808, 0.6993)\n",
      "\n",
      "‚úÖ ÊâÄÊúâÊäòÁöÑÈ¢ÑÊµãÁªìÊûúÂ∑≤ÂêàÂπ∂‰øùÂ≠ò‰∏∫Ôºö/home/mailiyi/Poisoning_Prediction/DNN/predict_non-recovery_valid_test_5cv/all_folds_results.csv\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn import metrics\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Random seed fixed as {seed}\")\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "save_path = \"/home/mailiyi/Poisoning_Prediction/DNN/predict_non-recovery_valid_test_5cv/\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "X_tensor = torch.tensor(datax_encoded.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(datay.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "auroc_list, auprc_list = [], []\n",
    "all_results = []\n",
    "\n",
    "for train_val_index, test_index in kf.split(X_tensor):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "    set_seed(42 + fold)\n",
    "\n",
    "    X_train_val, X_test = X_tensor[train_val_index], X_tensor[test_index]\n",
    "    y_train_val, y_test = y_tensor[train_val_index], y_tensor[test_index]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=1/8, random_state=42 + fold, stratify=y_train_val\n",
    "    )\n",
    "\n",
    "    num_pos = (y_train == 1).sum().item()\n",
    "    num_neg = (y_train == 0).sum().item()\n",
    "    pos_weight = torch.tensor(num_neg / num_pos, dtype=torch.float32).to(device)\n",
    "    print(f\"Fold {fold}: pos_weight = {pos_weight:.2f}\")\n",
    "\n",
    "    # DataLoader\n",
    "    def worker_init_fn(worker_id):\n",
    "        np.random.seed(42 + worker_id)\n",
    "        random.seed(42 + worker_id)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(X_train, y_train),\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        worker_init_fn=worker_init_fn\n",
    "    )\n",
    "\n",
    "    model = DNN(input_dim=X_tensor.shape[1]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    patience = 12\n",
    "    best_auroc = 0\n",
    "    wait = 0\n",
    "    best_model_path = os.path.join(save_path, f\"fold{fold}_best_model.pt\")\n",
    "\n",
    "    # =============== 6. train ===============\n",
    "    max_epochs = 100\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(X_val.to(device)).squeeze()\n",
    "            y_pred_prob = torch.sigmoid(logits).cpu().numpy()\n",
    "            y_true = y_val.squeeze().cpu().numpy()\n",
    "            auroc_val = roc_auc_score(y_true, y_pred_prob)\n",
    "        scheduler.step(auroc_val)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03d} | Loss: {avg_loss:.4f} | Val AUROC: {auroc_val:.4f} | LR={current_lr:.6f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if auroc_val > best_auroc:\n",
    "            best_auroc = auroc_val\n",
    "            wait = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1} (best Val AUROC={best_auroc:.4f})\")\n",
    "                break\n",
    "\n",
    "    # =============== 7. Test Set Evaluation ===============\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_test.to(device)).squeeze()\n",
    "        y_pred_prob = torch.sigmoid(logits).cpu().numpy()\n",
    "        y_true = y_test.squeeze().cpu().numpy()\n",
    "        auroc = roc_auc_score(y_true, y_pred_prob)\n",
    "        auprc = average_precision_score(y_true, y_pred_prob)\n",
    "        auroc_list.append(auroc)\n",
    "        auprc_list.append(auprc)\n",
    "\n",
    "        print(f\"[Fold {fold}] Test AUROC: {auroc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "\n",
    "        result_df = pd.DataFrame({\"y_test\": y_true, \"y_pred\": y_pred_prob})\n",
    "        result_df.to_csv(os.path.join(save_path, f\"fold{fold}_results.csv\"), index=False)\n",
    "        all_results.append(result_df)\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# =============== 8. Bootstrap Calculation of overall indicators ===============\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "all_results_df = pd.concat(all_results, axis=0).reset_index(drop=True)\n",
    "y_all_true = all_results_df[\"y_test\"].values\n",
    "y_all_pred = all_results_df[\"y_pred\"].values\n",
    "\n",
    "mean_auroc, auc_lower, auc_upper = bootstrap_metric_ci(y_all_true, y_all_pred, metrics.roc_auc_score)\n",
    "mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(y_all_true, y_all_pred, metrics.average_precision_score)\n",
    "\n",
    "print(f\"AUROC: Mean = {mean_auroc:.4f}, 95% CI = ({auc_lower:.4f}, {auc_upper:.4f})\")\n",
    "print(f\"AUPRC: Mean = {mean_auprc:.4f}, 95% CI = ({auprc_lower:.4f}, {auprc_upper:.4f})\")\n",
    "\n",
    "all_results_path = os.path.join(save_path, \"all_folds_results.csv\")\n",
    "all_results_df.to_csv(all_results_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3522950",
   "metadata": {},
   "source": [
    "## 2.2 Try random seeds, jump out of the loop when auc>0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58959765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "==============================\n",
      "üîÅ ÊµãËØïÈöèÊú∫ÁßçÂ≠ê: 5765\n",
      "==============================\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 001 | Loss: 1.0248 | Val AUROC: 0.6333\n",
      "Epoch 002 | Loss: 1.0186 | Val AUROC: 0.6800\n",
      "Epoch 003 | Loss: 0.9717 | Val AUROC: 0.7150\n",
      "Epoch 004 | Loss: 0.9386 | Val AUROC: 0.7128\n",
      "Epoch 005 | Loss: 0.8910 | Val AUROC: 0.7172\n",
      "Epoch 006 | Loss: 0.8796 | Val AUROC: 0.7089\n",
      "Epoch 007 | Loss: 0.8215 | Val AUROC: 0.7256\n",
      "Epoch 008 | Loss: 0.8015 | Val AUROC: 0.7372\n",
      "Epoch 009 | Loss: 0.8204 | Val AUROC: 0.7361\n",
      "Epoch 010 | Loss: 0.7495 | Val AUROC: 0.7389\n",
      "Epoch 011 | Loss: 0.7278 | Val AUROC: 0.7483\n",
      "Epoch 012 | Loss: 0.7157 | Val AUROC: 0.7572\n",
      "Epoch 013 | Loss: 0.7092 | Val AUROC: 0.7711\n",
      "Epoch 014 | Loss: 0.6619 | Val AUROC: 0.7856\n",
      "Epoch 015 | Loss: 0.6619 | Val AUROC: 0.7789\n",
      "Epoch 016 | Loss: 0.6018 | Val AUROC: 0.7756\n",
      "Epoch 017 | Loss: 0.5875 | Val AUROC: 0.7750\n",
      "Epoch 018 | Loss: 0.6005 | Val AUROC: 0.7811\n",
      "Epoch 019 | Loss: 0.5868 | Val AUROC: 0.7744\n",
      "Epoch 020 | Loss: 0.5576 | Val AUROC: 0.7667\n",
      "Epoch 021 | Loss: 0.5689 | Val AUROC: 0.7728\n",
      "Epoch 022 | Loss: 0.5222 | Val AUROC: 0.7706\n",
      "Epoch 023 | Loss: 0.5200 | Val AUROC: 0.7694\n",
      "Epoch 024 | Loss: 0.5475 | Val AUROC: 0.7656\n",
      "Epoch 025 | Loss: 0.5295 | Val AUROC: 0.7689\n",
      "Epoch 026 | Loss: 0.5366 | Val AUROC: 0.7672\n",
      "[Fold 1] Test AUROC: 0.7125, AUPRC: 0.5540\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 001 | Loss: 1.0737 | Val AUROC: 0.6644\n",
      "Epoch 002 | Loss: 1.0482 | Val AUROC: 0.7708\n",
      "Epoch 003 | Loss: 1.0011 | Val AUROC: 0.7742\n",
      "Epoch 004 | Loss: 0.9913 | Val AUROC: 0.7928\n",
      "Epoch 005 | Loss: 0.9649 | Val AUROC: 0.7934\n",
      "Epoch 006 | Loss: 0.9606 | Val AUROC: 0.8063\n",
      "Epoch 007 | Loss: 0.9112 | Val AUROC: 0.8114\n",
      "Epoch 008 | Loss: 0.8780 | Val AUROC: 0.8215\n",
      "Epoch 009 | Loss: 0.8431 | Val AUROC: 0.8193\n",
      "Epoch 010 | Loss: 0.8551 | Val AUROC: 0.8170\n",
      "Epoch 011 | Loss: 0.8277 | Val AUROC: 0.8102\n",
      "Epoch 012 | Loss: 0.7789 | Val AUROC: 0.8159\n",
      "Epoch 013 | Loss: 0.7748 | Val AUROC: 0.8125\n",
      "Epoch 014 | Loss: 0.7360 | Val AUROC: 0.8187\n",
      "Epoch 015 | Loss: 0.7299 | Val AUROC: 0.8204\n",
      "Epoch 016 | Loss: 0.7215 | Val AUROC: 0.8232\n",
      "Epoch 017 | Loss: 0.6987 | Val AUROC: 0.8277\n",
      "Epoch 018 | Loss: 0.7046 | Val AUROC: 0.8226\n",
      "Epoch 019 | Loss: 0.6632 | Val AUROC: 0.8159\n",
      "Epoch 020 | Loss: 0.7113 | Val AUROC: 0.8271\n",
      "Epoch 021 | Loss: 0.6736 | Val AUROC: 0.8226\n",
      "Epoch 022 | Loss: 0.6660 | Val AUROC: 0.8260\n",
      "Epoch 023 | Loss: 0.6615 | Val AUROC: 0.8271\n",
      "Epoch 024 | Loss: 0.6638 | Val AUROC: 0.8232\n",
      "Epoch 025 | Loss: 0.6704 | Val AUROC: 0.8249\n",
      "Epoch 026 | Loss: 0.6958 | Val AUROC: 0.8226\n",
      "Epoch 027 | Loss: 0.6851 | Val AUROC: 0.8187\n",
      "Epoch 028 | Loss: 0.6300 | Val AUROC: 0.8238\n",
      "Epoch 029 | Loss: 0.6497 | Val AUROC: 0.8198\n",
      "[Fold 2] Test AUROC: 0.8574, AUPRC: 0.7835\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 001 | Loss: 1.0535 | Val AUROC: 0.6667\n",
      "Epoch 002 | Loss: 1.0392 | Val AUROC: 0.7658\n",
      "Epoch 003 | Loss: 1.0095 | Val AUROC: 0.7983\n",
      "Epoch 004 | Loss: 0.9902 | Val AUROC: 0.8093\n",
      "Epoch 005 | Loss: 0.9340 | Val AUROC: 0.8104\n",
      "Epoch 006 | Loss: 0.9158 | Val AUROC: 0.8116\n",
      "Epoch 007 | Loss: 0.8764 | Val AUROC: 0.8249\n",
      "Epoch 008 | Loss: 0.8699 | Val AUROC: 0.8238\n",
      "Epoch 009 | Loss: 0.8159 | Val AUROC: 0.8203\n",
      "Epoch 010 | Loss: 0.7969 | Val AUROC: 0.8226\n",
      "Epoch 011 | Loss: 0.7738 | Val AUROC: 0.8203\n",
      "Epoch 012 | Loss: 0.7103 | Val AUROC: 0.8243\n",
      "Epoch 013 | Loss: 0.7050 | Val AUROC: 0.8261\n",
      "Epoch 014 | Loss: 0.7016 | Val AUROC: 0.8330\n",
      "Epoch 015 | Loss: 0.6938 | Val AUROC: 0.8296\n",
      "Epoch 016 | Loss: 0.7167 | Val AUROC: 0.8249\n",
      "Epoch 017 | Loss: 0.7128 | Val AUROC: 0.8284\n",
      "Epoch 018 | Loss: 0.6945 | Val AUROC: 0.8319\n",
      "Epoch 019 | Loss: 0.6603 | Val AUROC: 0.8296\n",
      "Epoch 020 | Loss: 0.7101 | Val AUROC: 0.8336\n",
      "Epoch 021 | Loss: 0.6933 | Val AUROC: 0.8284\n",
      "Epoch 022 | Loss: 0.6461 | Val AUROC: 0.8348\n",
      "Epoch 023 | Loss: 0.6554 | Val AUROC: 0.8354\n",
      "Epoch 024 | Loss: 0.6485 | Val AUROC: 0.8354\n",
      "Epoch 025 | Loss: 0.6749 | Val AUROC: 0.8377\n",
      "Epoch 026 | Loss: 0.6734 | Val AUROC: 0.8365\n",
      "Epoch 027 | Loss: 0.6722 | Val AUROC: 0.8383\n",
      "Epoch 028 | Loss: 0.6328 | Val AUROC: 0.8348\n",
      "Epoch 029 | Loss: 0.6133 | Val AUROC: 0.8325\n",
      "Epoch 030 | Loss: 0.6328 | Val AUROC: 0.8330\n",
      "Epoch 031 | Loss: 0.6206 | Val AUROC: 0.8307\n",
      "Epoch 032 | Loss: 0.6116 | Val AUROC: 0.8319\n",
      "Epoch 033 | Loss: 0.6874 | Val AUROC: 0.8313\n",
      "Epoch 034 | Loss: 0.6195 | Val AUROC: 0.8307\n",
      "Epoch 035 | Loss: 0.5945 | Val AUROC: 0.8301\n",
      "Epoch 036 | Loss: 0.6124 | Val AUROC: 0.8284\n",
      "Epoch 037 | Loss: 0.6504 | Val AUROC: 0.8342\n",
      "Epoch 038 | Loss: 0.6782 | Val AUROC: 0.8319\n",
      "Epoch 039 | Loss: 0.5726 | Val AUROC: 0.8290\n",
      "[Fold 3] Test AUROC: 0.7788, AUPRC: 0.6219\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 001 | Loss: 1.0410 | Val AUROC: 0.6734\n",
      "Epoch 002 | Loss: 1.0111 | Val AUROC: 0.7190\n",
      "Epoch 003 | Loss: 0.9897 | Val AUROC: 0.7314\n",
      "Epoch 004 | Loss: 0.9538 | Val AUROC: 0.7145\n",
      "Epoch 005 | Loss: 0.9295 | Val AUROC: 0.7078\n",
      "Epoch 006 | Loss: 0.9203 | Val AUROC: 0.7314\n",
      "Epoch 007 | Loss: 0.8703 | Val AUROC: 0.7354\n",
      "Epoch 008 | Loss: 0.8526 | Val AUROC: 0.7432\n",
      "Epoch 009 | Loss: 0.8169 | Val AUROC: 0.7494\n",
      "Epoch 010 | Loss: 0.7825 | Val AUROC: 0.7613\n",
      "Epoch 011 | Loss: 0.7739 | Val AUROC: 0.7714\n",
      "Epoch 012 | Loss: 0.7510 | Val AUROC: 0.7787\n",
      "Epoch 013 | Loss: 0.7160 | Val AUROC: 0.7894\n",
      "Epoch 014 | Loss: 0.7215 | Val AUROC: 0.7905\n",
      "Epoch 015 | Loss: 0.6754 | Val AUROC: 0.7843\n",
      "Epoch 016 | Loss: 0.6616 | Val AUROC: 0.7934\n",
      "Epoch 017 | Loss: 0.6696 | Val AUROC: 0.7956\n",
      "Epoch 018 | Loss: 0.5880 | Val AUROC: 0.7990\n",
      "Epoch 019 | Loss: 0.6024 | Val AUROC: 0.8148\n",
      "Epoch 020 | Loss: 0.6077 | Val AUROC: 0.8131\n",
      "Epoch 021 | Loss: 0.5909 | Val AUROC: 0.8114\n",
      "Epoch 022 | Loss: 0.5896 | Val AUROC: 0.8136\n",
      "Epoch 023 | Loss: 0.5238 | Val AUROC: 0.8074\n",
      "Epoch 024 | Loss: 0.5674 | Val AUROC: 0.8057\n",
      "Epoch 025 | Loss: 0.5129 | Val AUROC: 0.8080\n",
      "Epoch 026 | Loss: 0.5223 | Val AUROC: 0.8063\n",
      "Epoch 027 | Loss: 0.5411 | Val AUROC: 0.8086\n",
      "Epoch 028 | Loss: 0.5244 | Val AUROC: 0.8086\n",
      "Epoch 029 | Loss: 0.4961 | Val AUROC: 0.8125\n",
      "Epoch 030 | Loss: 0.5471 | Val AUROC: 0.8102\n",
      "Epoch 031 | Loss: 0.5133 | Val AUROC: 0.8063\n",
      "[Fold 4] Test AUROC: 0.8166, AUPRC: 0.6990\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 001 | Loss: 1.0571 | Val AUROC: 0.6695\n",
      "Epoch 002 | Loss: 1.0305 | Val AUROC: 0.7494\n",
      "Epoch 003 | Loss: 1.0055 | Val AUROC: 0.7511\n",
      "Epoch 004 | Loss: 1.0041 | Val AUROC: 0.7534\n",
      "Epoch 005 | Loss: 0.9768 | Val AUROC: 0.7658\n",
      "Epoch 006 | Loss: 0.9215 | Val AUROC: 0.7697\n",
      "Epoch 007 | Loss: 0.8933 | Val AUROC: 0.7934\n",
      "Epoch 008 | Loss: 0.8492 | Val AUROC: 0.7877\n",
      "Epoch 009 | Loss: 0.8047 | Val AUROC: 0.8035\n",
      "Epoch 010 | Loss: 0.8014 | Val AUROC: 0.8018\n",
      "Epoch 011 | Loss: 0.7276 | Val AUROC: 0.8001\n",
      "Epoch 012 | Loss: 0.7092 | Val AUROC: 0.8035\n",
      "Epoch 013 | Loss: 0.6706 | Val AUROC: 0.8035\n",
      "Epoch 014 | Loss: 0.6662 | Val AUROC: 0.8007\n",
      "Epoch 015 | Loss: 0.6440 | Val AUROC: 0.8074\n",
      "Epoch 016 | Loss: 0.7406 | Val AUROC: 0.8052\n",
      "Epoch 017 | Loss: 0.6094 | Val AUROC: 0.7939\n",
      "Epoch 018 | Loss: 0.5997 | Val AUROC: 0.7984\n",
      "Epoch 019 | Loss: 0.6365 | Val AUROC: 0.7922\n",
      "Epoch 020 | Loss: 0.6358 | Val AUROC: 0.7928\n",
      "Epoch 021 | Loss: 0.7059 | Val AUROC: 0.7877\n",
      "Epoch 022 | Loss: 0.5779 | Val AUROC: 0.7883\n",
      "Epoch 023 | Loss: 0.6245 | Val AUROC: 0.7900\n",
      "Epoch 024 | Loss: 0.6620 | Val AUROC: 0.7911\n",
      "Epoch 025 | Loss: 0.5631 | Val AUROC: 0.7928\n",
      "Epoch 026 | Loss: 0.5867 | Val AUROC: 0.7950\n",
      "Epoch 027 | Loss: 0.5956 | Val AUROC: 0.7911\n",
      "[Fold 5] Test AUROC: 0.8022, AUPRC: 0.6785\n",
      "\n",
      "===== Seed 5765 ‰∫îÊäòÁªìÊûú (Bootstrap) =====\n",
      "AUROC: 0.7976 (95% CI 0.7621-0.8320)\n",
      "AUPRC: 0.6641 (95% CI 0.6051-0.7198)\n",
      "\n",
      "==============================\n",
      "üîÅ ÊµãËØïÈöèÊú∫ÁßçÂ≠ê: 1025\n",
      "==============================\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 001 | Loss: 1.0663 | Val AUROC: 0.6357\n",
      "Epoch 002 | Loss: 1.0167 | Val AUROC: 0.6957\n",
      "Epoch 003 | Loss: 1.0160 | Val AUROC: 0.7174\n",
      "Epoch 004 | Loss: 0.9925 | Val AUROC: 0.7233\n",
      "Epoch 005 | Loss: 0.9587 | Val AUROC: 0.7262\n",
      "Epoch 006 | Loss: 0.9148 | Val AUROC: 0.7286\n",
      "Epoch 007 | Loss: 0.8868 | Val AUROC: 0.7468\n",
      "Epoch 008 | Loss: 0.8827 | Val AUROC: 0.7703\n",
      "Epoch 009 | Loss: 0.8072 | Val AUROC: 0.7638\n",
      "Epoch 010 | Loss: 0.7757 | Val AUROC: 0.7820\n",
      "Epoch 011 | Loss: 0.7597 | Val AUROC: 0.7873\n",
      "Epoch 012 | Loss: 0.7410 | Val AUROC: 0.7908\n",
      "Epoch 013 | Loss: 0.7304 | Val AUROC: 0.8043\n",
      "Epoch 014 | Loss: 0.6926 | Val AUROC: 0.8067\n",
      "Epoch 015 | Loss: 0.7023 | Val AUROC: 0.8032\n",
      "Epoch 016 | Loss: 0.6897 | Val AUROC: 0.8067\n",
      "Epoch 017 | Loss: 0.6413 | Val AUROC: 0.8020\n",
      "Epoch 018 | Loss: 0.6398 | Val AUROC: 0.8049\n",
      "Epoch 019 | Loss: 0.6204 | Val AUROC: 0.8108\n",
      "Epoch 020 | Loss: 0.6650 | Val AUROC: 0.8067\n",
      "Epoch 021 | Loss: 0.6329 | Val AUROC: 0.8061\n",
      "Epoch 022 | Loss: 0.5983 | Val AUROC: 0.8073\n",
      "Epoch 023 | Loss: 0.6422 | Val AUROC: 0.8090\n",
      "Epoch 024 | Loss: 0.6016 | Val AUROC: 0.8132\n",
      "Epoch 025 | Loss: 0.5890 | Val AUROC: 0.8126\n",
      "Epoch 026 | Loss: 0.6407 | Val AUROC: 0.8120\n",
      "Epoch 027 | Loss: 0.5752 | Val AUROC: 0.8032\n",
      "Epoch 028 | Loss: 0.5622 | Val AUROC: 0.8067\n",
      "Epoch 029 | Loss: 0.6128 | Val AUROC: 0.8096\n",
      "Epoch 030 | Loss: 0.5912 | Val AUROC: 0.8085\n",
      "Epoch 031 | Loss: 0.5416 | Val AUROC: 0.8049\n",
      "Epoch 032 | Loss: 0.5544 | Val AUROC: 0.8067\n",
      "Epoch 033 | Loss: 0.6458 | Val AUROC: 0.8038\n",
      "Epoch 034 | Loss: 0.5839 | Val AUROC: 0.8026\n",
      "Epoch 035 | Loss: 0.5888 | Val AUROC: 0.8061\n",
      "Epoch 036 | Loss: 0.5768 | Val AUROC: 0.8085\n",
      "[Fold 1] Test AUROC: 0.8209, AUPRC: 0.6971\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 001 | Loss: 1.0441 | Val AUROC: 0.7041\n",
      "Epoch 002 | Loss: 1.0089 | Val AUROC: 0.7359\n",
      "Epoch 003 | Loss: 0.9848 | Val AUROC: 0.7660\n",
      "Epoch 004 | Loss: 0.9766 | Val AUROC: 0.7710\n",
      "Epoch 005 | Loss: 0.9201 | Val AUROC: 0.7797\n",
      "Epoch 006 | Loss: 0.8994 | Val AUROC: 0.7836\n",
      "Epoch 007 | Loss: 0.8599 | Val AUROC: 0.7863\n",
      "Epoch 008 | Loss: 0.8231 | Val AUROC: 0.7808\n",
      "Epoch 009 | Loss: 0.7969 | Val AUROC: 0.7814\n",
      "Epoch 010 | Loss: 0.7597 | Val AUROC: 0.7737\n",
      "Epoch 011 | Loss: 0.7284 | Val AUROC: 0.7753\n",
      "Epoch 012 | Loss: 0.7585 | Val AUROC: 0.7759\n",
      "Epoch 013 | Loss: 0.6932 | Val AUROC: 0.7732\n",
      "Epoch 014 | Loss: 0.6600 | Val AUROC: 0.7770\n",
      "Epoch 015 | Loss: 0.6913 | Val AUROC: 0.7742\n",
      "Epoch 016 | Loss: 0.6470 | Val AUROC: 0.7715\n",
      "Epoch 017 | Loss: 0.6273 | Val AUROC: 0.7704\n",
      "Epoch 018 | Loss: 0.6433 | Val AUROC: 0.7710\n",
      "Epoch 019 | Loss: 0.7021 | Val AUROC: 0.7737\n",
      "[Fold 2] Test AUROC: 0.7919, AUPRC: 0.6166\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 001 | Loss: 1.0716 | Val AUROC: 0.6109\n",
      "Epoch 002 | Loss: 1.0219 | Val AUROC: 0.7309\n",
      "Epoch 003 | Loss: 1.0000 | Val AUROC: 0.7765\n",
      "Epoch 004 | Loss: 0.9833 | Val AUROC: 0.7877\n",
      "Epoch 005 | Loss: 0.9474 | Val AUROC: 0.7905\n",
      "Epoch 006 | Loss: 0.9121 | Val AUROC: 0.7883\n",
      "Epoch 007 | Loss: 0.8833 | Val AUROC: 0.7877\n",
      "Epoch 008 | Loss: 0.8397 | Val AUROC: 0.8024\n",
      "Epoch 009 | Loss: 0.8132 | Val AUROC: 0.8080\n",
      "Epoch 010 | Loss: 0.7638 | Val AUROC: 0.8007\n",
      "Epoch 011 | Loss: 0.7181 | Val AUROC: 0.7939\n",
      "Epoch 012 | Loss: 0.6886 | Val AUROC: 0.7995\n",
      "Epoch 013 | Loss: 0.7156 | Val AUROC: 0.8097\n",
      "Epoch 014 | Loss: 0.6832 | Val AUROC: 0.8080\n",
      "Epoch 015 | Loss: 0.6911 | Val AUROC: 0.8187\n",
      "Epoch 016 | Loss: 0.6014 | Val AUROC: 0.8209\n",
      "Epoch 017 | Loss: 0.6084 | Val AUROC: 0.8153\n",
      "Epoch 018 | Loss: 0.5736 | Val AUROC: 0.8193\n",
      "Epoch 019 | Loss: 0.5931 | Val AUROC: 0.8119\n",
      "Epoch 020 | Loss: 0.5568 | Val AUROC: 0.8181\n",
      "Epoch 021 | Loss: 0.5447 | Val AUROC: 0.8125\n",
      "Epoch 022 | Loss: 0.5779 | Val AUROC: 0.8170\n",
      "Epoch 023 | Loss: 0.5922 | Val AUROC: 0.8153\n",
      "Epoch 024 | Loss: 0.5839 | Val AUROC: 0.7990\n",
      "Epoch 025 | Loss: 0.5267 | Val AUROC: 0.8069\n",
      "Epoch 026 | Loss: 0.6170 | Val AUROC: 0.8057\n",
      "Epoch 027 | Loss: 0.5333 | Val AUROC: 0.8063\n",
      "Epoch 028 | Loss: 0.5454 | Val AUROC: 0.8057\n",
      "[Fold 3] Test AUROC: 0.7979, AUPRC: 0.6807\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 001 | Loss: 1.0415 | Val AUROC: 0.5923\n",
      "Epoch 002 | Loss: 1.0361 | Val AUROC: 0.6002\n",
      "Epoch 003 | Loss: 1.0134 | Val AUROC: 0.5968\n",
      "Epoch 004 | Loss: 1.0034 | Val AUROC: 0.5929\n",
      "Epoch 005 | Loss: 0.9605 | Val AUROC: 0.6087\n",
      "Epoch 006 | Loss: 0.9178 | Val AUROC: 0.6120\n",
      "Epoch 007 | Loss: 0.8858 | Val AUROC: 0.6216\n",
      "Epoch 008 | Loss: 0.8298 | Val AUROC: 0.6425\n",
      "Epoch 009 | Loss: 0.7999 | Val AUROC: 0.6588\n",
      "Epoch 010 | Loss: 0.7896 | Val AUROC: 0.6689\n",
      "Epoch 011 | Loss: 0.7458 | Val AUROC: 0.6740\n",
      "Epoch 012 | Loss: 0.7601 | Val AUROC: 0.6903\n",
      "Epoch 013 | Loss: 0.6864 | Val AUROC: 0.6993\n",
      "Epoch 014 | Loss: 0.6762 | Val AUROC: 0.7038\n",
      "Epoch 015 | Loss: 0.6795 | Val AUROC: 0.7111\n",
      "Epoch 016 | Loss: 0.6537 | Val AUROC: 0.7111\n",
      "Epoch 017 | Loss: 0.6064 | Val AUROC: 0.7095\n",
      "Epoch 018 | Loss: 0.5531 | Val AUROC: 0.7241\n",
      "Epoch 019 | Loss: 0.5652 | Val AUROC: 0.7117\n",
      "Epoch 020 | Loss: 0.6030 | Val AUROC: 0.7100\n",
      "Epoch 021 | Loss: 0.5469 | Val AUROC: 0.7145\n",
      "Epoch 022 | Loss: 0.6333 | Val AUROC: 0.7162\n",
      "Epoch 023 | Loss: 0.5208 | Val AUROC: 0.7241\n",
      "Epoch 024 | Loss: 0.5597 | Val AUROC: 0.7292\n",
      "Epoch 025 | Loss: 0.5330 | Val AUROC: 0.7230\n",
      "Epoch 026 | Loss: 0.5073 | Val AUROC: 0.7247\n",
      "Epoch 027 | Loss: 0.5642 | Val AUROC: 0.7247\n",
      "Epoch 028 | Loss: 0.5480 | Val AUROC: 0.7224\n",
      "Epoch 029 | Loss: 0.4883 | Val AUROC: 0.7218\n",
      "Epoch 030 | Loss: 0.5635 | Val AUROC: 0.7213\n",
      "Epoch 031 | Loss: 0.5324 | Val AUROC: 0.7202\n",
      "Epoch 032 | Loss: 0.4235 | Val AUROC: 0.7185\n",
      "Epoch 033 | Loss: 0.5047 | Val AUROC: 0.7224\n",
      "Epoch 034 | Loss: 0.5265 | Val AUROC: 0.7185\n",
      "Epoch 035 | Loss: 0.4854 | Val AUROC: 0.7162\n",
      "Epoch 036 | Loss: 0.5036 | Val AUROC: 0.7145\n",
      "[Fold 4] Test AUROC: 0.7914, AUPRC: 0.6318\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 001 | Loss: 1.0555 | Val AUROC: 0.6036\n",
      "Epoch 002 | Loss: 1.0290 | Val AUROC: 0.6374\n",
      "Epoch 003 | Loss: 1.0123 | Val AUROC: 0.6278\n",
      "Epoch 004 | Loss: 0.9821 | Val AUROC: 0.6633\n",
      "Epoch 005 | Loss: 0.9612 | Val AUROC: 0.6903\n",
      "Epoch 006 | Loss: 0.9312 | Val AUROC: 0.7044\n",
      "Epoch 007 | Loss: 0.8706 | Val AUROC: 0.7213\n",
      "Epoch 008 | Loss: 0.8480 | Val AUROC: 0.7218\n",
      "Epoch 009 | Loss: 0.8091 | Val AUROC: 0.7427\n",
      "Epoch 010 | Loss: 0.7837 | Val AUROC: 0.7461\n",
      "Epoch 011 | Loss: 0.7906 | Val AUROC: 0.7691\n",
      "Epoch 012 | Loss: 0.6890 | Val AUROC: 0.7720\n",
      "Epoch 013 | Loss: 0.7070 | Val AUROC: 0.7759\n",
      "Epoch 014 | Loss: 0.6848 | Val AUROC: 0.7731\n",
      "Epoch 015 | Loss: 0.6799 | Val AUROC: 0.7793\n",
      "Epoch 016 | Loss: 0.6764 | Val AUROC: 0.7770\n",
      "Epoch 017 | Loss: 0.6472 | Val AUROC: 0.7810\n",
      "Epoch 018 | Loss: 0.6022 | Val AUROC: 0.7776\n",
      "Epoch 019 | Loss: 0.6200 | Val AUROC: 0.7821\n",
      "Epoch 020 | Loss: 0.6383 | Val AUROC: 0.7714\n",
      "Epoch 021 | Loss: 0.5807 | Val AUROC: 0.7759\n",
      "Epoch 022 | Loss: 0.5769 | Val AUROC: 0.7742\n",
      "Epoch 023 | Loss: 0.5726 | Val AUROC: 0.7793\n",
      "Epoch 024 | Loss: 0.5289 | Val AUROC: 0.7759\n",
      "Epoch 025 | Loss: 0.5658 | Val AUROC: 0.7804\n",
      "Epoch 026 | Loss: 0.5044 | Val AUROC: 0.7776\n",
      "Epoch 027 | Loss: 0.5632 | Val AUROC: 0.7731\n",
      "Epoch 028 | Loss: 0.4925 | Val AUROC: 0.7742\n",
      "Epoch 029 | Loss: 0.5112 | Val AUROC: 0.7731\n",
      "Epoch 030 | Loss: 0.5389 | Val AUROC: 0.7759\n",
      "Epoch 031 | Loss: 0.5334 | Val AUROC: 0.7708\n",
      "[Fold 5] Test AUROC: 0.7713, AUPRC: 0.6388\n",
      "\n",
      "===== Seed 1025 ‰∫îÊäòÁªìÊûú (Bootstrap) =====\n",
      "AUROC: 0.7797 (95% CI 0.7428-0.8156)\n",
      "AUPRC: 0.6380 (95% CI 0.5773-0.6947)\n",
      "\n",
      "==============================\n",
      "üîÅ ÊµãËØïÈöèÊú∫ÁßçÂ≠ê: 7049\n",
      "==============================\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 001 | Loss: 1.0325 | Val AUROC: 0.6507\n",
      "Epoch 002 | Loss: 1.0202 | Val AUROC: 0.7694\n",
      "Epoch 003 | Loss: 0.9905 | Val AUROC: 0.8002\n",
      "Epoch 004 | Loss: 0.9736 | Val AUROC: 0.8094\n",
      "Epoch 005 | Loss: 0.9423 | Val AUROC: 0.8128\n",
      "Epoch 006 | Loss: 0.9221 | Val AUROC: 0.8248\n",
      "Epoch 007 | Loss: 0.8708 | Val AUROC: 0.8271\n",
      "Epoch 008 | Loss: 0.8211 | Val AUROC: 0.8339\n",
      "Epoch 009 | Loss: 0.8009 | Val AUROC: 0.8493\n",
      "Epoch 010 | Loss: 0.8108 | Val AUROC: 0.8527\n",
      "Epoch 011 | Loss: 0.7578 | Val AUROC: 0.8676\n",
      "Epoch 012 | Loss: 0.7247 | Val AUROC: 0.8739\n",
      "Epoch 013 | Loss: 0.7449 | Val AUROC: 0.8779\n",
      "Epoch 014 | Loss: 0.6903 | Val AUROC: 0.8801\n",
      "Epoch 015 | Loss: 0.6050 | Val AUROC: 0.8813\n",
      "Epoch 016 | Loss: 0.6504 | Val AUROC: 0.8796\n",
      "Epoch 017 | Loss: 0.6363 | Val AUROC: 0.8830\n",
      "Epoch 018 | Loss: 0.6346 | Val AUROC: 0.8824\n",
      "Epoch 019 | Loss: 0.5955 | Val AUROC: 0.8921\n",
      "Epoch 020 | Loss: 0.5677 | Val AUROC: 0.8967\n",
      "Epoch 021 | Loss: 0.5472 | Val AUROC: 0.8893\n",
      "Epoch 022 | Loss: 0.5877 | Val AUROC: 0.8904\n",
      "Epoch 023 | Loss: 0.5445 | Val AUROC: 0.8961\n",
      "Epoch 024 | Loss: 0.5119 | Val AUROC: 0.9041\n",
      "Epoch 025 | Loss: 0.5368 | Val AUROC: 0.9035\n",
      "Epoch 026 | Loss: 0.5139 | Val AUROC: 0.9064\n",
      "Epoch 027 | Loss: 0.5435 | Val AUROC: 0.9035\n",
      "Epoch 028 | Loss: 0.4822 | Val AUROC: 0.9024\n",
      "Epoch 029 | Loss: 0.5199 | Val AUROC: 0.9081\n",
      "Epoch 030 | Loss: 0.4710 | Val AUROC: 0.9058\n",
      "Epoch 031 | Loss: 0.4258 | Val AUROC: 0.9104\n",
      "Epoch 032 | Loss: 0.4813 | Val AUROC: 0.9121\n",
      "Epoch 033 | Loss: 0.4225 | Val AUROC: 0.9035\n",
      "Epoch 034 | Loss: 0.4375 | Val AUROC: 0.8984\n",
      "Epoch 035 | Loss: 0.4393 | Val AUROC: 0.9001\n",
      "Epoch 036 | Loss: 0.4111 | Val AUROC: 0.8950\n",
      "Epoch 037 | Loss: 0.4516 | Val AUROC: 0.8950\n",
      "Epoch 038 | Loss: 0.4255 | Val AUROC: 0.8933\n",
      "Epoch 039 | Loss: 0.4446 | Val AUROC: 0.8893\n",
      "Epoch 040 | Loss: 0.4547 | Val AUROC: 0.8893\n",
      "Epoch 041 | Loss: 0.4156 | Val AUROC: 0.8927\n",
      "Epoch 042 | Loss: 0.4223 | Val AUROC: 0.8921\n",
      "Epoch 043 | Loss: 0.3706 | Val AUROC: 0.8967\n",
      "Epoch 044 | Loss: 0.4758 | Val AUROC: 0.8938\n",
      "[Fold 1] Test AUROC: 0.7507, AUPRC: 0.5867\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 001 | Loss: 1.0480 | Val AUROC: 0.5850\n",
      "Epoch 002 | Loss: 1.0299 | Val AUROC: 0.6976\n",
      "Epoch 003 | Loss: 1.0104 | Val AUROC: 0.7866\n",
      "Epoch 004 | Loss: 0.9648 | Val AUROC: 0.8142\n",
      "Epoch 005 | Loss: 0.9644 | Val AUROC: 0.8209\n",
      "Epoch 006 | Loss: 0.9125 | Val AUROC: 0.8412\n",
      "Epoch 007 | Loss: 0.8664 | Val AUROC: 0.8502\n",
      "Epoch 008 | Loss: 0.8392 | Val AUROC: 0.8553\n",
      "Epoch 009 | Loss: 0.7837 | Val AUROC: 0.8643\n",
      "Epoch 010 | Loss: 0.7548 | Val AUROC: 0.8767\n",
      "Epoch 011 | Loss: 0.7469 | Val AUROC: 0.8773\n",
      "Epoch 012 | Loss: 0.7188 | Val AUROC: 0.8784\n",
      "Epoch 013 | Loss: 0.6913 | Val AUROC: 0.8739\n",
      "Epoch 014 | Loss: 0.7448 | Val AUROC: 0.8778\n",
      "Epoch 015 | Loss: 0.6763 | Val AUROC: 0.8761\n",
      "Epoch 016 | Loss: 0.6447 | Val AUROC: 0.8722\n",
      "Epoch 017 | Loss: 0.6163 | Val AUROC: 0.8823\n",
      "Epoch 018 | Loss: 0.5806 | Val AUROC: 0.8739\n",
      "Epoch 019 | Loss: 0.6151 | Val AUROC: 0.8812\n",
      "Epoch 020 | Loss: 0.6159 | Val AUROC: 0.8829\n",
      "Epoch 021 | Loss: 0.6194 | Val AUROC: 0.8789\n",
      "Epoch 022 | Loss: 0.5962 | Val AUROC: 0.8773\n",
      "Epoch 023 | Loss: 0.5732 | Val AUROC: 0.8739\n",
      "Epoch 024 | Loss: 0.5490 | Val AUROC: 0.8750\n",
      "Epoch 025 | Loss: 0.5224 | Val AUROC: 0.8733\n",
      "Epoch 026 | Loss: 0.6412 | Val AUROC: 0.8773\n",
      "Epoch 027 | Loss: 0.5289 | Val AUROC: 0.8705\n",
      "Epoch 028 | Loss: 0.5257 | Val AUROC: 0.8699\n",
      "Epoch 029 | Loss: 0.6037 | Val AUROC: 0.8705\n",
      "Epoch 030 | Loss: 0.5432 | Val AUROC: 0.8711\n",
      "Epoch 031 | Loss: 0.5855 | Val AUROC: 0.8671\n",
      "Epoch 032 | Loss: 0.5619 | Val AUROC: 0.8677\n",
      "[Fold 2] Test AUROC: 0.7361, AUPRC: 0.5658\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 001 | Loss: 1.0326 | Val AUROC: 0.5956\n",
      "Epoch 002 | Loss: 1.0247 | Val AUROC: 0.6597\n",
      "Epoch 003 | Loss: 0.9785 | Val AUROC: 0.7014\n",
      "Epoch 004 | Loss: 0.9582 | Val AUROC: 0.7085\n",
      "Epoch 005 | Loss: 0.9259 | Val AUROC: 0.7255\n",
      "Epoch 006 | Loss: 0.8920 | Val AUROC: 0.7496\n",
      "Epoch 007 | Loss: 0.8656 | Val AUROC: 0.7732\n",
      "Epoch 008 | Loss: 0.8311 | Val AUROC: 0.7973\n",
      "Epoch 009 | Loss: 0.8067 | Val AUROC: 0.8044\n",
      "Epoch 010 | Loss: 0.7677 | Val AUROC: 0.8082\n",
      "Epoch 011 | Loss: 0.7482 | Val AUROC: 0.8126\n",
      "Epoch 012 | Loss: 0.7304 | Val AUROC: 0.8137\n",
      "Epoch 013 | Loss: 0.6936 | Val AUROC: 0.8038\n",
      "Epoch 014 | Loss: 0.6986 | Val AUROC: 0.8093\n",
      "Epoch 015 | Loss: 0.6690 | Val AUROC: 0.8099\n",
      "Epoch 016 | Loss: 0.6231 | Val AUROC: 0.8115\n",
      "Epoch 017 | Loss: 0.6330 | Val AUROC: 0.8159\n",
      "Epoch 018 | Loss: 0.6096 | Val AUROC: 0.8126\n",
      "Epoch 019 | Loss: 0.6057 | Val AUROC: 0.8126\n",
      "Epoch 020 | Loss: 0.6172 | Val AUROC: 0.8126\n",
      "Epoch 021 | Loss: 0.6223 | Val AUROC: 0.8159\n",
      "Epoch 022 | Loss: 0.5836 | Val AUROC: 0.8142\n",
      "Epoch 023 | Loss: 0.5962 | Val AUROC: 0.8121\n",
      "Epoch 024 | Loss: 0.6141 | Val AUROC: 0.8142\n",
      "Epoch 025 | Loss: 0.6177 | Val AUROC: 0.8148\n",
      "Epoch 026 | Loss: 0.5602 | Val AUROC: 0.8132\n",
      "Epoch 027 | Loss: 0.5879 | Val AUROC: 0.8132\n",
      "Epoch 028 | Loss: 0.5298 | Val AUROC: 0.8137\n",
      "Epoch 029 | Loss: 0.5681 | Val AUROC: 0.8164\n",
      "Epoch 030 | Loss: 0.5522 | Val AUROC: 0.8142\n",
      "Epoch 031 | Loss: 0.5308 | Val AUROC: 0.8159\n",
      "Epoch 032 | Loss: 0.5568 | Val AUROC: 0.8159\n",
      "Epoch 033 | Loss: 0.5471 | Val AUROC: 0.8159\n",
      "Epoch 034 | Loss: 0.5460 | Val AUROC: 0.8142\n",
      "Epoch 035 | Loss: 0.5554 | Val AUROC: 0.8153\n",
      "Epoch 036 | Loss: 0.5581 | Val AUROC: 0.8132\n",
      "Epoch 037 | Loss: 0.6515 | Val AUROC: 0.8153\n",
      "Epoch 038 | Loss: 0.5341 | Val AUROC: 0.8137\n",
      "Epoch 039 | Loss: 0.5237 | Val AUROC: 0.8153\n",
      "Epoch 040 | Loss: 0.5655 | Val AUROC: 0.8159\n",
      "Epoch 041 | Loss: 0.5330 | Val AUROC: 0.8181\n",
      "Epoch 042 | Loss: 0.5266 | Val AUROC: 0.8164\n",
      "Epoch 043 | Loss: 0.5713 | Val AUROC: 0.8132\n",
      "Epoch 044 | Loss: 0.5296 | Val AUROC: 0.8159\n",
      "Epoch 045 | Loss: 0.5308 | Val AUROC: 0.8175\n",
      "Epoch 046 | Loss: 0.5567 | Val AUROC: 0.8170\n",
      "Epoch 047 | Loss: 0.5912 | Val AUROC: 0.8159\n",
      "Epoch 048 | Loss: 0.5826 | Val AUROC: 0.8153\n",
      "Epoch 049 | Loss: 0.5220 | Val AUROC: 0.8170\n",
      "Epoch 050 | Loss: 0.5778 | Val AUROC: 0.8153\n",
      "Epoch 051 | Loss: 0.5373 | Val AUROC: 0.8142\n",
      "Epoch 052 | Loss: 0.5310 | Val AUROC: 0.8170\n",
      "Epoch 053 | Loss: 0.5916 | Val AUROC: 0.8181\n",
      "[Fold 3] Test AUROC: 0.7636, AUPRC: 0.6411\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 001 | Loss: 1.0444 | Val AUROC: 0.6734\n",
      "Epoch 002 | Loss: 1.0331 | Val AUROC: 0.7320\n",
      "Epoch 003 | Loss: 1.0004 | Val AUROC: 0.7613\n",
      "Epoch 004 | Loss: 0.9765 | Val AUROC: 0.7860\n",
      "Epoch 005 | Loss: 0.9600 | Val AUROC: 0.7832\n",
      "Epoch 006 | Loss: 0.9249 | Val AUROC: 0.7872\n",
      "Epoch 007 | Loss: 0.8849 | Val AUROC: 0.8041\n",
      "Epoch 008 | Loss: 0.8648 | Val AUROC: 0.8215\n",
      "Epoch 009 | Loss: 0.8296 | Val AUROC: 0.8288\n",
      "Epoch 010 | Loss: 0.7986 | Val AUROC: 0.8316\n",
      "Epoch 011 | Loss: 0.7574 | Val AUROC: 0.8440\n",
      "Epoch 012 | Loss: 0.7552 | Val AUROC: 0.8418\n",
      "Epoch 013 | Loss: 0.7269 | Val AUROC: 0.8474\n",
      "Epoch 014 | Loss: 0.7192 | Val AUROC: 0.8418\n",
      "Epoch 015 | Loss: 0.7222 | Val AUROC: 0.8423\n",
      "Epoch 016 | Loss: 0.7198 | Val AUROC: 0.8457\n",
      "Epoch 017 | Loss: 0.6217 | Val AUROC: 0.8452\n",
      "Epoch 018 | Loss: 0.6098 | Val AUROC: 0.8480\n",
      "Epoch 019 | Loss: 0.6228 | Val AUROC: 0.8497\n",
      "Epoch 020 | Loss: 0.6883 | Val AUROC: 0.8463\n",
      "Epoch 021 | Loss: 0.6176 | Val AUROC: 0.8485\n",
      "Epoch 022 | Loss: 0.6065 | Val AUROC: 0.8508\n",
      "Epoch 023 | Loss: 0.5742 | Val AUROC: 0.8508\n",
      "Epoch 024 | Loss: 0.5976 | Val AUROC: 0.8474\n",
      "Epoch 025 | Loss: 0.6092 | Val AUROC: 0.8530\n",
      "Epoch 026 | Loss: 0.6374 | Val AUROC: 0.8502\n",
      "Epoch 027 | Loss: 0.6218 | Val AUROC: 0.8547\n",
      "Epoch 028 | Loss: 0.5627 | Val AUROC: 0.8570\n",
      "Epoch 029 | Loss: 0.5410 | Val AUROC: 0.8559\n",
      "Epoch 030 | Loss: 0.5833 | Val AUROC: 0.8514\n",
      "Epoch 031 | Loss: 0.5894 | Val AUROC: 0.8497\n",
      "Epoch 032 | Loss: 0.6060 | Val AUROC: 0.8435\n",
      "Epoch 033 | Loss: 0.5495 | Val AUROC: 0.8474\n",
      "Epoch 034 | Loss: 0.5754 | Val AUROC: 0.8502\n",
      "Epoch 035 | Loss: 0.5326 | Val AUROC: 0.8485\n",
      "Epoch 036 | Loss: 0.5018 | Val AUROC: 0.8497\n",
      "Epoch 037 | Loss: 0.5222 | Val AUROC: 0.8508\n",
      "Epoch 038 | Loss: 0.5495 | Val AUROC: 0.8508\n",
      "Epoch 039 | Loss: 0.5522 | Val AUROC: 0.8497\n",
      "Epoch 040 | Loss: 0.4810 | Val AUROC: 0.8508\n",
      "[Fold 4] Test AUROC: 0.8467, AUPRC: 0.7058\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 001 | Loss: 1.0352 | Val AUROC: 0.6689\n",
      "Epoch 002 | Loss: 1.0264 | Val AUROC: 0.6689\n",
      "Epoch 003 | Loss: 0.9857 | Val AUROC: 0.6836\n",
      "Epoch 004 | Loss: 0.9656 | Val AUROC: 0.7207\n",
      "Epoch 005 | Loss: 0.9391 | Val AUROC: 0.7264\n",
      "Epoch 006 | Loss: 0.8914 | Val AUROC: 0.7309\n",
      "Epoch 007 | Loss: 0.8957 | Val AUROC: 0.7562\n",
      "Epoch 008 | Loss: 0.8276 | Val AUROC: 0.7686\n",
      "Epoch 009 | Loss: 0.8116 | Val AUROC: 0.7793\n",
      "Epoch 010 | Loss: 0.7690 | Val AUROC: 0.7843\n",
      "Epoch 011 | Loss: 0.7237 | Val AUROC: 0.7990\n",
      "Epoch 012 | Loss: 0.7033 | Val AUROC: 0.8012\n",
      "Epoch 013 | Loss: 0.7479 | Val AUROC: 0.8024\n",
      "Epoch 014 | Loss: 0.6756 | Val AUROC: 0.8012\n",
      "Epoch 015 | Loss: 0.7237 | Val AUROC: 0.8035\n",
      "Epoch 016 | Loss: 0.6875 | Val AUROC: 0.7984\n",
      "Epoch 017 | Loss: 0.6436 | Val AUROC: 0.7956\n",
      "Epoch 018 | Loss: 0.6455 | Val AUROC: 0.7962\n",
      "Epoch 019 | Loss: 0.5897 | Val AUROC: 0.7939\n",
      "Epoch 020 | Loss: 0.5967 | Val AUROC: 0.7967\n",
      "Epoch 021 | Loss: 0.6009 | Val AUROC: 0.7950\n",
      "Epoch 022 | Loss: 0.5860 | Val AUROC: 0.7984\n",
      "Epoch 023 | Loss: 0.6027 | Val AUROC: 0.7945\n",
      "Epoch 024 | Loss: 0.5881 | Val AUROC: 0.7973\n",
      "Epoch 025 | Loss: 0.5051 | Val AUROC: 0.7979\n",
      "Epoch 026 | Loss: 0.5886 | Val AUROC: 0.7990\n",
      "Epoch 027 | Loss: 0.5551 | Val AUROC: 0.7962\n",
      "[Fold 5] Test AUROC: 0.8108, AUPRC: 0.7430\n",
      "\n",
      "===== Seed 7049 ‰∫îÊäòÁªìÊûú (Bootstrap) =====\n",
      "AUROC: 0.7796 (95% CI 0.7424-0.8159)\n",
      "AUPRC: 0.6425 (95% CI 0.5845-0.6983)\n",
      "\n",
      "==============================\n",
      "üîÅ ÊµãËØïÈöèÊú∫ÁßçÂ≠ê: 9071\n",
      "==============================\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 001 | Loss: 1.0591 | Val AUROC: 0.6416\n",
      "Epoch 002 | Loss: 1.0102 | Val AUROC: 0.7871\n",
      "Epoch 003 | Loss: 1.0117 | Val AUROC: 0.8065\n",
      "Epoch 004 | Loss: 0.9965 | Val AUROC: 0.8128\n",
      "Epoch 005 | Loss: 0.9455 | Val AUROC: 0.8059\n",
      "Epoch 006 | Loss: 0.9167 | Val AUROC: 0.8019\n",
      "Epoch 007 | Loss: 0.9000 | Val AUROC: 0.8031\n",
      "Epoch 008 | Loss: 0.8705 | Val AUROC: 0.8048\n",
      "Epoch 009 | Loss: 0.8184 | Val AUROC: 0.8099\n",
      "Epoch 010 | Loss: 0.8045 | Val AUROC: 0.8071\n",
      "Epoch 011 | Loss: 0.7973 | Val AUROC: 0.8065\n",
      "Epoch 012 | Loss: 0.7883 | Val AUROC: 0.8054\n",
      "Epoch 013 | Loss: 0.7617 | Val AUROC: 0.8059\n",
      "Epoch 014 | Loss: 0.7351 | Val AUROC: 0.8031\n",
      "Epoch 015 | Loss: 0.7373 | Val AUROC: 0.7985\n",
      "Epoch 016 | Loss: 0.7546 | Val AUROC: 0.7991\n",
      "[Fold 1] Test AUROC: 0.6918, AUPRC: 0.5380\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 001 | Loss: 1.1184 | Val AUROC: 0.6400\n",
      "Epoch 002 | Loss: 1.0713 | Val AUROC: 0.6852\n",
      "Epoch 003 | Loss: 1.0563 | Val AUROC: 0.6986\n",
      "Epoch 004 | Loss: 1.0268 | Val AUROC: 0.7038\n",
      "Epoch 005 | Loss: 1.0063 | Val AUROC: 0.7461\n",
      "Epoch 006 | Loss: 0.9970 | Val AUROC: 0.7386\n",
      "Epoch 007 | Loss: 0.9674 | Val AUROC: 0.7467\n",
      "Epoch 008 | Loss: 0.9110 | Val AUROC: 0.7530\n",
      "Epoch 009 | Loss: 0.9012 | Val AUROC: 0.7670\n",
      "Epoch 010 | Loss: 0.8438 | Val AUROC: 0.7739\n",
      "Epoch 011 | Loss: 0.8190 | Val AUROC: 0.7693\n",
      "Epoch 012 | Loss: 0.7509 | Val AUROC: 0.7704\n",
      "Epoch 013 | Loss: 0.7698 | Val AUROC: 0.7774\n",
      "Epoch 014 | Loss: 0.6954 | Val AUROC: 0.7704\n",
      "Epoch 015 | Loss: 0.7186 | Val AUROC: 0.7716\n",
      "Epoch 016 | Loss: 0.6604 | Val AUROC: 0.7699\n",
      "Epoch 017 | Loss: 0.6414 | Val AUROC: 0.7652\n",
      "Epoch 018 | Loss: 0.6335 | Val AUROC: 0.7606\n",
      "Epoch 019 | Loss: 0.6926 | Val AUROC: 0.7571\n",
      "Epoch 020 | Loss: 0.6255 | Val AUROC: 0.7704\n",
      "Epoch 021 | Loss: 0.6191 | Val AUROC: 0.7710\n",
      "Epoch 022 | Loss: 0.6331 | Val AUROC: 0.7728\n",
      "Epoch 023 | Loss: 0.5924 | Val AUROC: 0.7757\n",
      "Epoch 024 | Loss: 0.5906 | Val AUROC: 0.7704\n",
      "Epoch 025 | Loss: 0.6069 | Val AUROC: 0.7786\n",
      "Epoch 026 | Loss: 0.6820 | Val AUROC: 0.7687\n",
      "Epoch 027 | Loss: 0.5977 | Val AUROC: 0.7722\n",
      "Epoch 028 | Loss: 0.5893 | Val AUROC: 0.7739\n",
      "Epoch 029 | Loss: 0.5766 | Val AUROC: 0.7751\n",
      "Epoch 030 | Loss: 0.5743 | Val AUROC: 0.7780\n",
      "Epoch 031 | Loss: 0.5986 | Val AUROC: 0.7762\n",
      "Epoch 032 | Loss: 0.5458 | Val AUROC: 0.7786\n",
      "Epoch 033 | Loss: 0.6127 | Val AUROC: 0.7751\n",
      "Epoch 034 | Loss: 0.5519 | Val AUROC: 0.7722\n",
      "Epoch 035 | Loss: 0.5405 | Val AUROC: 0.7809\n",
      "Epoch 036 | Loss: 0.6057 | Val AUROC: 0.7774\n",
      "Epoch 037 | Loss: 0.5445 | Val AUROC: 0.7774\n",
      "Epoch 038 | Loss: 0.5993 | Val AUROC: 0.7791\n",
      "Epoch 039 | Loss: 0.5311 | Val AUROC: 0.7774\n",
      "Epoch 040 | Loss: 0.5567 | Val AUROC: 0.7809\n",
      "Epoch 041 | Loss: 0.5935 | Val AUROC: 0.7762\n",
      "Epoch 042 | Loss: 0.5673 | Val AUROC: 0.7728\n",
      "Epoch 043 | Loss: 0.5714 | Val AUROC: 0.7814\n",
      "Epoch 044 | Loss: 0.5762 | Val AUROC: 0.7757\n",
      "Epoch 045 | Loss: 0.5772 | Val AUROC: 0.7786\n",
      "Epoch 046 | Loss: 0.5645 | Val AUROC: 0.7733\n",
      "Epoch 047 | Loss: 0.5822 | Val AUROC: 0.7797\n",
      "Epoch 048 | Loss: 0.6841 | Val AUROC: 0.7716\n",
      "Epoch 049 | Loss: 0.5722 | Val AUROC: 0.7832\n",
      "Epoch 050 | Loss: 0.5385 | Val AUROC: 0.7814\n",
      "Epoch 051 | Loss: 0.5656 | Val AUROC: 0.7780\n",
      "Epoch 052 | Loss: 0.5640 | Val AUROC: 0.7757\n",
      "Epoch 053 | Loss: 0.5590 | Val AUROC: 0.7780\n",
      "Epoch 054 | Loss: 0.5899 | Val AUROC: 0.7757\n",
      "Epoch 055 | Loss: 0.5662 | Val AUROC: 0.7768\n",
      "Epoch 056 | Loss: 0.5416 | Val AUROC: 0.7774\n",
      "Epoch 057 | Loss: 0.5752 | Val AUROC: 0.7803\n",
      "Epoch 058 | Loss: 0.6230 | Val AUROC: 0.7733\n",
      "Epoch 059 | Loss: 0.5603 | Val AUROC: 0.7791\n",
      "Epoch 060 | Loss: 0.5571 | Val AUROC: 0.7809\n",
      "Epoch 061 | Loss: 0.5485 | Val AUROC: 0.7757\n",
      "[Fold 2] Test AUROC: 0.7908, AUPRC: 0.6940\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 001 | Loss: 1.1104 | Val AUROC: 0.5293\n",
      "Epoch 002 | Loss: 1.0273 | Val AUROC: 0.6588\n",
      "Epoch 003 | Loss: 1.0060 | Val AUROC: 0.7106\n",
      "Epoch 004 | Loss: 1.0039 | Val AUROC: 0.7252\n",
      "Epoch 005 | Loss: 0.9861 | Val AUROC: 0.7235\n",
      "Epoch 006 | Loss: 0.9824 | Val AUROC: 0.7280\n",
      "Epoch 007 | Loss: 0.9250 | Val AUROC: 0.7348\n",
      "Epoch 008 | Loss: 0.8991 | Val AUROC: 0.7348\n",
      "Epoch 009 | Loss: 0.8433 | Val AUROC: 0.7365\n",
      "Epoch 010 | Loss: 0.8277 | Val AUROC: 0.7421\n",
      "Epoch 011 | Loss: 0.7648 | Val AUROC: 0.7472\n",
      "Epoch 012 | Loss: 0.7408 | Val AUROC: 0.7483\n",
      "Epoch 013 | Loss: 0.7168 | Val AUROC: 0.7601\n",
      "Epoch 014 | Loss: 0.7087 | Val AUROC: 0.7624\n",
      "Epoch 015 | Loss: 0.6831 | Val AUROC: 0.7669\n",
      "Epoch 016 | Loss: 0.6884 | Val AUROC: 0.7652\n",
      "Epoch 017 | Loss: 0.6718 | Val AUROC: 0.7663\n",
      "Epoch 018 | Loss: 0.6441 | Val AUROC: 0.7703\n",
      "Epoch 019 | Loss: 0.6308 | Val AUROC: 0.7770\n",
      "Epoch 020 | Loss: 0.6134 | Val AUROC: 0.7838\n",
      "Epoch 021 | Loss: 0.5687 | Val AUROC: 0.7905\n",
      "Epoch 022 | Loss: 0.5943 | Val AUROC: 0.7849\n",
      "Epoch 023 | Loss: 0.5812 | Val AUROC: 0.7838\n",
      "Epoch 024 | Loss: 0.5449 | Val AUROC: 0.7838\n",
      "Epoch 025 | Loss: 0.5370 | Val AUROC: 0.7815\n",
      "Epoch 026 | Loss: 0.5407 | Val AUROC: 0.7787\n",
      "Epoch 027 | Loss: 0.5763 | Val AUROC: 0.7776\n",
      "Epoch 028 | Loss: 0.5212 | Val AUROC: 0.7748\n",
      "Epoch 029 | Loss: 0.5625 | Val AUROC: 0.7736\n",
      "Epoch 030 | Loss: 0.4933 | Val AUROC: 0.7708\n",
      "Epoch 031 | Loss: 0.4913 | Val AUROC: 0.7748\n",
      "Epoch 032 | Loss: 0.5425 | Val AUROC: 0.7736\n",
      "Epoch 033 | Loss: 0.4865 | Val AUROC: 0.7753\n",
      "[Fold 3] Test AUROC: 0.8061, AUPRC: 0.7003\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 001 | Loss: 1.0334 | Val AUROC: 0.7047\n",
      "Epoch 002 | Loss: 1.0019 | Val AUROC: 0.8175\n",
      "Epoch 003 | Loss: 0.9887 | Val AUROC: 0.8329\n",
      "Epoch 004 | Loss: 0.9502 | Val AUROC: 0.8460\n",
      "Epoch 005 | Loss: 0.9391 | Val AUROC: 0.8526\n",
      "Epoch 006 | Loss: 0.8850 | Val AUROC: 0.8636\n",
      "Epoch 007 | Loss: 0.8656 | Val AUROC: 0.8849\n",
      "Epoch 008 | Loss: 0.8366 | Val AUROC: 0.8953\n",
      "Epoch 009 | Loss: 0.8279 | Val AUROC: 0.9036\n",
      "Epoch 010 | Loss: 0.8119 | Val AUROC: 0.9014\n",
      "Epoch 011 | Loss: 0.7859 | Val AUROC: 0.9096\n",
      "Epoch 012 | Loss: 0.7664 | Val AUROC: 0.9030\n",
      "Epoch 013 | Loss: 0.7140 | Val AUROC: 0.8986\n",
      "Epoch 014 | Loss: 0.6989 | Val AUROC: 0.9036\n",
      "Epoch 015 | Loss: 0.7086 | Val AUROC: 0.9052\n",
      "Epoch 016 | Loss: 0.6764 | Val AUROC: 0.9079\n",
      "Epoch 017 | Loss: 0.6405 | Val AUROC: 0.9047\n",
      "Epoch 018 | Loss: 0.6610 | Val AUROC: 0.9052\n",
      "Epoch 019 | Loss: 0.6806 | Val AUROC: 0.9079\n",
      "Epoch 020 | Loss: 0.6692 | Val AUROC: 0.9074\n",
      "Epoch 021 | Loss: 0.6284 | Val AUROC: 0.9058\n",
      "Epoch 022 | Loss: 0.6399 | Val AUROC: 0.9058\n",
      "Epoch 023 | Loss: 0.6356 | Val AUROC: 0.9041\n",
      "[Fold 4] Test AUROC: 0.7867, AUPRC: 0.6603\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 001 | Loss: 1.0234 | Val AUROC: 0.7397\n",
      "Epoch 002 | Loss: 1.0193 | Val AUROC: 0.8060\n",
      "Epoch 003 | Loss: 0.9883 | Val AUROC: 0.7841\n",
      "Epoch 004 | Loss: 0.9906 | Val AUROC: 0.7655\n",
      "Epoch 005 | Loss: 0.9436 | Val AUROC: 0.7775\n",
      "Epoch 006 | Loss: 0.9081 | Val AUROC: 0.7858\n",
      "Epoch 007 | Loss: 0.8720 | Val AUROC: 0.7863\n",
      "Epoch 008 | Loss: 0.8622 | Val AUROC: 0.7841\n",
      "Epoch 009 | Loss: 0.8465 | Val AUROC: 0.7874\n",
      "Epoch 010 | Loss: 0.8231 | Val AUROC: 0.7978\n",
      "Epoch 011 | Loss: 0.7890 | Val AUROC: 0.7934\n",
      "Epoch 012 | Loss: 0.7988 | Val AUROC: 0.7890\n",
      "Epoch 013 | Loss: 0.7983 | Val AUROC: 0.7896\n",
      "Epoch 014 | Loss: 0.8071 | Val AUROC: 0.7956\n",
      "[Fold 5] Test AUROC: 0.7742, AUPRC: 0.5481\n",
      "\n",
      "===== Seed 9071 ‰∫îÊäòÁªìÊûú (Bootstrap) =====\n",
      "AUROC: 0.7517 (95% CI 0.7114-0.7879)\n",
      "AUPRC: 0.5974 (95% CI 0.5338-0.6532)\n",
      "\n",
      "==============================\n",
      "üîÅ ÊµãËØïÈöèÊú∫ÁßçÂ≠ê: 7433\n",
      "==============================\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 001 | Loss: 1.0773 | Val AUROC: 0.5972\n",
      "Epoch 002 | Loss: 1.0248 | Val AUROC: 0.7583\n",
      "Epoch 003 | Loss: 0.9859 | Val AUROC: 0.7883\n",
      "Epoch 004 | Loss: 0.9943 | Val AUROC: 0.8039\n",
      "Epoch 005 | Loss: 0.9660 | Val AUROC: 0.8267\n",
      "Epoch 006 | Loss: 0.9107 | Val AUROC: 0.8294\n",
      "Epoch 007 | Loss: 0.8956 | Val AUROC: 0.8339\n",
      "Epoch 008 | Loss: 0.8387 | Val AUROC: 0.8361\n",
      "Epoch 009 | Loss: 0.8086 | Val AUROC: 0.8389\n",
      "Epoch 010 | Loss: 0.7704 | Val AUROC: 0.8411\n",
      "Epoch 011 | Loss: 0.8006 | Val AUROC: 0.8383\n",
      "Epoch 012 | Loss: 0.7259 | Val AUROC: 0.8278\n",
      "Epoch 013 | Loss: 0.7264 | Val AUROC: 0.8261\n",
      "Epoch 014 | Loss: 0.6699 | Val AUROC: 0.8244\n",
      "Epoch 015 | Loss: 0.6556 | Val AUROC: 0.8256\n",
      "Epoch 016 | Loss: 0.6780 | Val AUROC: 0.8239\n",
      "Epoch 017 | Loss: 0.7015 | Val AUROC: 0.8244\n",
      "Epoch 018 | Loss: 0.6536 | Val AUROC: 0.8267\n",
      "Epoch 019 | Loss: 0.6170 | Val AUROC: 0.8267\n",
      "Epoch 020 | Loss: 0.6277 | Val AUROC: 0.8272\n",
      "Epoch 021 | Loss: 0.6258 | Val AUROC: 0.8239\n",
      "Epoch 022 | Loss: 0.6818 | Val AUROC: 0.8261\n",
      "[Fold 1] Test AUROC: 0.7729, AUPRC: 0.6086\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 001 | Loss: 1.0437 | Val AUROC: 0.7387\n",
      "Epoch 002 | Loss: 1.0131 | Val AUROC: 0.7984\n",
      "Epoch 003 | Loss: 0.9998 | Val AUROC: 0.8074\n",
      "Epoch 004 | Loss: 0.9712 | Val AUROC: 0.8221\n",
      "Epoch 005 | Loss: 0.9283 | Val AUROC: 0.8300\n",
      "Epoch 006 | Loss: 0.9214 | Val AUROC: 0.8373\n",
      "Epoch 007 | Loss: 0.8589 | Val AUROC: 0.8367\n",
      "Epoch 008 | Loss: 0.8175 | Val AUROC: 0.8401\n",
      "Epoch 009 | Loss: 0.7990 | Val AUROC: 0.8423\n",
      "Epoch 010 | Loss: 0.7666 | Val AUROC: 0.8530\n",
      "Epoch 011 | Loss: 0.7387 | Val AUROC: 0.8485\n",
      "Epoch 012 | Loss: 0.7273 | Val AUROC: 0.8480\n",
      "Epoch 013 | Loss: 0.7236 | Val AUROC: 0.8497\n",
      "Epoch 014 | Loss: 0.6919 | Val AUROC: 0.8497\n",
      "Epoch 015 | Loss: 0.6819 | Val AUROC: 0.8547\n",
      "Epoch 016 | Loss: 0.6763 | Val AUROC: 0.8508\n",
      "Epoch 017 | Loss: 0.6893 | Val AUROC: 0.8508\n",
      "Epoch 018 | Loss: 0.6386 | Val AUROC: 0.8530\n",
      "Epoch 019 | Loss: 0.6301 | Val AUROC: 0.8480\n",
      "Epoch 020 | Loss: 0.6211 | Val AUROC: 0.8525\n",
      "Epoch 021 | Loss: 0.6090 | Val AUROC: 0.8497\n",
      "Epoch 022 | Loss: 0.6021 | Val AUROC: 0.8491\n",
      "Epoch 023 | Loss: 0.5763 | Val AUROC: 0.8480\n",
      "Epoch 024 | Loss: 0.6447 | Val AUROC: 0.8480\n",
      "Epoch 025 | Loss: 0.6037 | Val AUROC: 0.8514\n",
      "Epoch 026 | Loss: 0.6004 | Val AUROC: 0.8536\n",
      "Epoch 027 | Loss: 0.6025 | Val AUROC: 0.8514\n",
      "[Fold 2] Test AUROC: 0.7982, AUPRC: 0.6683\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 001 | Loss: 1.0441 | Val AUROC: 0.7894\n",
      "Epoch 002 | Loss: 1.0270 | Val AUROC: 0.8260\n",
      "Epoch 003 | Loss: 0.9731 | Val AUROC: 0.8452\n",
      "Epoch 004 | Loss: 0.9776 | Val AUROC: 0.8457\n",
      "Epoch 005 | Loss: 0.9665 | Val AUROC: 0.8598\n",
      "Epoch 006 | Loss: 0.8964 | Val AUROC: 0.8671\n",
      "Epoch 007 | Loss: 0.8859 | Val AUROC: 0.8733\n",
      "Epoch 008 | Loss: 0.8777 | Val AUROC: 0.8694\n",
      "Epoch 009 | Loss: 0.8237 | Val AUROC: 0.8722\n",
      "Epoch 010 | Loss: 0.7926 | Val AUROC: 0.8744\n",
      "Epoch 011 | Loss: 0.7790 | Val AUROC: 0.8806\n",
      "Epoch 012 | Loss: 0.7585 | Val AUROC: 0.8863\n",
      "Epoch 013 | Loss: 0.7628 | Val AUROC: 0.8801\n",
      "Epoch 014 | Loss: 0.7468 | Val AUROC: 0.8767\n",
      "Epoch 015 | Loss: 0.7037 | Val AUROC: 0.8778\n",
      "Epoch 016 | Loss: 0.6596 | Val AUROC: 0.8823\n",
      "Epoch 017 | Loss: 0.7303 | Val AUROC: 0.8801\n",
      "Epoch 018 | Loss: 0.6550 | Val AUROC: 0.8818\n",
      "Epoch 019 | Loss: 0.6366 | Val AUROC: 0.8834\n",
      "Epoch 020 | Loss: 0.6127 | Val AUROC: 0.8857\n",
      "Epoch 021 | Loss: 0.6284 | Val AUROC: 0.8846\n",
      "Epoch 022 | Loss: 0.6435 | Val AUROC: 0.8846\n",
      "Epoch 023 | Loss: 0.6589 | Val AUROC: 0.8834\n",
      "Epoch 024 | Loss: 0.5974 | Val AUROC: 0.8846\n",
      "[Fold 3] Test AUROC: 0.8504, AUPRC: 0.7722\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 001 | Loss: 1.0546 | Val AUROC: 0.5715\n",
      "Epoch 002 | Loss: 1.0322 | Val AUROC: 0.6647\n",
      "Epoch 003 | Loss: 1.0236 | Val AUROC: 0.6893\n",
      "Epoch 004 | Loss: 0.9867 | Val AUROC: 0.7353\n",
      "Epoch 005 | Loss: 0.9658 | Val AUROC: 0.7348\n",
      "Epoch 006 | Loss: 0.9417 | Val AUROC: 0.7474\n",
      "Epoch 007 | Loss: 0.8973 | Val AUROC: 0.7589\n",
      "Epoch 008 | Loss: 0.8573 | Val AUROC: 0.7688\n",
      "Epoch 009 | Loss: 0.8411 | Val AUROC: 0.7945\n",
      "Epoch 010 | Loss: 0.8354 | Val AUROC: 0.8016\n",
      "Epoch 011 | Loss: 0.7655 | Val AUROC: 0.8115\n",
      "Epoch 012 | Loss: 0.7507 | Val AUROC: 0.8132\n",
      "Epoch 013 | Loss: 0.7398 | Val AUROC: 0.8214\n",
      "Epoch 014 | Loss: 0.7332 | Val AUROC: 0.8263\n",
      "Epoch 015 | Loss: 0.6978 | Val AUROC: 0.8351\n",
      "Epoch 016 | Loss: 0.6779 | Val AUROC: 0.8400\n",
      "Epoch 017 | Loss: 0.6532 | Val AUROC: 0.8427\n",
      "Epoch 018 | Loss: 0.6926 | Val AUROC: 0.8367\n",
      "Epoch 019 | Loss: 0.6214 | Val AUROC: 0.8581\n",
      "Epoch 020 | Loss: 0.6173 | Val AUROC: 0.8636\n",
      "Epoch 021 | Loss: 0.5957 | Val AUROC: 0.8608\n",
      "Epoch 022 | Loss: 0.5500 | Val AUROC: 0.8586\n",
      "Epoch 023 | Loss: 0.5925 | Val AUROC: 0.8477\n",
      "Epoch 024 | Loss: 0.5842 | Val AUROC: 0.8460\n",
      "Epoch 025 | Loss: 0.5721 | Val AUROC: 0.8482\n",
      "Epoch 026 | Loss: 0.5641 | Val AUROC: 0.8433\n",
      "Epoch 027 | Loss: 0.5329 | Val AUROC: 0.8433\n",
      "Epoch 028 | Loss: 0.5312 | Val AUROC: 0.8482\n",
      "Epoch 029 | Loss: 0.5558 | Val AUROC: 0.8493\n",
      "Epoch 030 | Loss: 0.5278 | Val AUROC: 0.8444\n",
      "Epoch 031 | Loss: 0.5470 | Val AUROC: 0.8422\n",
      "Epoch 032 | Loss: 0.5209 | Val AUROC: 0.8389\n",
      "[Fold 4] Test AUROC: 0.8059, AUPRC: 0.6477\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 001 | Loss: 1.0291 | Val AUROC: 0.7044\n",
      "Epoch 002 | Loss: 1.0059 | Val AUROC: 0.7348\n",
      "Epoch 003 | Loss: 0.9791 | Val AUROC: 0.7714\n",
      "Epoch 004 | Loss: 0.9581 | Val AUROC: 0.7804\n",
      "Epoch 005 | Loss: 0.9264 | Val AUROC: 0.7922\n",
      "Epoch 006 | Loss: 0.9155 | Val AUROC: 0.8012\n",
      "Epoch 007 | Loss: 0.8725 | Val AUROC: 0.8029\n",
      "Epoch 008 | Loss: 0.8239 | Val AUROC: 0.8097\n",
      "Epoch 009 | Loss: 0.7937 | Val AUROC: 0.8221\n",
      "Epoch 010 | Loss: 0.7399 | Val AUROC: 0.8266\n",
      "Epoch 011 | Loss: 0.7427 | Val AUROC: 0.8350\n",
      "Epoch 012 | Loss: 0.7055 | Val AUROC: 0.8401\n",
      "Epoch 013 | Loss: 0.6860 | Val AUROC: 0.8378\n",
      "Epoch 014 | Loss: 0.6633 | Val AUROC: 0.8361\n",
      "Epoch 015 | Loss: 0.6628 | Val AUROC: 0.8187\n",
      "Epoch 016 | Loss: 0.6187 | Val AUROC: 0.8181\n",
      "Epoch 017 | Loss: 0.6009 | Val AUROC: 0.8181\n",
      "Epoch 018 | Loss: 0.5959 | Val AUROC: 0.8193\n",
      "Epoch 019 | Loss: 0.6070 | Val AUROC: 0.8215\n",
      "Epoch 020 | Loss: 0.6227 | Val AUROC: 0.8159\n",
      "Epoch 021 | Loss: 0.5379 | Val AUROC: 0.8153\n",
      "Epoch 022 | Loss: 0.5594 | Val AUROC: 0.8159\n",
      "Epoch 023 | Loss: 0.6002 | Val AUROC: 0.8119\n",
      "Epoch 024 | Loss: 0.5392 | Val AUROC: 0.8119\n",
      "[Fold 5] Test AUROC: 0.7817, AUPRC: 0.6376\n",
      "\n",
      "===== Seed 7433 ‰∫îÊäòÁªìÊûú (Bootstrap) =====\n",
      "AUROC: 0.7990 (95% CI 0.7632-0.8332)\n",
      "AUPRC: 0.6561 (95% CI 0.5978-0.7132)\n",
      "\n",
      "==============================\n",
      "üîÅ ÊµãËØïÈöèÊú∫ÁßçÂ≠ê: 9352\n",
      "==============================\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 001 | Loss: 1.0736 | Val AUROC: 0.6598\n",
      "Epoch 002 | Loss: 1.0498 | Val AUROC: 0.7826\n",
      "Epoch 003 | Loss: 1.0110 | Val AUROC: 0.8079\n",
      "Epoch 004 | Loss: 1.0100 | Val AUROC: 0.8167\n",
      "Epoch 005 | Loss: 0.9751 | Val AUROC: 0.8425\n",
      "Epoch 006 | Loss: 0.9590 | Val AUROC: 0.8478\n",
      "Epoch 007 | Loss: 0.9361 | Val AUROC: 0.8461\n",
      "Epoch 008 | Loss: 0.8671 | Val AUROC: 0.8508\n",
      "Epoch 009 | Loss: 0.8502 | Val AUROC: 0.8649\n",
      "Epoch 010 | Loss: 0.7952 | Val AUROC: 0.8678\n",
      "Epoch 011 | Loss: 0.7714 | Val AUROC: 0.8713\n",
      "Epoch 012 | Loss: 0.7269 | Val AUROC: 0.8702\n",
      "Epoch 013 | Loss: 0.7298 | Val AUROC: 0.8754\n",
      "Epoch 014 | Loss: 0.6721 | Val AUROC: 0.8707\n",
      "Epoch 015 | Loss: 0.6813 | Val AUROC: 0.8707\n",
      "Epoch 016 | Loss: 0.6728 | Val AUROC: 0.8672\n",
      "Epoch 017 | Loss: 0.7161 | Val AUROC: 0.8590\n",
      "Epoch 018 | Loss: 0.5847 | Val AUROC: 0.8602\n",
      "Epoch 019 | Loss: 0.5728 | Val AUROC: 0.8602\n",
      "Epoch 020 | Loss: 0.5995 | Val AUROC: 0.8555\n",
      "Epoch 021 | Loss: 0.5774 | Val AUROC: 0.8590\n",
      "Epoch 022 | Loss: 0.5536 | Val AUROC: 0.8584\n",
      "Epoch 023 | Loss: 0.5202 | Val AUROC: 0.8578\n",
      "Epoch 024 | Loss: 0.5923 | Val AUROC: 0.8537\n",
      "Epoch 025 | Loss: 0.5447 | Val AUROC: 0.8543\n",
      "[Fold 1] Test AUROC: 0.8065, AUPRC: 0.7190\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 001 | Loss: 1.0551 | Val AUROC: 0.6824\n",
      "Epoch 002 | Loss: 1.0328 | Val AUROC: 0.7517\n",
      "Epoch 003 | Loss: 1.0219 | Val AUROC: 0.7804\n",
      "Epoch 004 | Loss: 1.0172 | Val AUROC: 0.7765\n",
      "Epoch 005 | Loss: 0.9747 | Val AUROC: 0.7956\n",
      "Epoch 006 | Loss: 0.9244 | Val AUROC: 0.7973\n",
      "Epoch 007 | Loss: 0.8860 | Val AUROC: 0.8153\n",
      "Epoch 008 | Loss: 0.8846 | Val AUROC: 0.8232\n",
      "Epoch 009 | Loss: 0.8198 | Val AUROC: 0.8266\n",
      "Epoch 010 | Loss: 0.8124 | Val AUROC: 0.8294\n",
      "Epoch 011 | Loss: 0.8194 | Val AUROC: 0.8322\n",
      "Epoch 012 | Loss: 0.7570 | Val AUROC: 0.8339\n",
      "Epoch 013 | Loss: 0.7602 | Val AUROC: 0.8277\n",
      "Epoch 014 | Loss: 0.6690 | Val AUROC: 0.8255\n",
      "Epoch 015 | Loss: 0.6934 | Val AUROC: 0.8243\n",
      "Epoch 016 | Loss: 0.6236 | Val AUROC: 0.8288\n",
      "Epoch 017 | Loss: 0.6367 | Val AUROC: 0.8288\n",
      "Epoch 018 | Loss: 0.6312 | Val AUROC: 0.8300\n",
      "Epoch 019 | Loss: 0.6293 | Val AUROC: 0.8333\n",
      "Epoch 020 | Loss: 0.6123 | Val AUROC: 0.8243\n",
      "Epoch 021 | Loss: 0.6109 | Val AUROC: 0.8226\n",
      "Epoch 022 | Loss: 0.6192 | Val AUROC: 0.8238\n",
      "Epoch 023 | Loss: 0.5856 | Val AUROC: 0.8260\n",
      "Epoch 024 | Loss: 0.6132 | Val AUROC: 0.8277\n",
      "[Fold 2] Test AUROC: 0.7685, AUPRC: 0.6434\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 001 | Loss: 1.0545 | Val AUROC: 0.5973\n",
      "Epoch 002 | Loss: 1.0147 | Val AUROC: 0.6586\n",
      "Epoch 003 | Loss: 0.9881 | Val AUROC: 0.6586\n",
      "Epoch 004 | Loss: 0.9587 | Val AUROC: 0.7074\n",
      "Epoch 005 | Loss: 0.9336 | Val AUROC: 0.7118\n",
      "Epoch 006 | Loss: 0.8994 | Val AUROC: 0.7430\n",
      "Epoch 007 | Loss: 0.8734 | Val AUROC: 0.7397\n",
      "Epoch 008 | Loss: 0.8340 | Val AUROC: 0.7474\n",
      "Epoch 009 | Loss: 0.8207 | Val AUROC: 0.7496\n",
      "Epoch 010 | Loss: 0.7805 | Val AUROC: 0.7518\n",
      "Epoch 011 | Loss: 0.7676 | Val AUROC: 0.7562\n",
      "Epoch 012 | Loss: 0.7011 | Val AUROC: 0.7732\n",
      "Epoch 013 | Loss: 0.6674 | Val AUROC: 0.7721\n",
      "Epoch 014 | Loss: 0.7305 | Val AUROC: 0.7682\n",
      "Epoch 015 | Loss: 0.6284 | Val AUROC: 0.7660\n",
      "Epoch 016 | Loss: 0.6562 | Val AUROC: 0.7775\n",
      "Epoch 017 | Loss: 0.5821 | Val AUROC: 0.7770\n",
      "Epoch 018 | Loss: 0.6157 | Val AUROC: 0.7759\n",
      "Epoch 019 | Loss: 0.5585 | Val AUROC: 0.7803\n",
      "Epoch 020 | Loss: 0.5518 | Val AUROC: 0.7819\n",
      "Epoch 021 | Loss: 0.5582 | Val AUROC: 0.7759\n",
      "Epoch 022 | Loss: 0.5656 | Val AUROC: 0.7721\n",
      "Epoch 023 | Loss: 0.4973 | Val AUROC: 0.7764\n",
      "Epoch 024 | Loss: 0.5669 | Val AUROC: 0.7649\n",
      "Epoch 025 | Loss: 0.5287 | Val AUROC: 0.7699\n",
      "Epoch 026 | Loss: 0.5458 | Val AUROC: 0.7704\n",
      "Epoch 027 | Loss: 0.4607 | Val AUROC: 0.7781\n",
      "Epoch 028 | Loss: 0.5122 | Val AUROC: 0.7699\n",
      "Epoch 029 | Loss: 0.5934 | Val AUROC: 0.7666\n",
      "Epoch 030 | Loss: 0.4646 | Val AUROC: 0.7693\n",
      "Epoch 031 | Loss: 0.5119 | Val AUROC: 0.7770\n",
      "Epoch 032 | Loss: 0.5809 | Val AUROC: 0.7808\n",
      "[Fold 3] Test AUROC: 0.7655, AUPRC: 0.5545\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 001 | Loss: 1.0455 | Val AUROC: 0.7275\n",
      "Epoch 002 | Loss: 1.0264 | Val AUROC: 0.8024\n",
      "Epoch 003 | Loss: 1.0035 | Val AUROC: 0.8193\n",
      "Epoch 004 | Loss: 0.9741 | Val AUROC: 0.8356\n",
      "Epoch 005 | Loss: 0.9579 | Val AUROC: 0.8271\n",
      "Epoch 006 | Loss: 0.9414 | Val AUROC: 0.8333\n",
      "Epoch 007 | Loss: 0.9081 | Val AUROC: 0.8485\n",
      "Epoch 008 | Loss: 0.8711 | Val AUROC: 0.8474\n",
      "Epoch 009 | Loss: 0.8429 | Val AUROC: 0.8440\n",
      "Epoch 010 | Loss: 0.8659 | Val AUROC: 0.8463\n",
      "Epoch 011 | Loss: 0.8124 | Val AUROC: 0.8530\n",
      "Epoch 012 | Loss: 0.7888 | Val AUROC: 0.8564\n",
      "Epoch 013 | Loss: 0.7545 | Val AUROC: 0.8626\n",
      "Epoch 014 | Loss: 0.7524 | Val AUROC: 0.8643\n",
      "Epoch 015 | Loss: 0.7400 | Val AUROC: 0.8609\n",
      "Epoch 016 | Loss: 0.6838 | Val AUROC: 0.8587\n",
      "Epoch 017 | Loss: 0.6966 | Val AUROC: 0.8564\n",
      "Epoch 018 | Loss: 0.7403 | Val AUROC: 0.8592\n",
      "Epoch 019 | Loss: 0.6656 | Val AUROC: 0.8553\n",
      "Epoch 020 | Loss: 0.6820 | Val AUROC: 0.8530\n",
      "Epoch 021 | Loss: 0.6629 | Val AUROC: 0.8604\n",
      "Epoch 022 | Loss: 0.6589 | Val AUROC: 0.8587\n",
      "Epoch 023 | Loss: 0.6259 | Val AUROC: 0.8564\n",
      "Epoch 024 | Loss: 0.6369 | Val AUROC: 0.8564\n",
      "Epoch 025 | Loss: 0.6439 | Val AUROC: 0.8592\n",
      "Epoch 026 | Loss: 0.6453 | Val AUROC: 0.8564\n",
      "[Fold 4] Test AUROC: 0.8355, AUPRC: 0.7126\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 001 | Loss: 1.0379 | Val AUROC: 0.6986\n",
      "Epoch 002 | Loss: 1.0044 | Val AUROC: 0.7310\n",
      "Epoch 003 | Loss: 0.9950 | Val AUROC: 0.7688\n",
      "Epoch 004 | Loss: 0.9752 | Val AUROC: 0.7770\n",
      "Epoch 005 | Loss: 0.9530 | Val AUROC: 0.7973\n",
      "Epoch 006 | Loss: 0.9056 | Val AUROC: 0.7956\n",
      "Epoch 007 | Loss: 0.8497 | Val AUROC: 0.7929\n",
      "Epoch 008 | Loss: 0.8352 | Val AUROC: 0.7912\n",
      "Epoch 009 | Loss: 0.8218 | Val AUROC: 0.7912\n",
      "Epoch 010 | Loss: 0.7759 | Val AUROC: 0.7890\n",
      "Epoch 011 | Loss: 0.7710 | Val AUROC: 0.7934\n",
      "Epoch 012 | Loss: 0.7439 | Val AUROC: 0.7918\n",
      "Epoch 013 | Loss: 0.7333 | Val AUROC: 0.7901\n",
      "Epoch 014 | Loss: 0.7574 | Val AUROC: 0.7890\n",
      "Epoch 015 | Loss: 0.7405 | Val AUROC: 0.7923\n",
      "Epoch 016 | Loss: 0.7301 | Val AUROC: 0.7901\n",
      "Epoch 017 | Loss: 0.7043 | Val AUROC: 0.7912\n",
      "[Fold 5] Test AUROC: 0.7667, AUPRC: 0.6094\n",
      "\n",
      "===== Seed 9352 ‰∫îÊäòÁªìÊûú (Bootstrap) =====\n",
      "AUROC: 0.7700 (95% CI 0.7326-0.8056)\n",
      "AUPRC: 0.6257 (95% CI 0.5644-0.6811)\n",
      "\n",
      "==============================\n",
      "üîÅ ÊµãËØïÈöèÊú∫ÁßçÂ≠ê: 5628\n",
      "==============================\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 001 | Loss: 1.0482 | Val AUROC: 0.6747\n",
      "Epoch 002 | Loss: 0.9908 | Val AUROC: 0.7546\n",
      "Epoch 003 | Loss: 0.9868 | Val AUROC: 0.7694\n",
      "Epoch 004 | Loss: 0.9482 | Val AUROC: 0.7643\n",
      "Epoch 005 | Loss: 0.9416 | Val AUROC: 0.7591\n",
      "Epoch 006 | Loss: 0.8998 | Val AUROC: 0.7546\n",
      "Epoch 007 | Loss: 0.8855 | Val AUROC: 0.7586\n",
      "Epoch 008 | Loss: 0.8723 | Val AUROC: 0.7711\n",
      "Epoch 009 | Loss: 0.8632 | Val AUROC: 0.7757\n",
      "Epoch 010 | Loss: 0.8175 | Val AUROC: 0.7728\n",
      "Epoch 011 | Loss: 0.8343 | Val AUROC: 0.7745\n",
      "Epoch 012 | Loss: 0.8186 | Val AUROC: 0.7734\n",
      "Epoch 013 | Loss: 0.7654 | Val AUROC: 0.7820\n",
      "Epoch 014 | Loss: 0.7854 | Val AUROC: 0.7808\n",
      "Epoch 015 | Loss: 0.7583 | Val AUROC: 0.7860\n",
      "Epoch 016 | Loss: 0.7275 | Val AUROC: 0.7785\n",
      "Epoch 017 | Loss: 0.7782 | Val AUROC: 0.7757\n",
      "Epoch 018 | Loss: 0.7416 | Val AUROC: 0.7774\n",
      "Epoch 019 | Loss: 0.7133 | Val AUROC: 0.7785\n",
      "Epoch 020 | Loss: 0.7138 | Val AUROC: 0.7820\n",
      "Epoch 021 | Loss: 0.6989 | Val AUROC: 0.7814\n",
      "Epoch 022 | Loss: 0.6968 | Val AUROC: 0.7837\n",
      "Epoch 023 | Loss: 0.6822 | Val AUROC: 0.7837\n",
      "Epoch 024 | Loss: 0.6714 | Val AUROC: 0.7917\n",
      "Epoch 025 | Loss: 0.7072 | Val AUROC: 0.7865\n",
      "Epoch 026 | Loss: 0.6779 | Val AUROC: 0.7877\n",
      "Epoch 027 | Loss: 0.6944 | Val AUROC: 0.7860\n",
      "Epoch 028 | Loss: 0.6727 | Val AUROC: 0.7888\n",
      "Epoch 029 | Loss: 0.6650 | Val AUROC: 0.7894\n",
      "Epoch 030 | Loss: 0.6710 | Val AUROC: 0.7905\n",
      "Epoch 031 | Loss: 0.6952 | Val AUROC: 0.7877\n",
      "Epoch 032 | Loss: 0.6458 | Val AUROC: 0.7894\n",
      "Epoch 033 | Loss: 0.7064 | Val AUROC: 0.7911\n",
      "Epoch 034 | Loss: 0.6963 | Val AUROC: 0.7894\n",
      "Epoch 035 | Loss: 0.6584 | Val AUROC: 0.7939\n",
      "Epoch 036 | Loss: 0.6464 | Val AUROC: 0.7900\n",
      "Epoch 037 | Loss: 0.6937 | Val AUROC: 0.7917\n",
      "Epoch 038 | Loss: 0.6820 | Val AUROC: 0.7917\n",
      "Epoch 039 | Loss: 0.6825 | Val AUROC: 0.7888\n",
      "Epoch 040 | Loss: 0.6612 | Val AUROC: 0.7877\n",
      "Epoch 041 | Loss: 0.7326 | Val AUROC: 0.7922\n",
      "Epoch 042 | Loss: 0.6652 | Val AUROC: 0.7882\n",
      "Epoch 043 | Loss: 0.6877 | Val AUROC: 0.7888\n",
      "Epoch 044 | Loss: 0.6611 | Val AUROC: 0.7900\n",
      "Epoch 045 | Loss: 0.7089 | Val AUROC: 0.7831\n",
      "Epoch 046 | Loss: 0.6785 | Val AUROC: 0.7928\n",
      "Epoch 047 | Loss: 0.7019 | Val AUROC: 0.7894\n",
      "[Fold 1] Test AUROC: 0.8350, AUPRC: 0.7208\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 001 | Loss: 1.0397 | Val AUROC: 0.5670\n",
      "Epoch 002 | Loss: 1.0097 | Val AUROC: 0.6650\n",
      "Epoch 003 | Loss: 0.9916 | Val AUROC: 0.7359\n",
      "Epoch 004 | Loss: 0.9560 | Val AUROC: 0.7568\n",
      "Epoch 005 | Loss: 0.9201 | Val AUROC: 0.7720\n",
      "Epoch 006 | Loss: 0.8848 | Val AUROC: 0.8012\n",
      "Epoch 007 | Loss: 0.8598 | Val AUROC: 0.8209\n",
      "Epoch 008 | Loss: 0.8409 | Val AUROC: 0.8328\n",
      "Epoch 009 | Loss: 0.7945 | Val AUROC: 0.8508\n",
      "Epoch 010 | Loss: 0.7844 | Val AUROC: 0.8502\n",
      "Epoch 011 | Loss: 0.7463 | Val AUROC: 0.8446\n",
      "Epoch 012 | Loss: 0.7182 | Val AUROC: 0.8457\n",
      "Epoch 013 | Loss: 0.6939 | Val AUROC: 0.8514\n",
      "Epoch 014 | Loss: 0.6960 | Val AUROC: 0.8457\n",
      "Epoch 015 | Loss: 0.6721 | Val AUROC: 0.8497\n",
      "Epoch 016 | Loss: 0.6747 | Val AUROC: 0.8598\n",
      "Epoch 017 | Loss: 0.6736 | Val AUROC: 0.8604\n",
      "Epoch 018 | Loss: 0.5814 | Val AUROC: 0.8547\n",
      "Epoch 019 | Loss: 0.6066 | Val AUROC: 0.8502\n",
      "Epoch 020 | Loss: 0.6524 | Val AUROC: 0.8564\n",
      "Epoch 021 | Loss: 0.5734 | Val AUROC: 0.8547\n",
      "Epoch 022 | Loss: 0.5807 | Val AUROC: 0.8547\n",
      "Epoch 023 | Loss: 0.5610 | Val AUROC: 0.8468\n",
      "Epoch 024 | Loss: 0.5291 | Val AUROC: 0.8530\n",
      "Epoch 025 | Loss: 0.5569 | Val AUROC: 0.8525\n",
      "Epoch 026 | Loss: 0.4932 | Val AUROC: 0.8547\n",
      "Epoch 027 | Loss: 0.4973 | Val AUROC: 0.8497\n",
      "Epoch 028 | Loss: 0.5098 | Val AUROC: 0.8514\n",
      "Epoch 029 | Loss: 0.5176 | Val AUROC: 0.8553\n",
      "[Fold 2] Test AUROC: 0.7882, AUPRC: 0.6417\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 001 | Loss: 1.0570 | Val AUROC: 0.6435\n",
      "Epoch 002 | Loss: 1.0437 | Val AUROC: 0.6939\n",
      "Epoch 003 | Loss: 1.0043 | Val AUROC: 0.7055\n",
      "Epoch 004 | Loss: 0.9972 | Val AUROC: 0.7258\n",
      "Epoch 005 | Loss: 0.9543 | Val AUROC: 0.7432\n",
      "Epoch 006 | Loss: 0.9060 | Val AUROC: 0.7420\n",
      "Epoch 007 | Loss: 0.8747 | Val AUROC: 0.7472\n",
      "Epoch 008 | Loss: 0.8144 | Val AUROC: 0.7438\n",
      "Epoch 009 | Loss: 0.8331 | Val AUROC: 0.7554\n",
      "Epoch 010 | Loss: 0.7849 | Val AUROC: 0.7635\n",
      "Epoch 011 | Loss: 0.7265 | Val AUROC: 0.7652\n",
      "Epoch 012 | Loss: 0.7541 | Val AUROC: 0.7704\n",
      "Epoch 013 | Loss: 0.6594 | Val AUROC: 0.7606\n",
      "Epoch 014 | Loss: 0.7002 | Val AUROC: 0.7612\n",
      "Epoch 015 | Loss: 0.6576 | Val AUROC: 0.7629\n",
      "Epoch 016 | Loss: 0.6683 | Val AUROC: 0.7583\n",
      "Epoch 017 | Loss: 0.6656 | Val AUROC: 0.7617\n",
      "Epoch 018 | Loss: 0.6115 | Val AUROC: 0.7675\n",
      "Epoch 019 | Loss: 0.6532 | Val AUROC: 0.7699\n",
      "Epoch 020 | Loss: 0.5975 | Val AUROC: 0.7739\n",
      "Epoch 021 | Loss: 0.6509 | Val AUROC: 0.7739\n",
      "Epoch 022 | Loss: 0.6208 | Val AUROC: 0.7797\n",
      "Epoch 023 | Loss: 0.6319 | Val AUROC: 0.7791\n",
      "Epoch 024 | Loss: 0.6393 | Val AUROC: 0.7820\n",
      "Epoch 025 | Loss: 0.5995 | Val AUROC: 0.7803\n",
      "Epoch 026 | Loss: 0.5802 | Val AUROC: 0.7768\n",
      "Epoch 027 | Loss: 0.5591 | Val AUROC: 0.7774\n",
      "Epoch 028 | Loss: 0.5399 | Val AUROC: 0.7739\n",
      "Epoch 029 | Loss: 0.5709 | Val AUROC: 0.7762\n",
      "Epoch 030 | Loss: 0.5607 | Val AUROC: 0.7762\n",
      "Epoch 031 | Loss: 0.5804 | Val AUROC: 0.7803\n",
      "Epoch 032 | Loss: 0.5572 | Val AUROC: 0.7762\n",
      "Epoch 033 | Loss: 0.5247 | Val AUROC: 0.7786\n",
      "Epoch 034 | Loss: 0.6106 | Val AUROC: 0.7751\n",
      "Epoch 035 | Loss: 0.5585 | Val AUROC: 0.7762\n",
      "Epoch 036 | Loss: 0.5679 | Val AUROC: 0.7757\n",
      "[Fold 3] Test AUROC: 0.8024, AUPRC: 0.6711\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 001 | Loss: 1.0622 | Val AUROC: 0.6225\n",
      "Epoch 002 | Loss: 1.0093 | Val AUROC: 0.7529\n",
      "Epoch 003 | Loss: 1.0062 | Val AUROC: 0.7967\n",
      "Epoch 004 | Loss: 0.9920 | Val AUROC: 0.7995\n",
      "Epoch 005 | Loss: 0.9502 | Val AUROC: 0.8159\n",
      "Epoch 006 | Loss: 0.9145 | Val AUROC: 0.8159\n",
      "Epoch 007 | Loss: 0.8682 | Val AUROC: 0.8203\n",
      "Epoch 008 | Loss: 0.8157 | Val AUROC: 0.8203\n",
      "Epoch 009 | Loss: 0.7971 | Val AUROC: 0.8351\n",
      "Epoch 010 | Loss: 0.7815 | Val AUROC: 0.8373\n",
      "Epoch 011 | Loss: 0.7794 | Val AUROC: 0.8395\n",
      "Epoch 012 | Loss: 0.7454 | Val AUROC: 0.8416\n",
      "Epoch 013 | Loss: 0.7232 | Val AUROC: 0.8411\n",
      "Epoch 014 | Loss: 0.7033 | Val AUROC: 0.8373\n",
      "Epoch 015 | Loss: 0.6729 | Val AUROC: 0.8427\n",
      "Epoch 016 | Loss: 0.6495 | Val AUROC: 0.8351\n",
      "Epoch 017 | Loss: 0.6853 | Val AUROC: 0.8334\n",
      "Epoch 018 | Loss: 0.5958 | Val AUROC: 0.8274\n",
      "Epoch 019 | Loss: 0.6274 | Val AUROC: 0.8296\n",
      "Epoch 020 | Loss: 0.6106 | Val AUROC: 0.8318\n",
      "Epoch 021 | Loss: 0.5631 | Val AUROC: 0.8241\n",
      "Epoch 022 | Loss: 0.5887 | Val AUROC: 0.8230\n",
      "Epoch 023 | Loss: 0.5846 | Val AUROC: 0.8214\n",
      "Epoch 024 | Loss: 0.5667 | Val AUROC: 0.8225\n",
      "Epoch 025 | Loss: 0.5549 | Val AUROC: 0.8181\n",
      "Epoch 026 | Loss: 0.5718 | Val AUROC: 0.8241\n",
      "Epoch 027 | Loss: 0.5457 | Val AUROC: 0.8241\n",
      "[Fold 4] Test AUROC: 0.7979, AUPRC: 0.6628\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 001 | Loss: 1.0406 | Val AUROC: 0.4764\n",
      "Epoch 002 | Loss: 1.0191 | Val AUROC: 0.6075\n",
      "Epoch 003 | Loss: 0.9887 | Val AUROC: 0.6571\n",
      "Epoch 004 | Loss: 0.9744 | Val AUROC: 0.6813\n",
      "Epoch 005 | Loss: 0.9393 | Val AUROC: 0.6852\n",
      "Epoch 006 | Loss: 0.9187 | Val AUROC: 0.6976\n",
      "Epoch 007 | Loss: 0.8810 | Val AUROC: 0.7050\n",
      "Epoch 008 | Loss: 0.8682 | Val AUROC: 0.7100\n",
      "Epoch 009 | Loss: 0.8176 | Val AUROC: 0.7179\n",
      "Epoch 010 | Loss: 0.7782 | Val AUROC: 0.7202\n",
      "Epoch 011 | Loss: 0.7452 | Val AUROC: 0.7286\n",
      "Epoch 012 | Loss: 0.7485 | Val AUROC: 0.7354\n",
      "Epoch 013 | Loss: 0.7389 | Val AUROC: 0.7348\n",
      "Epoch 014 | Loss: 0.7888 | Val AUROC: 0.7359\n",
      "Epoch 015 | Loss: 0.6549 | Val AUROC: 0.7444\n",
      "Epoch 016 | Loss: 0.6819 | Val AUROC: 0.7506\n",
      "Epoch 017 | Loss: 0.6970 | Val AUROC: 0.7562\n",
      "Epoch 018 | Loss: 0.6536 | Val AUROC: 0.7523\n",
      "Epoch 019 | Loss: 0.6781 | Val AUROC: 0.7506\n",
      "Epoch 020 | Loss: 0.6410 | Val AUROC: 0.7545\n",
      "Epoch 021 | Loss: 0.6224 | Val AUROC: 0.7523\n",
      "Epoch 022 | Loss: 0.5879 | Val AUROC: 0.7528\n",
      "Epoch 023 | Loss: 0.6023 | Val AUROC: 0.7562\n",
      "Epoch 024 | Loss: 0.5732 | Val AUROC: 0.7551\n",
      "Epoch 025 | Loss: 0.6013 | Val AUROC: 0.7523\n",
      "Epoch 026 | Loss: 0.5477 | Val AUROC: 0.7523\n",
      "Epoch 027 | Loss: 0.5523 | Val AUROC: 0.7534\n",
      "Epoch 028 | Loss: 0.5685 | Val AUROC: 0.7545\n",
      "Epoch 029 | Loss: 0.5788 | Val AUROC: 0.7551\n",
      "[Fold 5] Test AUROC: 0.8555, AUPRC: 0.7471\n",
      "\n",
      "===== Seed 5628 ‰∫îÊäòÁªìÊûú (Bootstrap) =====\n",
      "AUROC: 0.8137 (95% CI 0.7809-0.8453)\n",
      "AUPRC: 0.6837 (95% CI 0.6290-0.7359)\n",
      "\n",
      "üéØ ËææÂà∞ÁõÆÊ†á AUROC=0.81, ÂÅúÊ≠¢Âæ™ÁéØÔºÅ(Seed=5628)\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn import metrics\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "base_save_path = \"/home/mailiyi/Poisoning_Prediction/DNN/predict_non-recovery_valid_test_5cv/\"\n",
    "os.makedirs(base_save_path, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "X_tensor = torch.tensor(datax_encoded.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(datay.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# =============== 4. DNN model ===============\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# =============== 5. Bootstrap function ===============\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "# =============== 6. Round robin testing different random seeds ===============\n",
    "target_auroc = 0.81\n",
    "max_seed_trials = 100  \n",
    "found = False\n",
    "\n",
    "for seed in random.sample(range(1, 10000), max_seed_trials):\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"üîÅ : {seed}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    save_path = os.path.join(base_save_path, f\"seed_{seed}\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    set_seed(seed)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    fold = 1\n",
    "    auroc_list, auprc_list = [], []\n",
    "    all_results = []\n",
    "\n",
    "    for train_val_index, test_index in kf.split(X_tensor):\n",
    "        print(f\"\\n===== Fold {fold} =====\")\n",
    "        set_seed(seed + fold)\n",
    "\n",
    "        X_train_val, X_test = X_tensor[train_val_index], X_tensor[test_index]\n",
    "        y_train_val, y_test = y_tensor[train_val_index], y_tensor[test_index]\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val, test_size=1/8, random_state=seed + fold, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        num_pos = (y_train == 1).sum().item()\n",
    "        num_neg = (y_train == 0).sum().item()\n",
    "        pos_weight = torch.tensor(num_neg / num_pos, dtype=torch.float32).to(device)\n",
    "\n",
    "        # DataLoader\n",
    "        def worker_init_fn(worker_id):\n",
    "            np.random.seed(seed + worker_id)\n",
    "            random.seed(seed + worker_id)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(X_train, y_train),\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            worker_init_fn=worker_init_fn\n",
    "        )\n",
    "\n",
    "        model = DNN(input_dim=X_tensor.shape[1]).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=5e-4)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=3\n",
    "        )\n",
    "\n",
    "        # Early stopping\n",
    "        patience = 12\n",
    "        best_auroc = 0\n",
    "        wait = 0\n",
    "        best_model_path = os.path.join(save_path, f\"fold{fold}_best_model.pt\")\n",
    "\n",
    "        # =============== train ===============\n",
    "        for epoch in range(100):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                logits = model(X_val.to(device)).squeeze()\n",
    "                y_pred_prob = torch.sigmoid(logits).cpu().numpy()\n",
    "                y_true = y_val.squeeze().cpu().numpy()\n",
    "                auroc_val = roc_auc_score(y_true, y_pred_prob)\n",
    "            scheduler.step(auroc_val)\n",
    "            print(f\"Epoch {epoch+1:03d} | Loss: {avg_loss:.4f} | Val AUROC: {auroc_val:.4f}\")\n",
    "\n",
    "            if auroc_val > best_auroc:\n",
    "                best_auroc = auroc_val\n",
    "                wait = 0\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    break\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(X_test.to(device)).squeeze()\n",
    "            y_pred_prob = torch.sigmoid(logits).cpu().numpy()\n",
    "            y_true = y_test.squeeze().cpu().numpy()\n",
    "            auroc = roc_auc_score(y_true, y_pred_prob)\n",
    "            auprc = average_precision_score(y_true, y_pred_prob)\n",
    "            auroc_list.append(auroc)\n",
    "            auprc_list.append(auprc)\n",
    "\n",
    "            print(f\"[Fold {fold}] Test AUROC: {auroc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "\n",
    "            result_df = pd.DataFrame({\"y_test\": y_true, \"y_pred\": y_pred_prob})\n",
    "            result_df.to_csv(os.path.join(save_path, f\"fold{fold}_results.csv\"), index=False)\n",
    "            all_results.append(result_df)\n",
    "        fold += 1\n",
    "        \n",
    "    all_results_df = pd.concat(all_results, axis=0).reset_index(drop=True)\n",
    "    y_all_true = all_results_df[\"y_test\"].values\n",
    "    y_all_pred = all_results_df[\"y_pred\"].values\n",
    "\n",
    "    mean_auroc, auc_lower, auc_upper = bootstrap_metric_ci(y_all_true, y_all_pred, metrics.roc_auc_score)\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(y_all_true, y_all_pred, metrics.average_precision_score)\n",
    "\n",
    "    print(f\"AUROC: {mean_auroc:.4f} (95% CI {auc_lower:.4f}-{auc_upper:.4f})\")\n",
    "    print(f\"AUPRC: {mean_auprc:.4f} (95% CI {auprc_lower:.4f}-{auprc_upper:.4f})\")\n",
    "\n",
    "    all_results_df.to_csv(os.path.join(save_path, \"all_folds_results.csv\"), index=False)\n",
    "\n",
    "    if mean_auroc >= target_auroc:\n",
    "        print(f\"\\nüéØ AUROC={target_auroc}, (Seed={seed})\")\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    print(\"\\n‚ö†Ô∏è No random seeds found with AUROC ‚â• 0.81, increase max_seed_trials or adjust model parameters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05978483",
   "metadata": {},
   "source": [
    "## No pos_weight specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1e4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed fixed as 5628\n",
      "Using device: cuda\n",
      "\n",
      "===== Fold 1 =====\n",
      "Random seed fixed as 5629\n",
      "Epoch 001 | Loss: 0.6516 | Val AUROC: 0.6256 | LR=0.000500\n",
      "Epoch 002 | Loss: 0.5865 | Val AUROC: 0.7072 | LR=0.000500\n",
      "Epoch 003 | Loss: 0.5677 | Val AUROC: 0.7637 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.5353 | Val AUROC: 0.7728 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.5341 | Val AUROC: 0.7808 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.4935 | Val AUROC: 0.7808 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.4889 | Val AUROC: 0.7774 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.4702 | Val AUROC: 0.7751 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.4578 | Val AUROC: 0.7797 | LR=0.000250\n",
      "Epoch 010 | Loss: 0.4265 | Val AUROC: 0.7803 | LR=0.000250\n",
      "Epoch 011 | Loss: 0.4389 | Val AUROC: 0.7791 | LR=0.000250\n",
      "Epoch 012 | Loss: 0.4195 | Val AUROC: 0.7785 | LR=0.000250\n",
      "Epoch 013 | Loss: 0.4024 | Val AUROC: 0.7814 | LR=0.000250\n",
      "Epoch 014 | Loss: 0.4012 | Val AUROC: 0.7791 | LR=0.000250\n",
      "Epoch 015 | Loss: 0.4012 | Val AUROC: 0.7768 | LR=0.000250\n",
      "Epoch 016 | Loss: 0.3812 | Val AUROC: 0.7740 | LR=0.000250\n",
      "Epoch 017 | Loss: 0.4128 | Val AUROC: 0.7763 | LR=0.000125\n",
      "Epoch 018 | Loss: 0.3998 | Val AUROC: 0.7780 | LR=0.000125\n",
      "Epoch 019 | Loss: 0.3814 | Val AUROC: 0.7763 | LR=0.000125\n",
      "Epoch 020 | Loss: 0.3744 | Val AUROC: 0.7814 | LR=0.000125\n",
      "Epoch 021 | Loss: 0.3768 | Val AUROC: 0.7797 | LR=0.000063\n",
      "Epoch 022 | Loss: 0.3661 | Val AUROC: 0.7785 | LR=0.000063\n",
      "Epoch 023 | Loss: 0.3673 | Val AUROC: 0.7785 | LR=0.000063\n",
      "Epoch 024 | Loss: 0.3787 | Val AUROC: 0.7837 | LR=0.000063\n",
      "Epoch 025 | Loss: 0.3855 | Val AUROC: 0.7774 | LR=0.000063\n",
      "Epoch 026 | Loss: 0.3611 | Val AUROC: 0.7825 | LR=0.000063\n",
      "Epoch 027 | Loss: 0.3865 | Val AUROC: 0.7763 | LR=0.000063\n",
      "Epoch 028 | Loss: 0.3600 | Val AUROC: 0.7768 | LR=0.000031\n",
      "Epoch 029 | Loss: 0.3809 | Val AUROC: 0.7808 | LR=0.000031\n",
      "Epoch 030 | Loss: 0.3856 | Val AUROC: 0.7803 | LR=0.000031\n",
      "Epoch 031 | Loss: 0.3704 | Val AUROC: 0.7785 | LR=0.000031\n",
      "Epoch 032 | Loss: 0.3476 | Val AUROC: 0.7797 | LR=0.000016\n",
      "Epoch 033 | Loss: 0.3612 | Val AUROC: 0.7803 | LR=0.000016\n",
      "Epoch 034 | Loss: 0.3588 | Val AUROC: 0.7803 | LR=0.000016\n",
      "Epoch 035 | Loss: 0.3582 | Val AUROC: 0.7848 | LR=0.000016\n",
      "Epoch 036 | Loss: 0.3510 | Val AUROC: 0.7791 | LR=0.000016\n",
      "Epoch 037 | Loss: 0.3912 | Val AUROC: 0.7791 | LR=0.000016\n",
      "Epoch 038 | Loss: 0.3716 | Val AUROC: 0.7808 | LR=0.000016\n",
      "Epoch 039 | Loss: 0.3771 | Val AUROC: 0.7763 | LR=0.000008\n",
      "Epoch 040 | Loss: 0.3552 | Val AUROC: 0.7808 | LR=0.000008\n",
      "Epoch 041 | Loss: 0.3946 | Val AUROC: 0.7791 | LR=0.000008\n",
      "Epoch 042 | Loss: 0.3637 | Val AUROC: 0.7785 | LR=0.000008\n",
      "Epoch 043 | Loss: 0.3721 | Val AUROC: 0.7825 | LR=0.000004\n",
      "Epoch 044 | Loss: 0.3459 | Val AUROC: 0.7797 | LR=0.000004\n",
      "Epoch 045 | Loss: 0.3921 | Val AUROC: 0.7751 | LR=0.000004\n",
      "Epoch 046 | Loss: 0.3767 | Val AUROC: 0.7825 | LR=0.000004\n",
      "Epoch 047 | Loss: 0.3831 | Val AUROC: 0.7831 | LR=0.000002\n",
      "Early stopping at epoch 47 (best Val AUROC=0.7848)\n",
      "[Fold 1] Test AUROC: 0.8239, AUPRC: 0.7221\n",
      "\n",
      "===== Fold 2 =====\n",
      "Random seed fixed as 5630\n",
      "Epoch 001 | Loss: 0.7055 | Val AUROC: 0.4645 | LR=0.000500\n",
      "Epoch 002 | Loss: 0.6400 | Val AUROC: 0.6396 | LR=0.000500\n",
      "Epoch 003 | Loss: 0.5980 | Val AUROC: 0.7511 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.5586 | Val AUROC: 0.7956 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.5356 | Val AUROC: 0.7782 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.4899 | Val AUROC: 0.7889 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.4807 | Val AUROC: 0.7945 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.4684 | Val AUROC: 0.7973 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.4353 | Val AUROC: 0.8238 | LR=0.000500\n",
      "Epoch 010 | Loss: 0.4563 | Val AUROC: 0.8322 | LR=0.000500\n",
      "Epoch 011 | Loss: 0.4146 | Val AUROC: 0.8249 | LR=0.000500\n",
      "Epoch 012 | Loss: 0.4101 | Val AUROC: 0.8288 | LR=0.000500\n",
      "Epoch 013 | Loss: 0.3847 | Val AUROC: 0.8350 | LR=0.000500\n",
      "Epoch 014 | Loss: 0.3924 | Val AUROC: 0.8423 | LR=0.000500\n",
      "Epoch 015 | Loss: 0.3693 | Val AUROC: 0.8480 | LR=0.000500\n",
      "Epoch 016 | Loss: 0.3766 | Val AUROC: 0.8457 | LR=0.000500\n",
      "Epoch 017 | Loss: 0.3757 | Val AUROC: 0.8474 | LR=0.000500\n",
      "Epoch 018 | Loss: 0.3250 | Val AUROC: 0.8440 | LR=0.000500\n",
      "Epoch 019 | Loss: 0.3407 | Val AUROC: 0.8480 | LR=0.000250\n",
      "Epoch 020 | Loss: 0.3736 | Val AUROC: 0.8485 | LR=0.000250\n",
      "Epoch 021 | Loss: 0.3313 | Val AUROC: 0.8468 | LR=0.000250\n",
      "Epoch 022 | Loss: 0.3349 | Val AUROC: 0.8446 | LR=0.000250\n",
      "Epoch 023 | Loss: 0.3132 | Val AUROC: 0.8429 | LR=0.000250\n",
      "Epoch 024 | Loss: 0.2984 | Val AUROC: 0.8468 | LR=0.000125\n",
      "Epoch 025 | Loss: 0.3225 | Val AUROC: 0.8435 | LR=0.000125\n",
      "Epoch 026 | Loss: 0.2728 | Val AUROC: 0.8440 | LR=0.000125\n",
      "Epoch 027 | Loss: 0.3089 | Val AUROC: 0.8440 | LR=0.000125\n",
      "Epoch 028 | Loss: 0.2917 | Val AUROC: 0.8463 | LR=0.000063\n",
      "Epoch 029 | Loss: 0.3052 | Val AUROC: 0.8463 | LR=0.000063\n",
      "Epoch 030 | Loss: 0.2873 | Val AUROC: 0.8418 | LR=0.000063\n",
      "Epoch 031 | Loss: 0.2987 | Val AUROC: 0.8418 | LR=0.000063\n",
      "Epoch 032 | Loss: 0.3017 | Val AUROC: 0.8423 | LR=0.000031\n",
      "Early stopping at epoch 32 (best Val AUROC=0.8485)\n",
      "[Fold 2] Test AUROC: 0.7710, AUPRC: 0.6329\n",
      "\n",
      "===== Fold 3 =====\n",
      "Random seed fixed as 5631\n",
      "Epoch 001 | Loss: 0.6549 | Val AUROC: 0.6243 | LR=0.000500\n",
      "Epoch 002 | Loss: 0.5890 | Val AUROC: 0.6586 | LR=0.000500\n",
      "Epoch 003 | Loss: 0.5440 | Val AUROC: 0.6962 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.5338 | Val AUROC: 0.7241 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.5057 | Val AUROC: 0.7426 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.4778 | Val AUROC: 0.7438 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.4517 | Val AUROC: 0.7583 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.4302 | Val AUROC: 0.7565 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.4325 | Val AUROC: 0.7612 | LR=0.000500\n",
      "Epoch 010 | Loss: 0.4049 | Val AUROC: 0.7635 | LR=0.000500\n",
      "Epoch 011 | Loss: 0.3754 | Val AUROC: 0.7716 | LR=0.000500\n",
      "Epoch 012 | Loss: 0.3980 | Val AUROC: 0.7757 | LR=0.000500\n",
      "Epoch 013 | Loss: 0.3477 | Val AUROC: 0.7658 | LR=0.000500\n",
      "Epoch 014 | Loss: 0.3600 | Val AUROC: 0.7635 | LR=0.000500\n",
      "Epoch 015 | Loss: 0.3409 | Val AUROC: 0.7623 | LR=0.000500\n",
      "Epoch 016 | Loss: 0.3527 | Val AUROC: 0.7704 | LR=0.000250\n",
      "Epoch 017 | Loss: 0.3395 | Val AUROC: 0.7681 | LR=0.000250\n",
      "Epoch 018 | Loss: 0.3148 | Val AUROC: 0.7832 | LR=0.000250\n",
      "Epoch 019 | Loss: 0.3345 | Val AUROC: 0.7826 | LR=0.000250\n",
      "Epoch 020 | Loss: 0.3185 | Val AUROC: 0.7838 | LR=0.000250\n",
      "Epoch 021 | Loss: 0.3541 | Val AUROC: 0.7803 | LR=0.000250\n",
      "Epoch 022 | Loss: 0.3229 | Val AUROC: 0.7814 | LR=0.000250\n",
      "Epoch 023 | Loss: 0.3327 | Val AUROC: 0.7826 | LR=0.000250\n",
      "Epoch 024 | Loss: 0.3459 | Val AUROC: 0.7867 | LR=0.000250\n",
      "Epoch 025 | Loss: 0.3156 | Val AUROC: 0.7797 | LR=0.000250\n",
      "Epoch 026 | Loss: 0.2926 | Val AUROC: 0.7814 | LR=0.000250\n",
      "Epoch 027 | Loss: 0.2952 | Val AUROC: 0.7884 | LR=0.000250\n",
      "Epoch 028 | Loss: 0.2944 | Val AUROC: 0.7820 | LR=0.000250\n",
      "Epoch 029 | Loss: 0.3054 | Val AUROC: 0.7872 | LR=0.000250\n",
      "Epoch 030 | Loss: 0.2872 | Val AUROC: 0.7843 | LR=0.000250\n",
      "Epoch 031 | Loss: 0.3016 | Val AUROC: 0.7913 | LR=0.000250\n",
      "Epoch 032 | Loss: 0.2873 | Val AUROC: 0.7925 | LR=0.000250\n",
      "Epoch 033 | Loss: 0.2654 | Val AUROC: 0.7884 | LR=0.000250\n",
      "Epoch 034 | Loss: 0.3058 | Val AUROC: 0.7896 | LR=0.000250\n",
      "Epoch 035 | Loss: 0.3011 | Val AUROC: 0.7983 | LR=0.000250\n",
      "Epoch 036 | Loss: 0.2879 | Val AUROC: 0.7930 | LR=0.000250\n",
      "Epoch 037 | Loss: 0.2699 | Val AUROC: 0.8000 | LR=0.000250\n",
      "Epoch 038 | Loss: 0.2556 | Val AUROC: 0.7971 | LR=0.000250\n",
      "Epoch 039 | Loss: 0.2680 | Val AUROC: 0.8006 | LR=0.000250\n",
      "Epoch 040 | Loss: 0.2624 | Val AUROC: 0.8023 | LR=0.000250\n",
      "Epoch 041 | Loss: 0.2389 | Val AUROC: 0.7959 | LR=0.000250\n",
      "Epoch 042 | Loss: 0.2844 | Val AUROC: 0.8017 | LR=0.000250\n",
      "Epoch 043 | Loss: 0.2859 | Val AUROC: 0.7936 | LR=0.000250\n",
      "Epoch 044 | Loss: 0.2755 | Val AUROC: 0.7878 | LR=0.000125\n",
      "Epoch 045 | Loss: 0.2470 | Val AUROC: 0.7867 | LR=0.000125\n",
      "Epoch 046 | Loss: 0.2735 | Val AUROC: 0.7884 | LR=0.000125\n",
      "Epoch 047 | Loss: 0.2451 | Val AUROC: 0.7855 | LR=0.000125\n",
      "Epoch 048 | Loss: 0.2882 | Val AUROC: 0.7861 | LR=0.000063\n",
      "Epoch 049 | Loss: 0.2380 | Val AUROC: 0.7954 | LR=0.000063\n",
      "Epoch 050 | Loss: 0.2539 | Val AUROC: 0.7896 | LR=0.000063\n",
      "Epoch 051 | Loss: 0.2505 | Val AUROC: 0.7913 | LR=0.000063\n",
      "Epoch 052 | Loss: 0.2507 | Val AUROC: 0.7907 | LR=0.000031\n",
      "Early stopping at epoch 52 (best Val AUROC=0.8023)\n",
      "[Fold 3] Test AUROC: 0.8011, AUPRC: 0.6639\n",
      "\n",
      "===== Fold 4 =====\n",
      "Random seed fixed as 5632\n",
      "Epoch 001 | Loss: 0.7024 | Val AUROC: 0.5879 | LR=0.000500\n",
      "Epoch 002 | Loss: 0.6201 | Val AUROC: 0.7419 | LR=0.000500\n",
      "Epoch 003 | Loss: 0.5858 | Val AUROC: 0.7792 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.5585 | Val AUROC: 0.7786 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.5189 | Val AUROC: 0.8077 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.4752 | Val AUROC: 0.8066 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.4576 | Val AUROC: 0.8055 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.4510 | Val AUROC: 0.8137 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.4207 | Val AUROC: 0.8258 | LR=0.000500\n",
      "Epoch 010 | Loss: 0.4232 | Val AUROC: 0.8230 | LR=0.000500\n",
      "Epoch 011 | Loss: 0.4322 | Val AUROC: 0.8268 | LR=0.000500\n",
      "Epoch 012 | Loss: 0.4163 | Val AUROC: 0.8301 | LR=0.000500\n",
      "Epoch 013 | Loss: 0.4016 | Val AUROC: 0.8356 | LR=0.000500\n",
      "Epoch 014 | Loss: 0.3739 | Val AUROC: 0.8318 | LR=0.000500\n",
      "Epoch 015 | Loss: 0.3721 | Val AUROC: 0.8444 | LR=0.000500\n",
      "Epoch 016 | Loss: 0.3607 | Val AUROC: 0.8367 | LR=0.000500\n",
      "Epoch 017 | Loss: 0.3798 | Val AUROC: 0.8301 | LR=0.000500\n",
      "Epoch 018 | Loss: 0.3458 | Val AUROC: 0.8279 | LR=0.000500\n",
      "Epoch 019 | Loss: 0.3370 | Val AUROC: 0.8290 | LR=0.000250\n",
      "Epoch 020 | Loss: 0.3411 | Val AUROC: 0.8345 | LR=0.000250\n",
      "Epoch 021 | Loss: 0.3178 | Val AUROC: 0.8274 | LR=0.000250\n",
      "Epoch 022 | Loss: 0.3220 | Val AUROC: 0.8274 | LR=0.000250\n",
      "Epoch 023 | Loss: 0.3241 | Val AUROC: 0.8279 | LR=0.000125\n",
      "Epoch 024 | Loss: 0.3239 | Val AUROC: 0.8307 | LR=0.000125\n",
      "Epoch 025 | Loss: 0.3195 | Val AUROC: 0.8279 | LR=0.000125\n",
      "Epoch 026 | Loss: 0.3201 | Val AUROC: 0.8290 | LR=0.000125\n",
      "Epoch 027 | Loss: 0.3008 | Val AUROC: 0.8274 | LR=0.000063\n",
      "Early stopping at epoch 27 (best Val AUROC=0.8444)\n",
      "[Fold 4] Test AUROC: 0.7955, AUPRC: 0.6531\n",
      "\n",
      "===== Fold 5 =====\n",
      "Random seed fixed as 5633\n",
      "Epoch 001 | Loss: 0.6729 | Val AUROC: 0.3941 | LR=0.000500\n",
      "Epoch 002 | Loss: 0.6140 | Val AUROC: 0.5501 | LR=0.000500\n",
      "Epoch 003 | Loss: 0.5773 | Val AUROC: 0.6633 | LR=0.000500\n",
      "Epoch 004 | Loss: 0.5558 | Val AUROC: 0.6892 | LR=0.000500\n",
      "Epoch 005 | Loss: 0.5178 | Val AUROC: 0.7021 | LR=0.000500\n",
      "Epoch 006 | Loss: 0.5087 | Val AUROC: 0.7044 | LR=0.000500\n",
      "Epoch 007 | Loss: 0.4814 | Val AUROC: 0.7111 | LR=0.000500\n",
      "Epoch 008 | Loss: 0.4650 | Val AUROC: 0.7252 | LR=0.000500\n",
      "Epoch 009 | Loss: 0.4358 | Val AUROC: 0.7275 | LR=0.000500\n",
      "Epoch 010 | Loss: 0.4259 | Val AUROC: 0.7354 | LR=0.000500\n",
      "Epoch 011 | Loss: 0.4028 | Val AUROC: 0.7455 | LR=0.000500\n",
      "Epoch 012 | Loss: 0.4000 | Val AUROC: 0.7494 | LR=0.000500\n",
      "Epoch 013 | Loss: 0.4039 | Val AUROC: 0.7466 | LR=0.000500\n",
      "Epoch 014 | Loss: 0.4152 | Val AUROC: 0.7461 | LR=0.000500\n",
      "Epoch 015 | Loss: 0.3531 | Val AUROC: 0.7539 | LR=0.000500\n",
      "Epoch 016 | Loss: 0.3612 | Val AUROC: 0.7630 | LR=0.000500\n",
      "Epoch 017 | Loss: 0.3676 | Val AUROC: 0.7618 | LR=0.000500\n",
      "Epoch 018 | Loss: 0.3608 | Val AUROC: 0.7551 | LR=0.000500\n",
      "Epoch 019 | Loss: 0.3668 | Val AUROC: 0.7613 | LR=0.000500\n",
      "Epoch 020 | Loss: 0.3590 | Val AUROC: 0.7708 | LR=0.000500\n",
      "Epoch 021 | Loss: 0.3290 | Val AUROC: 0.7725 | LR=0.000500\n",
      "Epoch 022 | Loss: 0.3153 | Val AUROC: 0.7708 | LR=0.000500\n",
      "Epoch 023 | Loss: 0.3294 | Val AUROC: 0.7697 | LR=0.000500\n",
      "Epoch 024 | Loss: 0.3023 | Val AUROC: 0.7652 | LR=0.000500\n",
      "Epoch 025 | Loss: 0.3188 | Val AUROC: 0.7630 | LR=0.000250\n",
      "Epoch 026 | Loss: 0.2933 | Val AUROC: 0.7624 | LR=0.000250\n",
      "Epoch 027 | Loss: 0.2912 | Val AUROC: 0.7708 | LR=0.000250\n",
      "Epoch 028 | Loss: 0.3041 | Val AUROC: 0.7742 | LR=0.000250\n",
      "Epoch 029 | Loss: 0.3081 | Val AUROC: 0.7675 | LR=0.000250\n",
      "Epoch 030 | Loss: 0.3113 | Val AUROC: 0.7725 | LR=0.000250\n",
      "Epoch 031 | Loss: 0.3254 | Val AUROC: 0.7765 | LR=0.000250\n",
      "Epoch 032 | Loss: 0.2706 | Val AUROC: 0.7742 | LR=0.000250\n",
      "Epoch 033 | Loss: 0.2695 | Val AUROC: 0.7731 | LR=0.000250\n",
      "Epoch 034 | Loss: 0.2964 | Val AUROC: 0.7686 | LR=0.000250\n",
      "Epoch 035 | Loss: 0.2922 | Val AUROC: 0.7770 | LR=0.000250\n",
      "Epoch 036 | Loss: 0.3095 | Val AUROC: 0.7782 | LR=0.000250\n",
      "Epoch 037 | Loss: 0.2582 | Val AUROC: 0.7798 | LR=0.000250\n",
      "Epoch 038 | Loss: 0.3002 | Val AUROC: 0.7810 | LR=0.000250\n",
      "Epoch 039 | Loss: 0.2656 | Val AUROC: 0.7798 | LR=0.000250\n",
      "Epoch 040 | Loss: 0.2556 | Val AUROC: 0.7776 | LR=0.000250\n",
      "Epoch 041 | Loss: 0.2715 | Val AUROC: 0.7776 | LR=0.000250\n",
      "Epoch 042 | Loss: 0.2583 | Val AUROC: 0.7748 | LR=0.000125\n",
      "Epoch 043 | Loss: 0.2818 | Val AUROC: 0.7793 | LR=0.000125\n",
      "Epoch 044 | Loss: 0.2961 | Val AUROC: 0.7725 | LR=0.000125\n",
      "Epoch 045 | Loss: 0.2614 | Val AUROC: 0.7782 | LR=0.000125\n",
      "Epoch 046 | Loss: 0.2301 | Val AUROC: 0.7798 | LR=0.000063\n",
      "Epoch 047 | Loss: 0.2620 | Val AUROC: 0.7759 | LR=0.000063\n",
      "Epoch 048 | Loss: 0.2767 | Val AUROC: 0.7787 | LR=0.000063\n",
      "Epoch 049 | Loss: 0.2630 | Val AUROC: 0.7782 | LR=0.000063\n",
      "Epoch 050 | Loss: 0.2524 | Val AUROC: 0.7838 | LR=0.000063\n",
      "Epoch 051 | Loss: 0.2350 | Val AUROC: 0.7815 | LR=0.000063\n",
      "Epoch 052 | Loss: 0.2565 | Val AUROC: 0.7793 | LR=0.000063\n",
      "Epoch 053 | Loss: 0.2455 | Val AUROC: 0.7776 | LR=0.000063\n",
      "Epoch 054 | Loss: 0.2526 | Val AUROC: 0.7821 | LR=0.000031\n",
      "Epoch 055 | Loss: 0.2711 | Val AUROC: 0.7843 | LR=0.000031\n",
      "Epoch 056 | Loss: 0.2603 | Val AUROC: 0.7782 | LR=0.000031\n",
      "Epoch 057 | Loss: 0.2668 | Val AUROC: 0.7815 | LR=0.000031\n",
      "Epoch 058 | Loss: 0.2621 | Val AUROC: 0.7827 | LR=0.000031\n",
      "Epoch 059 | Loss: 0.2680 | Val AUROC: 0.7877 | LR=0.000031\n",
      "Epoch 060 | Loss: 0.2236 | Val AUROC: 0.7843 | LR=0.000031\n",
      "Epoch 061 | Loss: 0.2467 | Val AUROC: 0.7855 | LR=0.000031\n",
      "Epoch 062 | Loss: 0.2935 | Val AUROC: 0.7821 | LR=0.000031\n",
      "Epoch 063 | Loss: 0.2444 | Val AUROC: 0.7815 | LR=0.000016\n",
      "Epoch 064 | Loss: 0.2547 | Val AUROC: 0.7793 | LR=0.000016\n",
      "Epoch 065 | Loss: 0.2285 | Val AUROC: 0.7855 | LR=0.000016\n",
      "Epoch 066 | Loss: 0.2364 | Val AUROC: 0.7810 | LR=0.000016\n",
      "Epoch 067 | Loss: 0.2365 | Val AUROC: 0.7821 | LR=0.000008\n",
      "Epoch 068 | Loss: 0.2557 | Val AUROC: 0.7810 | LR=0.000008\n",
      "Epoch 069 | Loss: 0.2590 | Val AUROC: 0.7877 | LR=0.000008\n",
      "Epoch 070 | Loss: 0.2545 | Val AUROC: 0.7810 | LR=0.000008\n",
      "Epoch 071 | Loss: 0.2335 | Val AUROC: 0.7827 | LR=0.000004\n",
      "Epoch 072 | Loss: 0.2491 | Val AUROC: 0.7838 | LR=0.000004\n",
      "Epoch 073 | Loss: 0.2490 | Val AUROC: 0.7843 | LR=0.000004\n",
      "Epoch 074 | Loss: 0.2293 | Val AUROC: 0.7821 | LR=0.000004\n",
      "Epoch 075 | Loss: 0.2495 | Val AUROC: 0.7832 | LR=0.000002\n",
      "Epoch 076 | Loss: 0.2372 | Val AUROC: 0.7798 | LR=0.000002\n",
      "Epoch 077 | Loss: 0.2361 | Val AUROC: 0.7815 | LR=0.000002\n",
      "Epoch 078 | Loss: 0.2287 | Val AUROC: 0.7843 | LR=0.000002\n",
      "Epoch 079 | Loss: 0.2458 | Val AUROC: 0.7787 | LR=0.000001\n",
      "Epoch 080 | Loss: 0.2492 | Val AUROC: 0.7793 | LR=0.000001\n",
      "Epoch 081 | Loss: 0.2759 | Val AUROC: 0.7810 | LR=0.000001\n",
      "Early stopping at epoch 81 (best Val AUROC=0.7877)\n",
      "[Fold 5] Test AUROC: 0.8607, AUPRC: 0.7358\n",
      "\n",
      "===== ‰∫îÊäò‰∫§ÂèâÈ™åËØÅÁªìÊûú (Bootstrap, seed=5628) =====\n",
      "AUROC: Mean = 0.8059, 95% CI = (0.7729, 0.8385)\n",
      "AUPRC: Mean = 0.6665, 95% CI = (0.6068, 0.7203)\n",
      "\n",
      "‚úÖ ÊâÄÊúâÊäòÁöÑÈ¢ÑÊµãÁªìÊûúÂ∑≤ÂêàÂπ∂‰øùÂ≠ò‰∏∫Ôºö/home/mailiyi/Poisoning_Prediction/DNN/predict_non-recovery_calibration/all_folds_results.csv\n"
     ]
    }
   ],
   "source": [
    "import torch    \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn import metrics\n",
    "\n",
    "def set_seed(seed=5628):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Random seed fixed as {seed}\")\n",
    "\n",
    "set_seed(5628)\n",
    "\n",
    "save_path = \"/home/mailiyi/Poisoning_Prediction/DNN/predict_non-recovery_calibration/\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "X_tensor = torch.tensor(datax_encoded.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(datay.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# ===================== 4. DNN model =====================\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ===================== 5. Five-fold cross-validation =====================\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=5628)\n",
    "fold = 1\n",
    "auroc_list, auprc_list = [], []\n",
    "all_results = []\n",
    "\n",
    "for train_val_index, test_index in kf.split(X_tensor):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "    set_seed(5628 + fold)\n",
    "\n",
    "    X_train_val, X_test = X_tensor[train_val_index], X_tensor[test_index]\n",
    "    y_train_val, y_test = y_tensor[train_val_index], y_tensor[test_index]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=1/8, random_state=5628 + fold, stratify=y_train_val\n",
    "    )\n",
    "\n",
    "    # DataLoader\n",
    "    def worker_init_fn(worker_id):\n",
    "        np.random.seed(5628 + worker_id)\n",
    "        random.seed(5628 + worker_id)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(X_train, y_train),\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        worker_init_fn=worker_init_fn\n",
    "    )\n",
    "\n",
    "    model = DNN(input_dim=X_tensor.shape[1]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3\n",
    "    )\n",
    "\n",
    "    # Early stopping \n",
    "    patience = 12\n",
    "    best_auroc = 0\n",
    "    wait = 0\n",
    "    best_model_path = os.path.join(save_path, f\"fold{fold}_best_model.pt\")\n",
    "\n",
    "    # ===================== 6. train =====================\n",
    "    max_epochs = 100\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(X_val.to(device)).squeeze()\n",
    "            y_pred_prob = torch.sigmoid(logits).cpu().numpy()\n",
    "            y_true = y_val.squeeze().cpu().numpy()\n",
    "            auroc_val = roc_auc_score(y_true, y_pred_prob)\n",
    "\n",
    "        scheduler.step(auroc_val)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1:03d} | Loss: {avg_loss:.4f} | Val AUROC: {auroc_val:.4f} | LR={current_lr:.6f}\")\n",
    "        # Early stopping\n",
    "        if auroc_val > best_auroc:\n",
    "            best_auroc = auroc_val\n",
    "            wait = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1} (best Val AUROC={best_auroc:.4f})\")\n",
    "                break\n",
    "\n",
    "    # ===================== 7. Test Set Evaluation =====================\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_test.to(device)).squeeze()\n",
    "        y_pred_prob = torch.sigmoid(logits).cpu().numpy()\n",
    "        y_true = y_test.squeeze().cpu().numpy()\n",
    "        auroc = roc_auc_score(y_true, y_pred_prob)\n",
    "        auprc = average_precision_score(y_true, y_pred_prob)\n",
    "        auroc_list.append(auroc)\n",
    "        auprc_list.append(auprc)\n",
    "        print(f\"[Fold {fold}] Test AUROC: {auroc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "        result_df = pd.DataFrame({\"y_test\": y_true, \"y_pred\": y_pred_prob})\n",
    "        result_df.to_csv(os.path.join(save_path, f\"fold{fold}_results.csv\"), index=False)\n",
    "        all_results.append(result_df)\n",
    "    fold += 1\n",
    "\n",
    "# ===================== 8. BootstrapÔºàseed=5628Ôºâ =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=5628):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "all_results_df = pd.concat(all_results, axis=0).reset_index(drop=True)\n",
    "y_all_true = all_results_df[\"y_test\"].values\n",
    "y_all_pred = all_results_df[\"y_pred\"].values\n",
    "\n",
    "mean_auroc, auc_lower, auc_upper = bootstrap_metric_ci(y_all_true, y_all_pred, metrics.roc_auc_score)\n",
    "mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(y_all_true, y_all_pred, metrics.average_precision_score)\n",
    "\n",
    "print(f\"AUROC: Mean = {mean_auroc:.4f}, 95% CI = ({auc_lower:.4f}, {auc_upper:.4f})\")\n",
    "print(f\"AUPRC: Mean = {mean_auprc:.4f}, 95% CI = ({auprc_lower:.4f}, {auprc_upper:.4f})\")\n",
    "\n",
    "all_results_path = os.path.join(save_path, \"all_folds_results.csv\")\n",
    "all_results_df.to_csv(all_results_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930be63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
