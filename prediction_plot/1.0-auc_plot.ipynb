{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d200ec4",
   "metadata": {},
   "source": [
    "## Cohort 1 (Survival vs. Death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d280ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "title_num = 'a1'\n",
    "\n",
    "# =========================================================\n",
    "# Calculate ROC curve + confidence interval\n",
    "# =========================================================\n",
    "def get_roc_CI_curve(y_true, y_pred, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    mean_fpr = np.linspace(0, 1, 2000)\n",
    "\n",
    "    bootstrapped_scores = []\n",
    "    tprs = []\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true.iloc[indices])) < 2:\n",
    "            continue\n",
    "        y_true_boot = y_true.iloc[indices]\n",
    "        y_pred_boot = y_pred.iloc[indices]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true_boot, y_pred_boot)\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        bootstrapped_scores.append(auc(fpr, tpr))\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    tprs_lower = np.percentile(tprs, 2.5, axis=0)\n",
    "    tprs_upper = np.percentile(tprs, 97.5, axis=0)\n",
    "    mean_auc = np.mean(bootstrapped_scores)\n",
    "    ci_lower = np.percentile(bootstrapped_scores, 2.5)\n",
    "    ci_upper = np.percentile(bootstrapped_scores, 97.5)\n",
    "\n",
    "    return mean_fpr, mean_tpr, tprs_lower, tprs_upper, mean_auc, ci_lower, ci_upper\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "#  parameter defines\n",
    "# =========================================================\n",
    "\n",
    "colors = [\"#E27916\", \"#CF6A84\", \"#5B8FF9\", \"#7ECF4A\", \"#9B59B6\",\"#E1C542\"]\n",
    "models = [\n",
    "          'catboost',\n",
    "          'xgboost',\n",
    "          'randomforest',\n",
    "          'DNN',\n",
    "          'LSTM',\n",
    "          'lr',\n",
    "          ]\n",
    "labels = [\n",
    "          'CatBoost',\n",
    "          'XGBoost',\n",
    "          'RF',\n",
    "          'DNN', \n",
    "          'LSTM',\n",
    "          'LR',\n",
    "          ]\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# drew the ROC curve\n",
    "# =========================================================\n",
    "plt.figure(figsize=(5, 5), dpi=300)\n",
    "# plt.figure(figsize=(5, 5))\n",
    "\n",
    "for model, color, label in zip(models, colors, labels):\n",
    "    # file = os.path.join(search_path, model, 'predict_death_valid_test', 'all_folds_results.csv')\n",
    "    if model == 'DNN':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_death_valid_test_5cv', 'all_folds_results.csv')\n",
    "    elif model == 'LSTM':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_death_valid_test_5cv', 'all_folds_results.csv')\n",
    "    elif model == 'catboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death/{model}_gridsearch_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'depth_5_iterations_200_learning_rate_0.05', 'all_folds_results.csv')  \n",
    "    elif model == 'xgboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death/{model}_gridsearch_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'learning_rate_0.05_max_depth_5_n_estimators_200', 'all_folds_results.csv')\n",
    "    elif model == 'randomforest':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death/{model}_gridsearch_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'max_depth_5_n_estimators_200', 'all_folds_results.csv')\n",
    "    elif model == 'lr':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death/{model}_valid_test_5cv'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"⚠️ 未找到文件：{file}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"✅ 读取文件：{file}，共 {len(df)} 条记录\")\n",
    "    if not {'y_test', 'y_pred'}.issubset(df.columns):\n",
    "        raise ValueError(f\"{file} 缺少 'y_test' 或 'y_pred' 列\")\n",
    "\n",
    "    # ROC + CI\n",
    "    mean_fpr, mean_tpr, tprs_lower, tprs_upper, mean_auc, ci_lower, ci_upper = get_roc_CI_curve(\n",
    "        df['y_test'], df['y_pred']\n",
    "    )\n",
    "\n",
    "    # plot ROC curve\n",
    "    plt.plot(mean_fpr, mean_tpr, color=color, lw=2,\n",
    "             label=f\"{label}: {mean_auc:.3f} ({ci_lower:.3f}-{ci_upper:.3f})\")\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=color, alpha=0.15)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "\n",
    "lg = plt.legend(loc='lower right', handlelength=1.0, fontsize=10, title='AUROC (95% CI)')\n",
    "lg.get_title().set_fontsize(11)\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "plt.title(f'{title_num}. ROC curves for Task 1', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "title_num = 'a2'\n",
    "\n",
    "# =========================================================\n",
    "# Calculate PR curve + confidence interval\n",
    "# =========================================================\n",
    "def get_prc_CI_curve(y_true, y_pred, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    mean_recall = np.linspace(0, 1, 2000)\n",
    "    bootstrapped_scores = []\n",
    "    precisions = []\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true.iloc[indices])) < 2:\n",
    "            continue\n",
    "        y_true_boot = y_true.iloc[indices]\n",
    "        y_pred_boot = y_pred.iloc[indices]\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true_boot, y_pred_boot)\n",
    "        # Interpolate precision at mean_recall points\n",
    "        precisions.append(np.interp(mean_recall, recall[::-1], precision[::-1]))\n",
    "        bootstrapped_scores.append(average_precision_score(y_true_boot, y_pred_boot))\n",
    "\n",
    "    mean_precision = np.mean(precisions, axis=0)\n",
    "    precisions_lower = np.percentile(precisions, 2.5, axis=0)\n",
    "    precisions_upper = np.percentile(precisions, 97.5, axis=0)\n",
    "    mean_auprc = np.mean(bootstrapped_scores)\n",
    "    ci_lower = np.percentile(bootstrapped_scores, 2.5)\n",
    "    ci_upper = np.percentile(bootstrapped_scores, 97.5)\n",
    "\n",
    "    return mean_recall, mean_precision, precisions_lower, precisions_upper, mean_auprc, ci_lower, ci_upper\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# parameter defines\n",
    "# =========================================================\n",
    "colors = [\"#E27916\", \"#CF6A84\", \"#5B8FF9\", \"#7ECF4A\", \"#9B59B6\",\"#E1C542\"]  # color for each model\n",
    "models = [\n",
    "          'catboost',\n",
    "          'xgboost',\n",
    "          'randomforest',\n",
    "          'DNN',\n",
    "          'LSTM',\n",
    "          'lr',\n",
    "          ]\n",
    "labels = [\n",
    "          'CatBoost',\n",
    "          'XGBoost',\n",
    "          'RF',\n",
    "          'DNN', \n",
    "          'LSTM',\n",
    "          'LR',\n",
    "          ]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Draw PRC curve\n",
    "# =========================================================\n",
    "# plt.figure(figsize=(5, 5))\n",
    "plt.figure(figsize=(5, 5), dpi=300)\n",
    "\n",
    "for model, color, label in zip(models, colors, labels):\n",
    "    # file = os.path.join(search_path, model, 'predict_death_valid_test', 'all_folds_results.csv')\n",
    "    if model == 'DNN':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_death_valid_test_5cv', 'all_folds_results.csv')\n",
    "    elif model == 'LSTM':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_death_valid_test_5cv', 'all_folds_results.csv')\n",
    "    elif model == 'catboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death/{model}_gridsearch_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'depth_5_iterations_200_learning_rate_0.05', 'all_folds_results.csv') \n",
    "    elif model == 'xgboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death/{model}_gridsearch_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'learning_rate_0.05_max_depth_5_n_estimators_200', 'all_folds_results.csv') \n",
    "    elif model == 'randomforest':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death/{model}_gridsearch_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'max_depth_5_n_estimators_200', 'all_folds_results.csv')\n",
    "    elif model == 'lr':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death/{model}_valid_test_5cv'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"⚠️ 未找到文件：{file}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"✅ 读取文件：{file}，共 {len(df)} 条记录\")\n",
    "    if not {'y_test', 'y_pred'}.issubset(df.columns):\n",
    "        raise ValueError(f\"{file} 缺少 'y_test' 或 'y_pred' 列\")\n",
    "\n",
    "    # PRC + CI\n",
    "    mean_recall, mean_precision, precisions_lower, precisions_upper, mean_auprc, ci_lower, ci_upper = get_prc_CI_curve(\n",
    "        df['y_test'], df['y_pred']\n",
    "    )\n",
    "\n",
    "    # plot PRC curve\n",
    "    plt.plot(mean_recall, mean_precision, color=color, lw=2,\n",
    "             label=f\"{label}: {mean_auprc:.3f} ({ci_lower:.3f}-{ci_upper:.3f})\")\n",
    "    plt.fill_between(mean_recall, precisions_lower, precisions_upper, color=color, alpha=0.15)\n",
    "\n",
    "# plt.plot([0, 1], [0.5, 0.5], color='gray', linestyle='--', label='Baseline (0.5)')\n",
    "\n",
    "lg = plt.legend(loc='upper right', handlelength=1.0, fontsize=10, title='AUPRC (95% CI)')\n",
    "lg.get_title().set_fontsize(11)\n",
    "plt.xlabel('Recall', fontsize=13)\n",
    "plt.ylabel('Precision', fontsize=13)\n",
    "plt.title(f'{title_num}. PR curves for Task 1', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc05eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Decision Curve Analysis (DCA)\n",
    "#####################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "######################\n",
    "## decision_curve\n",
    "\n",
    "def calculate_net_benefit_model(thresh_group, y_pred_score, y_label):\n",
    "    \"\"\"Calculate the net benefit of the model at different thresholds\"\"\"\n",
    "    n = len(y_label)\n",
    "    net_benefit_model = []\n",
    "    for thresh in thresh_group:\n",
    "        y_pred_label = y_pred_score > thresh\n",
    "        tn, fp, fn, tp = confusion_matrix(y_label, y_pred_label).ravel()\n",
    "        nb = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_model.append(nb)\n",
    "    return np.array(net_benefit_model)\n",
    "\n",
    "def calculate_net_benefit_all(thresh_group, y_label):\n",
    "    \"\"\"Net benefit of the 'Treat all' strategy\"\"\"\n",
    "    n = len(y_label)\n",
    "    num_pos = np.sum(y_label == 1)\n",
    "    num_neg = n - num_pos\n",
    "    net_benefit_all = []\n",
    "    for thresh in thresh_group:\n",
    "        nb = (num_pos / n) - (num_neg / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_all.append(nb)\n",
    "    return np.array(net_benefit_all)\n",
    "\n",
    "def calculate_net_benefit_none(thresh_group, y_label):\n",
    "    \"\"\"Net benefit of the 'Treat none' strategy, always 0\"\"\"\n",
    "    return np.zeros_like(thresh_group)\n",
    "\n",
    "#########\n",
    "\n",
    "title_num = 'a3'\n",
    "\n",
    "data = {}\n",
    "thresh_group = np.arange(0, 1, 0.001)\n",
    "\n",
    "# Unified image size and resolution\n",
    "plt.figure(figsize=(5, 5), dpi=300)\n",
    "\n",
    "# Model list\n",
    "models = [\n",
    "          'catboost',\n",
    "          'xgboost',\n",
    "          'randomforest',\n",
    "          'DNN',\n",
    "          'LSTM',\n",
    "          'lr',\n",
    "          ]\n",
    "labels = [\n",
    "          'CatBoost',\n",
    "          'XGBoost',\n",
    "          'RF',\n",
    "          'DNN', \n",
    "          'LSTM',\n",
    "          'LR',\n",
    "          ]\n",
    "\n",
    "# Curve colors\n",
    "colors = [\"#E27916\", \"#CF6A84\", \"#5B8FF9\", \"#7ECF4A\", \"#9B59B6\",\"#E1C542\"]\n",
    "\n",
    "# Read data\n",
    "for model in models:\n",
    "\n",
    "    if model == 'DNN':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_death_calibration', 'all_folds_results.csv')\n",
    "    elif model == 'LSTM':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_death_calibration', 'all_folds_results.csv')\n",
    "    elif model == 'catboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death_calibration/{model}/'\n",
    "        file = os.path.join(search_path, f'depth_5_iterations_200_learning_rate_0.05', 'all_folds_results.csv')  \n",
    "    elif model == 'xgboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death_calibration/{model}/'\n",
    "        file = os.path.join(search_path, f'learning_rate_0.05_max_depth_5_n_estimators_200', 'all_folds_results.csv') \n",
    "    elif model == 'randomforest':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death_calibration/{model}/'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "    elif model == 'lr':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death_calibration/{model}/'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"⚠️ File not found: {file}\")\n",
    "        continue\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"✅ File read: {file}, total {len(df)} records\")\n",
    "    data[model] = df\n",
    "\n",
    "# Plot DCA curves\n",
    "for c_index, (model, label) in enumerate(zip(models, labels)):\n",
    "    if model not in data:\n",
    "        continue\n",
    "    net_benefit_model = calculate_net_benefit_model(\n",
    "        thresh_group, \n",
    "        data[model]['y_pred'],  # Column name 'y_pred' in AUROC file\n",
    "        data[model]['y_test']\n",
    "    )\n",
    "    plt.plot(\n",
    "        thresh_group, \n",
    "        net_benefit_model, \n",
    "        label=label,\n",
    "        color=colors[c_index], \n",
    "        lw=2\n",
    "    )\n",
    "\n",
    "# Plot Treat all / Treat none\n",
    "net_benefit_all = calculate_net_benefit_all(thresh_group, data[model]['y_test'])\n",
    "net_benefit_none = calculate_net_benefit_none(thresh_group, data[model]['y_test'])\n",
    "plt.plot(thresh_group, net_benefit_all, color='black', lw=2, label='Treat all')\n",
    "plt.plot(thresh_group, net_benefit_none, color='black', linestyle=':', lw=2, label='Treat none')\n",
    "\n",
    "# Axes and font\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(net_benefit_model.min() - 0.02, net_benefit_model.max() + 0.02)\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "plt.xlabel('Threshold probability', fontsize=13)\n",
    "plt.ylabel('Net benefit', fontsize=13)\n",
    "\n",
    "# Legend\n",
    "lg = plt.legend(\n",
    "    loc='upper right',\n",
    "    handlelength=1.0,\n",
    "    fontsize=10,\n",
    "    ncol=2,\n",
    "    columnspacing=2.0,\n",
    "    title='Decision Curve Analysis',\n",
    ")\n",
    "lg.get_title().set_fontsize(11)\n",
    "\n",
    "plt.title(\n",
    "    f'{title_num}. DCA for Task 1',\n",
    "    fontsize=14\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import os\n",
    "\n",
    "# ============================================\n",
    "# Adaptive Quantile Binning (Fixed Version: Added Sorting)\n",
    "# ============================================\n",
    "def adaptive_binning(y_true, y_prob, n_bins=10, method='quantile'):\n",
    "    if method == 'quantile':\n",
    "        bins = np.percentile(y_prob, np.linspace(0, 100, n_bins + 1))\n",
    "    elif method == 'density':\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=0.1).fit(y_prob[:, None])\n",
    "        bins = np.linspace(0, 1, n_bins + 1)\n",
    "    else:\n",
    "        raise ValueError(\"Method should be 'quantile' or 'density'\")\n",
    "\n",
    "    bin_indices = np.digitize(y_prob, bins) - 1\n",
    "    fraction_of_positives = []\n",
    "    mean_predicted_value = []\n",
    "    std_errors = []\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        mask = bin_indices == i\n",
    "        if np.sum(mask) > 0:\n",
    "            fraction_of_positives.append(np.mean(y_true[mask]))\n",
    "            mean_predicted_value.append(np.mean(y_prob[mask]))\n",
    "            std_errors.append(np.std(y_true[mask]) / np.sqrt(np.sum(mask)))\n",
    "    # ----------------------------\n",
    "    # Key Fix: Sort by mean_pred\n",
    "    # ----------------------------\n",
    "    fraction_of_positives = np.array(fraction_of_positives)\n",
    "    mean_predicted_value = np.array(mean_predicted_value)\n",
    "    std_errors = np.array(std_errors)\n",
    "    order = np.argsort(mean_predicted_value)\n",
    "    return (\n",
    "        fraction_of_positives[order],\n",
    "        mean_predicted_value[order],\n",
    "        std_errors[order],\n",
    "        bins\n",
    "    )\n",
    "\n",
    "# ============================================\n",
    "# Brier Score (Correct, No Modification Needed)\n",
    "# ============================================\n",
    "def brier_score(y_true, y_prob):\n",
    "    return np.mean((y_true - y_prob)**2)\n",
    "\n",
    "# ============================================\n",
    "# Model List (Fully Consistent with DCA)\n",
    "# ============================================\n",
    "models = [\n",
    "    'catboost',\n",
    "    'xgboost',\n",
    "    'randomforest',\n",
    "    'DNN',\n",
    "    'LSTM',\n",
    "    'lr',\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    'CatBoost',\n",
    "    'XGBoost',\n",
    "    'RF',\n",
    "    'DNN',\n",
    "    'LSTM',\n",
    "    'LR',\n",
    "]\n",
    "\n",
    "# Colors (Same as Your DCA Color Scheme)\n",
    "colors = [\"#E27916\", \"#CF6A84\", \"#5B8FF9\", \"#7ECF4A\", \"#9B59B6\", \"#E1C542\"]\n",
    "data = {}\n",
    "\n",
    "# ============================================\n",
    "# Load Prediction Files (Fully Synchronized with DCA)\n",
    "# ============================================\n",
    "for model in models:\n",
    "\n",
    "    if model == 'DNN':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_death_calibration', 'all_folds_results.csv')\n",
    "    elif model == 'LSTM':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_death_calibration', 'all_folds_results.csv')\n",
    "    elif model == 'catboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death_calibration/{model}/'\n",
    "        file = os.path.join(search_path, f'depth_5_iterations_200_learning_rate_0.05', 'all_folds_results.csv')  \n",
    "    elif model == 'xgboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death_calibration/{model}/'\n",
    "        file = os.path.join(search_path, f'learning_rate_0.05_max_depth_5_n_estimators_200', 'all_folds_results.csv') \n",
    "    elif model == 'randomforest':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death_calibration/{model}/'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "    elif model == 'lr':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_death_calibration/{model}/'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"⚠️ File not found: {file}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"✅ Read {model} file: {file} with {len(df)} records\")\n",
    "    data[model] = df\n",
    "\n",
    "# ============================================\n",
    "# Plot Calibration Curve (Consistent with DCA Style)\n",
    "# ============================================\n",
    "plt.figure(figsize=(5, 5), dpi=300)\n",
    "\n",
    "for idx, (model, label) in enumerate(zip(models, labels)):\n",
    "    if model not in data:\n",
    "        continue\n",
    "    y_test = data[model]['y_test'].values\n",
    "    y_pred = data[model]['y_pred'].values\n",
    "    frac_pos, mean_pred, std_err, bins = adaptive_binning(y_test, y_pred, n_bins=10)\n",
    "    brier = brier_score(y_test, y_pred)\n",
    "    plt.errorbar(\n",
    "        mean_pred,\n",
    "        frac_pos,\n",
    "        yerr=std_err,\n",
    "        fmt='.',\n",
    "        label=f\"{label}: {brier:.4f}\",\n",
    "        # markersize=6,\n",
    "        # elinewidth=1,\n",
    "        markersize=10,\n",
    "        elinewidth=2,\n",
    "        alpha=0.85,\n",
    "        color=colors[idx]\n",
    "    )\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
    "\n",
    "plt.xlabel(\"Mean Predicted Probability\", fontsize=13)\n",
    "plt.ylabel(\"Fraction of Positives\", fontsize=13)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"Calibration curves for Task 1\", fontsize=14)\n",
    "\n",
    "lg = plt.legend(\n",
    "    loc='lower right',\n",
    "    handlelength=1.0,\n",
    "    fontsize=10,\n",
    "    title=\"Brier Score\",\n",
    ")\n",
    "lg.get_title().set_fontsize(12)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a58a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb2ab4d6",
   "metadata": {},
   "source": [
    "## Cohort 2 (Recovery vs. Non-recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "title_num = 'b1'\n",
    "\n",
    "# =========================================================\n",
    "# Calculate ROC curve + confidence interval\n",
    "# =========================================================\n",
    "def get_roc_CI_curve(y_true, y_pred, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    mean_fpr = np.linspace(0, 1, 2000)\n",
    "\n",
    "    bootstrapped_scores = []\n",
    "    tprs = []\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true.iloc[indices])) < 2:\n",
    "            continue\n",
    "        y_true_boot = y_true.iloc[indices]\n",
    "        y_pred_boot = y_pred.iloc[indices]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true_boot, y_pred_boot)\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        bootstrapped_scores.append(auc(fpr, tpr))\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    tprs_lower = np.percentile(tprs, 2.5, axis=0)\n",
    "    tprs_upper = np.percentile(tprs, 97.5, axis=0)\n",
    "    mean_auc = np.mean(bootstrapped_scores)\n",
    "    ci_lower = np.percentile(bootstrapped_scores, 2.5)\n",
    "    ci_upper = np.percentile(bootstrapped_scores, 97.5)\n",
    "    return mean_fpr, mean_tpr, tprs_lower, tprs_upper, mean_auc, ci_lower, ci_upper\n",
    "\n",
    "# =========================================================\n",
    "# Parameter definitions\n",
    "# =========================================================\n",
    "colors = [\"#E27916\", \"#CF6A84\", \"#5B8FF9\", \"#7ECF4A\", \"#9B59B6\",\"#E1C542\"]  # Color for each model\n",
    "models = [\n",
    "          'catboost',\n",
    "          'xgboost',\n",
    "          'randomforest',\n",
    "          'DNN',\n",
    "          'LSTM',\n",
    "          'lr',\n",
    "          ]\n",
    "labels = [\n",
    "          'CatBoost',\n",
    "          'XGBoost',\n",
    "          'RF',\n",
    "          'DNN', \n",
    "          'LSTM',\n",
    "          'LR',\n",
    "          ]\n",
    "\n",
    "# =========================================================\n",
    "# Plot ROC curve\n",
    "# =========================================================\n",
    "plt.figure(figsize=(5, 5), dpi=300)\n",
    "# plt.figure(figsize=(5, 5))\n",
    "\n",
    "for model, color, label in zip(models, colors, labels):\n",
    "    # file = os.path.join(search_path, model, 'predict_death_valid_test', 'all_folds_results.csv')\n",
    "    if model == 'DNN':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_non-recovery_valid_test_5cv', 'all_folds_results.csv')\n",
    "    elif model == 'LSTM':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_non-recovery_valid_test_5cv', 'all_folds_results.csv')\n",
    "    elif model == 'catboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery/{model}_fixed_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'depth_5_iterations_200_learning_rate_0.05', 'all_folds_results.csv') \n",
    "    elif model == 'xgboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery/{model}_fixed_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'learning_rate_0.05_max_depth_5_n_estimators_200', 'all_folds_results.csv')\n",
    "    elif model == 'randomforest':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery/{model}_fixed_valid_test_5cv'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "    elif model == 'lr':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery/{model}_valid_test_5cv'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"⚠️ File not found: {file}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"✅ File read: {file}, total {len(df)} records\")\n",
    "    if not {'y_test', 'y_pred'}.issubset(df.columns):\n",
    "        raise ValueError(f\"{file} is missing 'y_test' or 'y_pred' columns\")\n",
    "\n",
    "    # Calculate ROC + CI\n",
    "    mean_fpr, mean_tpr, tprs_lower, tprs_upper, mean_auc, ci_lower, ci_upper = get_roc_CI_curve(\n",
    "        df['y_test'], df['y_pred']\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    plt.plot(mean_fpr, mean_tpr, color=color, lw=2,\n",
    "             label=f\"{label}: {mean_auc:.3f} ({ci_lower:.3f}-{ci_upper:.3f})\")\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=color, alpha=0.15)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "\n",
    "lg = plt.legend(loc='lower right', handlelength=1.0, fontsize=10, title='AUROC (95% CI)')\n",
    "lg.get_title().set_fontsize(11)\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "plt.title(f'{title_num}. ROC curves for Task 2', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "title_num = 'b2'\n",
    "\n",
    "# =========================================================\n",
    "# Calculate PRC + Confidence Interval\n",
    "# =========================================================\n",
    "def get_prc_CI_curve(y_true, y_pred, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    mean_recall = np.linspace(0, 1, 2000)\n",
    "    bootstrapped_scores = []\n",
    "    precisions = []\n",
    "    for i in range(n_bootstrap):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true.iloc[indices])) < 2:\n",
    "            continue\n",
    "        y_true_boot = y_true.iloc[indices]\n",
    "        y_pred_boot = y_pred.iloc[indices]\n",
    "        precision, recall, _ = precision_recall_curve(y_true_boot, y_pred_boot)\n",
    "        # Interpolate precision at the same recall\n",
    "        precisions.append(np.interp(mean_recall, recall[::-1], precision[::-1]))\n",
    "        bootstrapped_scores.append(average_precision_score(y_true_boot, y_pred_boot))\n",
    "    mean_precision = np.mean(precisions, axis=0)\n",
    "    precisions_lower = np.percentile(precisions, 2.5, axis=0)\n",
    "    precisions_upper = np.percentile(precisions, 97.5, axis=0)\n",
    "    mean_auprc = np.mean(bootstrapped_scores)\n",
    "    ci_lower = np.percentile(bootstrapped_scores, 2.5)\n",
    "    ci_upper = np.percentile(bootstrapped_scores, 97.5)\n",
    "    return mean_recall, mean_precision, precisions_lower, precisions_upper, mean_auprc, ci_lower, ci_upper\n",
    "\n",
    "# =========================================================\n",
    "# Parameter Definitions\n",
    "# =========================================================\n",
    "colors = [\"#E27916\", \"#CF6A84\", \"#5B8FF9\", \"#7ECF4A\", \"#9B59B6\",\"#E1C542\"]\n",
    "models = [\n",
    "          'catboost',\n",
    "          'xgboost',\n",
    "          'randomforest',\n",
    "          'DNN',\n",
    "          'LSTM',\n",
    "          'lr',\n",
    "          ]\n",
    "labels = [\n",
    "          'CatBoost',\n",
    "          'XGBoost',\n",
    "          'RF',\n",
    "          'DNN', \n",
    "          'LSTM',\n",
    "          'LR',\n",
    "          ]\n",
    "\n",
    "# =========================================================\n",
    "# Plot PRC Curves\n",
    "# =========================================================\n",
    "# plt.figure(figsize=(5, 5))\n",
    "plt.figure(figsize=(5, 5), dpi=300)\n",
    "\n",
    "for model, color, label in zip(models, colors, labels):\n",
    "    # file = os.path.join(search_path, model, 'predict_death_valid_test', 'all_folds_results.csv')\n",
    "    if model == 'DNN':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_non-recovery_valid_test_5cv', 'all_folds_results.csv')\n",
    "    elif model == 'LSTM':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_non-recovery_valid_test_5cv', 'all_folds_results.csv')\n",
    "    elif model == 'catboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery/{model}_fixed_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'depth_5_iterations_200_learning_rate_0.05', 'all_folds_results.csv')  \n",
    "    elif model == 'xgboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery/{model}_fixed_valid_test_5cv'\n",
    "        file = os.path.join(search_path, f'learning_rate_0.05_max_depth_5_n_estimators_200', 'all_folds_results.csv') \n",
    "    elif model == 'randomforest':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery/{model}_fixed_valid_test_5cv'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "    elif model == 'lr':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery/{model}_valid_test_5cv'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"⚠️ File not found: {file}\")\n",
    "        continue\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"✅ File read: {file}, total {len(df)} records\")\n",
    "    if not {'y_test', 'y_pred'}.issubset(df.columns):\n",
    "        raise ValueError(f\"{file} is missing 'y_test' or 'y_pred' columns\")\n",
    "    # Calculate PRC + CI\n",
    "    mean_recall, mean_precision, precisions_lower, precisions_upper, mean_auprc, ci_lower, ci_upper = get_prc_CI_curve(\n",
    "        df['y_test'], df['y_pred'])\n",
    "    # Plot\n",
    "    plt.plot(mean_recall, mean_precision, color=color, lw=2,\n",
    "             label=f\"{label}: {mean_auprc:.3f} ({ci_lower:.3f}-{ci_upper:.3f})\")\n",
    "    plt.fill_between(mean_recall, precisions_lower, precisions_upper, color=color, alpha=0.15)\n",
    "\n",
    "# plt.plot([0, 1], [0.5, 0.5], color='gray', linestyle='--', label='Baseline (0.5)')\n",
    "\n",
    "lg = plt.legend(\n",
    "    loc='lower left',\n",
    "    bbox_to_anchor=(0.05, 0.0),\n",
    "    handlelength=1.0,\n",
    "    fontsize=10,\n",
    "    title='AUPRC (95% CI)'\n",
    ")\n",
    "lg.get_title().set_fontsize(11)\n",
    "plt.xlabel('Recall', fontsize=13)\n",
    "plt.ylabel('Precision', fontsize=13)\n",
    "plt.title(f'{title_num}. PR curves for Task 2', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ca52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Decision Analysis Curve (DCA)\n",
    "#####################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "\n",
    "######################\n",
    "## decision_curve\n",
    "def calculate_net_benefit_model(thresh_group, y_pred_score, y_label):\n",
    "    net_benefit_model = np.array([])\n",
    "    for thresh in thresh_group:\n",
    "        y_pred_label = y_pred_score > thresh\n",
    "        tn, fp, fn, tp = confusion_matrix(y_label, y_pred_label).ravel()\n",
    "        n = len(y_label)\n",
    "        net_benefit = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_model = np.append(net_benefit_model, net_benefit)\n",
    "    return net_benefit_model\n",
    "\n",
    "def calculate_net_benefit_all(thresh_group, y_label):\n",
    "    net_benefit_all = np.array([])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_label, y_label).ravel()\n",
    "    total = tp + tn\n",
    "    for thresh in thresh_group:\n",
    "        net_benefit = (tp / total) - (tn / total) * (thresh / (1 - thresh))\n",
    "        net_benefit_all = np.append(net_benefit_all, net_benefit)\n",
    "    return net_benefit_all\n",
    "\n",
    "#########\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "title_num = 'b3'\n",
    "\n",
    "data = {}\n",
    "thresh_group = np.arange(0, 1, 0.001)\n",
    "plt.figure(figsize=(5, 5), dpi=300)\n",
    "\n",
    "models = [\n",
    "    'catboost',\n",
    "    'xgboost',\n",
    "    'randomforest',\n",
    "    'DNN',\n",
    "    'LSTM',\n",
    "    'lr',\n",
    "]\n",
    "labels = [\n",
    "    'CatBoost',\n",
    "    'XGBoost',\n",
    "    'RF',\n",
    "    'DNN', \n",
    "    'LSTM',\n",
    "    'LR',\n",
    "]\n",
    "\n",
    "colors = [\"#E27916\", \"#CF6A84\", \"#5B8FF9\", \"#7ECF4A\", \"#9B59B6\",\"#E1C542\"]\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    if model == 'DNN':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_non-recovery_calibration', 'all_folds_results.csv')\n",
    "    elif model == 'LSTM':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_non-recovery_calibration', 'all_folds_results.csv')\n",
    "    elif model == 'catboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery_calibration/{model}/'\n",
    "        file = os.path.join(search_path, f'depth_5_iterations_200_learning_rate_0.05', 'all_folds_results.csv')  \n",
    "    elif model == 'xgboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery_calibration/{model}/'\n",
    "        file = os.path.join(search_path, f'learning_rate_0.05_max_depth_5_n_estimators_200', 'all_folds_results.csv') \n",
    "    elif model == 'randomforest':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery_calibration/{model}/'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "    elif model == 'lr':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery_calibration/{model}/'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"⚠️ File not found: {file}\")\n",
    "        continue\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"✅ File read successfully: {file}, total {len(df)} records\")\n",
    "    data[model] = df\n",
    "\n",
    "# Plot the DCA curve\n",
    "for c_index, (model, label) in enumerate(zip(models, labels)):\n",
    "    if model not in data:\n",
    "        continue\n",
    "    net_benefit_model = calculate_net_benefit_model(\n",
    "        thresh_group, \n",
    "        data[model]['y_pred'],\n",
    "        data[model]['y_test']\n",
    "    )\n",
    "    plt.plot(\n",
    "        thresh_group, \n",
    "        net_benefit_model, \n",
    "        label=label,\n",
    "        color=colors[c_index], \n",
    "        lw=2\n",
    "    )\n",
    "\n",
    "net_benefit_all = calculate_net_benefit_all(thresh_group, data[model]['y_test'])\n",
    "plt.plot(thresh_group, net_benefit_all, color='black', lw=2, label='Treat all')\n",
    "plt.plot((0, 1), (0, 0), color='black', linestyle=':', lw=2, label='Treat none')\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(net_benefit_model.min() - 0.02, net_benefit_model.max() + 0.02)\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "plt.xlabel('Threshold probability', fontsize=13)\n",
    "plt.ylabel('Net benefit', fontsize=13)\n",
    "# plt.legend(loc='upper right', handlelength=1.0, fontsize=10, title='Decision Curve')\n",
    "# plt.legend(loc='upper right', handlelength=1.0, fontsize=10)\n",
    "lg = plt.legend(\n",
    "    loc='upper right',\n",
    "    handlelength=1.0,\n",
    "    fontsize=10,\n",
    "    ncol=2,\n",
    "    columnspacing=2.0,\n",
    "    title='Decision Curve Analysis',\n",
    ")\n",
    "lg.get_title().set_fontsize(11)\n",
    "\n",
    "plt.title(\n",
    "    f'{title_num}. DCA for Task 2',\n",
    "    fontsize=14\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import os\n",
    "\n",
    "# ============================================\n",
    "# Adaptive Quantile Binning (Fixed Version: Add Sort)\n",
    "# ============================================\n",
    "def adaptive_binning(y_true, y_prob, n_bins=10, method='quantile'):\n",
    "    if method == 'quantile':\n",
    "        bins = np.percentile(y_prob, np.linspace(0, 100, n_bins + 1))\n",
    "    elif method == 'density':\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=0.1).fit(y_prob[:, None])\n",
    "        bins = np.linspace(0, 1, n_bins + 1)\n",
    "    else:\n",
    "        raise ValueError(\"Method should be 'quantile' or 'density'\")\n",
    "\n",
    "    bin_indices = np.digitize(y_prob, bins) - 1\n",
    "    fraction_of_positives = []\n",
    "    mean_predicted_value = []\n",
    "    std_errors = []\n",
    "    for i in range(n_bins):\n",
    "        mask = bin_indices == i\n",
    "        if np.sum(mask) > 0:\n",
    "            fraction_of_positives.append(np.mean(y_true[mask]))\n",
    "            mean_predicted_value.append(np.mean(y_prob[mask]))\n",
    "            std_errors.append(np.std(y_true[mask]) / np.sqrt(np.sum(mask)))\n",
    "\n",
    "    # ----------------------------\n",
    "    # Key fixes: sort by mean_pred!\n",
    "    # ----------------------------\n",
    "    fraction_of_positives = np.array(fraction_of_positives)\n",
    "    mean_predicted_value = np.array(mean_predicted_value)\n",
    "    std_errors = np.array(std_errors)\n",
    "\n",
    "    order = np.argsort(mean_predicted_value)\n",
    "    return (\n",
    "        fraction_of_positives[order],\n",
    "        mean_predicted_value[order],\n",
    "        std_errors[order],\n",
    "        bins\n",
    "    )\n",
    "\n",
    "# ============================================\n",
    "# Brier Score (correct, no modification required)\n",
    "# ============================================\n",
    "def brier_score(y_true, y_prob):\n",
    "    return np.mean((y_true - y_prob)**2)\n",
    "\n",
    "# ============================================\n",
    "# List of models (fully consistent with DCA)\n",
    "# ============================================\n",
    "models = [\n",
    "    'catboost',\n",
    "    'xgboost',\n",
    "    'randomforest',\n",
    "    'DNN',\n",
    "    'LSTM',\n",
    "    'lr',\n",
    "]\n",
    "labels = [\n",
    "    'CatBoost',\n",
    "    'XGBoost',\n",
    "    'RF',\n",
    "    'DNN',\n",
    "    'LSTM',\n",
    "    'LR',\n",
    "]\n",
    "\n",
    "# Color (use your DCA color scheme)\n",
    "colors = [\"#E27916\", \"#CF6A84\", \"#5B8FF9\", \"#7ECF4A\", \"#9B59B6\", \"#E1C542\"]\n",
    "data = {}\n",
    "\n",
    "# ============================================\n",
    "# Load prediction files (fully synchronized with your DCA)\n",
    "# ============================================\n",
    "for model in models:\n",
    "\n",
    "    if model == 'DNN':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_non-recovery_calibration', 'all_folds_results.csv')\n",
    "    elif model == 'LSTM':\n",
    "        search_path = f'./Poisoning_Prediction/'\n",
    "        file = os.path.join(search_path, model, 'predict_non-recovery_calibration', 'all_folds_results.csv')\n",
    "    elif model == 'catboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery_calibration/{model}/'\n",
    "        file = os.path.join(search_path, f'depth_5_iterations_200_learning_rate_0.05', 'all_folds_results.csv')\n",
    "    elif model == 'xgboost':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery_calibration/{model}/'\n",
    "        file = os.path.join(search_path, f'learning_rate_0.05_max_depth_5_n_estimators_200', 'all_folds_results.csv')\n",
    "    elif model == 'randomforest':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery_calibration/{model}/'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "    elif model == 'lr':\n",
    "        search_path = f'./Poisoning_Prediction/ML/predict_non-recovery_calibration/{model}/'\n",
    "        file = os.path.join(search_path, 'all_folds_results.csv')\n",
    "\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"⚠️ file not found：{file}\")\n",
    "        continue\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"✅ Read {model} file: {file} total {len(df)} records\")\n",
    "    data[model] = df\n",
    "\n",
    "# ============================================\n",
    "# Draw calibration curve (consistent with DCA style)\n",
    "# ============================================\n",
    "plt.figure(figsize=(5, 5), dpi=300)\n",
    "\n",
    "for idx, (model, label) in enumerate(zip(models, labels)):\n",
    "    if model not in data:\n",
    "        continue\n",
    "    y_test = data[model]['y_test'].values\n",
    "    y_pred = data[model]['y_pred'].values\n",
    "    frac_pos, mean_pred, std_err, bins = adaptive_binning(y_test, y_pred, n_bins=10)\n",
    "    brier = brier_score(y_test, y_pred)\n",
    "    plt.errorbar(\n",
    "        mean_pred,\n",
    "        frac_pos,\n",
    "        yerr=std_err,\n",
    "        fmt='.',\n",
    "        label=f\"{label}: {brier:.4f}\",\n",
    "        # markersize=6,\n",
    "        # elinewidth=1,\n",
    "        markersize=10,\n",
    "        elinewidth=2,\n",
    "        alpha=0.85,\n",
    "        color=colors[idx]\n",
    "    )\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
    "\n",
    "plt.xlabel(\"Mean Predicted Probability\", fontsize=13)\n",
    "plt.ylabel(\"Fraction of Positives\", fontsize=13)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"Calibration curves for Task 2\", fontsize=14)\n",
    "\n",
    "lg = plt.legend(\n",
    "    loc='lower right',\n",
    "    handlelength=1.0,\n",
    "    fontsize=10,\n",
    "    title=\"Brier Score\",\n",
    ")\n",
    "lg.get_title().set_fontsize(12)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
