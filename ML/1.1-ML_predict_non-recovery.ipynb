{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d8b5c7",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3bdbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_albumin_clean = pd.read_excel('/home/mailiyi/Poisoning_Prediction/all_poisoning_data_wide_clean_albumin_20251106.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222dacc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical = ['Gender',\n",
    " 'Education Level',\n",
    " 'Type of Poisoning',\n",
    " 'Hypertension',\n",
    " 'Hyperlipidemia',\n",
    " 'Diabetes Mellitus',\n",
    " 'Cerebrovascular Disease',\n",
    " 'Heart Disease',\n",
    " 'Allergy History',\n",
    " 'Cancer',\n",
    " 'Poisoning',\n",
    " 'degree of poisoning',\n",
    " 'Smoking Status',\n",
    " 'Alcohol Consumption Status',\n",
    " 'Shortness of Breath',\n",
    " 'Chest Pain',\n",
    " 'Cough',\n",
    " 'Pre-syncope',\n",
    " 'Altered Consciousness or Syncope',\n",
    " 'Sore Throat',\n",
    " 'Fever',\n",
    " 'Fatigue',\n",
    " 'Lower Limb Edema',\n",
    " 'Palpitations',\n",
    " 'Vomiting',\n",
    " 'Nausea',\n",
    " 'Weakness',\n",
    " 'Headache',\n",
    " 'Residence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9e60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_mappings_en = {\n",
    "    \"Gender\": {\n",
    "        1: \"Male\",\n",
    "        0: \"Female\"\n",
    "    },\n",
    "    \"Education Level\": {\n",
    "        1: \"Illiterate\",\n",
    "        2: \"Primary School\",\n",
    "        3: \"Junior High School\",\n",
    "        4: \"Senior High School\",\n",
    "        5: \"University Degree\"\n",
    "    },\n",
    "    \"Type of Poisoning\": {\n",
    "        1: \"Industrial\",\n",
    "        2: \"Pharmaceutical\",\n",
    "        3: \"Pesticide\",\n",
    "        4: \"Alcohol\",\n",
    "        0: \"Uncertain\"\n",
    "    },\n",
    "    \"Hypertension\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Hyperlipidemia\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Diabetes Mellitus\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Cerebrovascular Disease\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Heart Disease\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Allergy History\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Cancer\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Poisoning\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"degree of poisoning\": {\n",
    "        0: \"Undetermined\",\n",
    "        1: \"Low\",\n",
    "        2: \"Moderate\",\n",
    "        3: \"High\"\n",
    "    },\n",
    "    \"Smoking\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Alcohol Consumption Status\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Shortness of Breath\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Chest Pain\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Cough\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Pre-syncope\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Altered Mental Status or Syncope(AMS or Sync)\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Sore Throat\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Fever\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Fatigue\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Lower Limb Edema\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Palpitations\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Vomiting\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Nausea\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Weakness\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Headache\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Residence\": {\n",
    "        1: \"Rural\",\n",
    "        2: \"Urban\"\n",
    "    },\n",
    "    \"Smoking Status\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    'Altered Consciousness or Syncope': {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inverse mapping (English label → numerical value)\n",
    "df_mapped_wide = df_albumin_clean.copy()\n",
    "for col in features_categorical:\n",
    "    if col in value_mappings_en and col in df_mapped_wide.columns:\n",
    "        inv_map = {v: k for k, v in value_mappings_en[col].items()}\n",
    "        df_mapped_wide[col] = df_mapped_wide[col].map(inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b63a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【Gender】的分布：\n",
      "Gender\n",
      "0    513\n",
      "1    458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Education Level】的分布：\n",
      "Education Level\n",
      "3.0    412\n",
      "2.0    226\n",
      "4.0    189\n",
      "1.0     87\n",
      "5.0     54\n",
      "NaN      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Type of Poisoning】的分布：\n",
      "Type of Poisoning\n",
      "3    474\n",
      "2    257\n",
      "1    194\n",
      "4     46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Hypertension】的分布：\n",
      "Hypertension\n",
      "0.0    740\n",
      "1.0    230\n",
      "NaN      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Hyperlipidemia】的分布：\n",
      "Hyperlipidemia\n",
      "0.0    962\n",
      "1.0      8\n",
      "NaN      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Diabetes Mellitus】的分布：\n",
      "Diabetes Mellitus\n",
      "0.0    891\n",
      "1.0     79\n",
      "NaN      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Cerebrovascular Disease】的分布：\n",
      "Cerebrovascular Disease\n",
      "0.0    875\n",
      "1.0     95\n",
      "NaN      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Heart Disease】的分布：\n",
      "Heart Disease\n",
      "0.0    912\n",
      "1.0     58\n",
      "NaN      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Allergy History】的分布：\n",
      "Allergy History\n",
      "0.0    896\n",
      "1.0     74\n",
      "NaN      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Cancer】的分布：\n",
      "Cancer\n",
      "0.0    952\n",
      "1.0     18\n",
      "NaN      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Poisoning】的分布：\n",
      "Poisoning\n",
      "0.0    955\n",
      "1.0     15\n",
      "NaN      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【degree of poisoning】的分布：\n",
      "degree of poisoning\n",
      "3    372\n",
      "2    291\n",
      "1    206\n",
      "0    102\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Smoking Status】的分布：\n",
      "Smoking Status\n",
      "0    720\n",
      "1    251\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Alcohol Consumption Status】的分布：\n",
      "Alcohol Consumption Status\n",
      "0    778\n",
      "1    193\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Shortness of Breath】的分布：\n",
      "Shortness of Breath\n",
      "0    871\n",
      "1    100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Chest Pain】的分布：\n",
      "Chest Pain\n",
      "0    930\n",
      "1     41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Cough】的分布：\n",
      "Cough\n",
      "0    948\n",
      "1     23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Pre-syncope】的分布：\n",
      "Pre-syncope\n",
      "0    837\n",
      "1    134\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Altered Consciousness or Syncope】的分布：\n",
      "Altered Consciousness or Syncope\n",
      "0    589\n",
      "1    382\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Sore Throat】的分布：\n",
      "Sore Throat\n",
      "0    920\n",
      "1     51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Fever】的分布：\n",
      "Fever\n",
      "0    950\n",
      "1     21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Fatigue】的分布：\n",
      "Fatigue\n",
      "0    824\n",
      "1    147\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Lower Limb Edema】的分布：\n",
      "Lower Limb Edema\n",
      "0    965\n",
      "1      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Palpitations】的分布：\n",
      "Palpitations\n",
      "0    908\n",
      "1     63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Vomiting】的分布：\n",
      "Vomiting\n",
      "0    497\n",
      "1    474\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Nausea】的分布：\n",
      "Nausea\n",
      "1    486\n",
      "0    485\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Weakness】的分布：\n",
      "Weakness\n",
      "1    592\n",
      "0    379\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Headache】的分布：\n",
      "Headache\n",
      "0    880\n",
      "1     91\n",
      "Name: count, dtype: int64\n",
      "\n",
      "【Residence】的分布：\n",
      "Residence\n",
      "1.0    427\n",
      "NaN    401\n",
      "2.0    143\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Stores the distribution of each categorical variable\n",
    "category_distributions = {}\n",
    "\n",
    "for col in features_categorical:\n",
    "    if col in df_mapped_wide.columns:\n",
    "        counts = df_mapped_wide[col].value_counts(dropna=False)\n",
    "        category_distributions[col] = counts\n",
    "        print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79312ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcome_other 分布（是否死亡）：\n",
      "Outcome_other\n",
      "0    889\n",
      "1     82\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome 分布（是否未治愈）：\n",
      "Outcome\n",
      "0    731\n",
      "1    240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Statistics Distribution of Outcome_other and Outcome\n",
    "print(df_mapped_wide[\"Outcome_other\"].value_counts(dropna=False))\n",
    "print(df_mapped_wide[\"Outcome\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58352688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9aa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "变量缺失比例（%）:\n",
      "Lactate                                             96.81\n",
      "Carbon Dioxide                                      94.95\n",
      "Potassium                                           94.75\n",
      "Sodium                                              94.75\n",
      "Chloride                                            94.75\n",
      "Prothrombin Time                                    94.64\n",
      "D-Dimer                                             94.64\n",
      "Atropine Dosage                                     93.92\n",
      "Long-acting Nitroglycerin Dosage                    92.48\n",
      "Hyperbaric Oxygen Therapy Duration and Frequency    92.38\n",
      "Pralidoxime Dosage                                  92.17\n",
      "Serum Creatinine                                    89.70\n",
      "Blood Cholinesterase Test Results                   89.29\n",
      "Number of Blood Purification Sessions               84.55\n",
      "Number of Hemoperfusion Sessions                    84.04\n",
      "Homocysteine                                        62.20\n",
      "Systolic Blood Pressure                             54.89\n",
      "Diastolic Blood Pressure                            54.89\n",
      "Troponin I                                          54.69\n",
      "Direct Bilirubin                                    54.07\n",
      "Weight                                              38.93\n",
      "High-Sensitivity C-Reactive Protein (hs-CRP)        37.80\n",
      "Albumin (First Measurement)                          6.80\n",
      "Albumin (Last Measurement)                           6.80\n",
      "Creatine Kinase-MB Isoenzyme                         5.87\n",
      "Length of Stay                                       5.15\n",
      "Respiratory Rate                                     4.53\n",
      "Urea                                                 2.88\n",
      "Uric Acid                                            2.78\n",
      "Creatine Kinase (CK)                                 2.57\n",
      "Mean Platelet Volume                                 2.47\n",
      "White Blood Cell Count                               1.96\n",
      "Hemoglobin Concentration                             1.96\n",
      "Red Blood Cell Count                                 1.96\n",
      "Mean Corpuscular Volume                              1.96\n",
      "Platelet Count                                       1.96\n",
      "Mean Corpuscular Hemoglobin                          1.96\n",
      "Mean Corpuscular Hemoglobin Concentration            1.96\n",
      "Lactate Dehydrogenase (LDH)                          1.75\n",
      "Alanine Aminotransferase (ALT)                       1.54\n",
      "Total Bilirubin                                      1.44\n",
      "Heart Rate                                           0.00\n",
      "Age                                                  0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Calculate missing proportions for continuous variables\n",
    "\n",
    "features_continuous = ['Age',\n",
    " 'Length of Stay',\n",
    " 'Weight',\n",
    " 'Systolic Blood Pressure',\n",
    " 'Diastolic Blood Pressure',\n",
    " 'Respiratory Rate',\n",
    " 'Heart Rate',\n",
    " 'White Blood Cell Count',\n",
    " 'Red Blood Cell Count',\n",
    " 'Hemoglobin Concentration',\n",
    " 'Mean Corpuscular Volume',\n",
    " 'Mean Corpuscular Hemoglobin',\n",
    " 'Mean Corpuscular Hemoglobin Concentration',\n",
    " 'Platelet Count',\n",
    " 'Mean Platelet Volume',\n",
    " 'Alanine Aminotransferase (ALT)',\n",
    " 'Total Bilirubin',\n",
    " 'Direct Bilirubin',\n",
    " 'Lactate Dehydrogenase (LDH)',\n",
    " 'Urea',\n",
    " 'Serum Creatinine',\n",
    " 'Uric Acid',\n",
    " 'Creatine Kinase (CK)',\n",
    " 'Creatine Kinase-MB Isoenzyme',\n",
    " 'Troponin I',\n",
    " 'High-Sensitivity C-Reactive Protein (hs-CRP)',\n",
    " 'Homocysteine',\n",
    " 'Potassium',\n",
    " 'Sodium',\n",
    " 'Chloride',\n",
    " 'Carbon Dioxide',\n",
    " 'Prothrombin Time',\n",
    " 'D-Dimer',\n",
    " 'Lactate',\n",
    " 'Blood Cholinesterase Test Results',\n",
    " 'Albumin (First Measurement)',\n",
    " 'Albumin (Last Measurement)',\n",
    " 'Number of Hemoperfusion Sessions',\n",
    " 'Number of Blood Purification Sessions',\n",
    " 'Hyperbaric Oxygen Therapy Duration and Frequency',\n",
    " 'Atropine Dosage',\n",
    " 'Long-acting Nitroglycerin Dosage',\n",
    " 'Pralidoxime Dosage',\n",
    " ] \n",
    "\n",
    "missing_ratios = df_mapped_wide[features_continuous].isnull().mean()\n",
    "missing_summary = (missing_ratios * 100).round(2).sort_values(ascending=False)\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d58cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失率 > 90% 的连续变量:\n",
      "Potassium: 94.75%\n",
      "Sodium: 94.75%\n",
      "Chloride: 94.75%\n",
      "Carbon Dioxide: 94.95%\n",
      "Prothrombin Time: 94.64%\n",
      "D-Dimer: 94.64%\n",
      "Lactate: 96.81%\n",
      "Hyperbaric Oxygen Therapy Duration and Frequency: 92.38%\n",
      "Atropine Dosage: 93.92%\n",
      "Long-acting Nitroglycerin Dosage: 92.48%\n",
      "Pralidoxime Dosage: 92.17%\n"
     ]
    }
   ],
   "source": [
    "# Feature names screened for deletion rates> 90%\n",
    "high_missing_features = missing_ratios[missing_ratios > 0.90].index.tolist()\n",
    "for feat in high_missing_features:\n",
    "    print(f\"{feat}: {missing_ratios[feat]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c950c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "11\n",
      "32\n",
      "(971, 95)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(features_continuous))\n",
    "print(len(high_missing_features))\n",
    "features_continuous = [feat for feat in features_continuous if feat not in high_missing_features]\n",
    "print(len(features_continuous))\n",
    "\n",
    "df_mapped_wide = df_mapped_wide.drop(columns=high_missing_features)\n",
    "print(df_mapped_wide.shape)\n",
    "\n",
    "print('number of features：',len(features_categorical + features_continuous))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104809af",
   "metadata": {},
   "source": [
    "## 5-fold cross validation: Divide 1/8 of the training set into validation sets (i.e. 70% training set, 10% validation set, 20% test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16489a72",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485dbd7",
   "metadata": {},
   "source": [
    "- Number of seeds tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "def train_catboost_until_auc(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    early_stopping_rounds=30,\n",
    "    n_bootstrap=2000, \n",
    "    seed_global=42,\n",
    "    auc_threshold=0.83 \n",
    "    # auc_threshold=0.85\n",
    "):\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            X[c] = X[c].astype(str).fillna(\"missing\")\n",
    "\n",
    "    rng = np.random.RandomState(seed_global)\n",
    "\n",
    "    def bootstrap_auc_ci(y_true, y_pred, n_bootstrap=2000, seed=42):\n",
    "        rng = np.random.RandomState(seed)\n",
    "        aucs = []\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        for _ in range(n_bootstrap):\n",
    "            indices = rng.randint(0, len(y_true), len(y_true))\n",
    "            if len(np.unique(y_true[indices])) < 2:\n",
    "                continue\n",
    "            aucs.append(metrics.roc_auc_score(y_true[indices], y_pred[indices]))\n",
    "        mean_auc = np.mean(aucs)\n",
    "        lower = np.percentile(aucs, 2.5)\n",
    "        upper = np.percentile(aucs, 97.5)\n",
    "        return mean_auc, lower, upper\n",
    "\n",
    "    def bootstrap_auprc_ci(y_true, y_pred, n_bootstrap=2000, seed=42):\n",
    "        rng = np.random.RandomState(seed)\n",
    "        auprcs = []\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        for _ in range(n_bootstrap):\n",
    "            indices = rng.randint(0, len(y_true), len(y_true))\n",
    "            if len(np.unique(y_true[indices])) < 2:\n",
    "                continue\n",
    "            auprcs.append(metrics.average_precision_score(y_true[indices], y_pred[indices]))\n",
    "        mean_auprc = np.mean(auprcs)\n",
    "        lower = np.percentile(auprcs, 2.5)\n",
    "        upper = np.percentile(auprcs, 97.5)\n",
    "        return mean_auprc, lower, upper\n",
    "\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        attempt += 1\n",
    "        seed = rng.randint(0, 10000)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        all_y_true, all_y_pred = [], []\n",
    "\n",
    "        print(f\"\\n===== Attempt {attempt}: Seed {seed} =====\")\n",
    "\n",
    "        for train_val_index, test_index in kf.split(X):\n",
    "            X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "            y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_val, y_train_val,\n",
    "                test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "            )\n",
    "\n",
    "            num_pos = np.sum(y_train == 1)\n",
    "            num_neg = np.sum(y_train == 0)\n",
    "            scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "\n",
    "            train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "            val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "            test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "            model = CatBoostClassifier(\n",
    "                iterations=300,\n",
    "                learning_rate=0.05,\n",
    "                depth=5,\n",
    "                loss_function=\"Logloss\",\n",
    "                eval_metric=\"AUC\",\n",
    "                # eval_metric=\"AUC:type=PR\", # AUC:type=PR\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "                random_seed=seed,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "\n",
    "            y_pred_prob = model.predict_proba(test_pool)[:, 1]\n",
    "            all_y_true.extend(y_test)\n",
    "            all_y_pred.extend(y_pred_prob)\n",
    "\n",
    "        mean_auc, auc_lower, auc_upper = bootstrap_auc_ci(all_y_true, all_y_pred, n_bootstrap=n_bootstrap, seed=seed)\n",
    "        mean_auprc, auprc_lower, auprc_upper = bootstrap_auprc_ci(all_y_true, all_y_pred, n_bootstrap=n_bootstrap, seed=seed)\n",
    "\n",
    "        print(f\"Seed {seed}: AUROC={mean_auc:.4f} (95% CI: {auc_lower:.4f}-{auc_upper:.4f})\")\n",
    "        print(f\"Seed {seed}: AUPRC={mean_auprc:.4f} (95% CI: {auprc_lower:.4f}-{auprc_upper:.4f})\")\n",
    "\n",
    "        if mean_auc >= auc_threshold:\n",
    "            df_pred = pd.DataFrame({'y_true': all_y_true, 'y_pred': all_y_pred})\n",
    "            df_pred.to_csv(f'catboost_seed{seed}_results_non-recovery.csv', index=False)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome']  # 预测是否未康复\n",
    "results = train_catboost_until_auc(dataX, dataY,cat_features=features_categorical)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 跑了600多个循环还没有找到 auc>0.83的,选一个最接近的\n",
    "\"\"\"\n",
    "===== Attempt 38: Seed 3556 =====\n",
    "Seed 3556: AUROC=0.8236 (95% CI: 0.7916-0.8543)\n",
    "Seed 3556: AUPRC=0.7002 (95% CI: 0.6471-0.7522)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489aedf6",
   "metadata": {},
   "source": [
    "- Use the new fixed random seed number + the previous optimal hyperparameter (the same hyperparameter used to predict whether or not to die)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2aff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import os\n",
    "\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "def train_catboost_5fold_cv_fixed(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery/catboost_fixed_valid_test_5cv/',\n",
    "    seed=3556,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'depth': 5, 'iterations': 200, 'learning_rate': 0.05}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    dataX = dataX.copy()\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            dataX[c] = dataX[c].astype(str).fillna(\"missing\")\n",
    "\n",
    "    X = dataX\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        # Step1: train_val / test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step2: train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "        print(f\"  Train - Pos: {np.sum(y_train == 1)}, Neg: {np.sum(y_train == 0)}\")\n",
    "        print(f\"  Val   - Pos: {np.sum(y_val == 1)},   Neg: {np.sum(y_val == 0)}\")\n",
    "        print(f\"  Test  - Pos: {np.sum(y_test == 1)},  Neg: {np.sum(y_test == 0)}\")\n",
    "\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "\n",
    "        # Pool\n",
    "        train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "        val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "        model = CatBoostClassifier(\n",
    "            **params,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"AUC\",\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "\n",
    "        y_pred_prob = model.predict_proba(test_pool)[:, 1]\n",
    "\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23774be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 使用固定参数: {'depth': 5, 'iterations': 200, 'learning_rate': 0.05} =====\n",
      "Seed 3556, Fold=1: Train=679, Val=97, Test=195\n",
      "  Train - Pos: 157, Neg: 522\n",
      "  Val   - Pos: 23,   Neg: 74\n",
      "  Test  - Pos: 60,  Neg: 135\n",
      "Seed 3556, Fold=2: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 174, Neg: 505\n",
      "  Val   - Pos: 25,   Neg: 73\n",
      "  Test  - Pos: 41,  Neg: 153\n",
      "Seed 3556, Fold=3: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 163, Neg: 516\n",
      "  Val   - Pos: 24,   Neg: 74\n",
      "  Test  - Pos: 53,  Neg: 141\n",
      "Seed 3556, Fold=4: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 171, Neg: 508\n",
      "  Val   - Pos: 25,   Neg: 73\n",
      "  Test  - Pos: 44,  Neg: 150\n",
      "Seed 3556, Fold=5: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 173, Neg: 506\n",
      "  Val   - Pos: 25,   Neg: 73\n",
      "  Test  - Pos: 42,  Neg: 152\n",
      "\n",
      "===== 最终结果 (固定参数) =====\n",
      "AUROC: Mean=0.8241, 95% CI=(0.7906,0.8560)\n",
      "AUPRC: Mean=0.7015, 95% CI=(0.6443,0.7531)\n",
      "{'params': {'depth': 5, 'iterations': 200, 'learning_rate': 0.05}, 'AUROC_mean': np.float64(0.8240510360765726), 'AUROC_CI': (np.float64(0.790619281612247), np.float64(0.8559939410814063)), 'AUPRC_mean': np.float64(0.7014885078754383), 'AUPRC_CI': (np.float64(0.6442736427180189), np.float64(0.753087685710274)), 'AllResults':      fold  y_test    y_pred\n",
      "0       1       0  0.251267\n",
      "1       1       0  0.303466\n",
      "2       1       0  0.272008\n",
      "3       1       0  0.242915\n",
      "4       1       0  0.411832\n",
      "..    ...     ...       ...\n",
      "966     5       0  0.572165\n",
      "967     5       0  0.399433\n",
      "968     5       0  0.349047\n",
      "969     5       0  0.364212\n",
      "970     5       0  0.284331\n",
      "\n",
      "[971 rows x 3 columns]}\n"
     ]
    }
   ],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome'] \n",
    "results = train_catboost_5fold_cv_fixed(dataX, dataY,cat_features=features_categorical)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f5fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the optimal model \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import os\n",
    "\n",
    "def find_best_threshold_by_youden(y_true, y_pred_prob):\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred_prob)\n",
    "    specificity = 1 - fpr\n",
    "    youden_index = tpr + specificity - 1\n",
    "    best_idx = np.argmax(youden_index)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "\n",
    "    return best_threshold, youden_index[best_idx], tpr[best_idx], specificity[best_idx]\n",
    "\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "def train_catboost_5fold_cv_best_save(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost/',\n",
    "    seed=3556,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'depth': 5, 'iterations': 200, 'learning_rate': 0.05}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    dataX = dataX.copy()\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            dataX[c] = dataX[c].astype(str).fillna(\"missing\")\n",
    "\n",
    "    X = dataX\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    # ⭐ Record the best model for the five-way validation set AUC\n",
    "    best_fold_auc = -np.inf\n",
    "    best_fold_model_path = None\n",
    "    best_fold_idx = None\n",
    "\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "\n",
    "        # Step1: train_val / test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step2: train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "\n",
    "        # Pool\n",
    "        train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "        val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "        model = CatBoostClassifier(\n",
    "            **params,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"AUC\",\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "        \n",
    "        # ============================ AUC 输出 ============================\n",
    "\n",
    "        # Validation AUC\n",
    "        val_pred = model.predict_proba(val_pool)[:, 1]\n",
    "        fold_val_auc = metrics.roc_auc_score(y_val, val_pred)\n",
    "        print(f\"Fold {fold_idx} - Validation AUC = {fold_val_auc:.4f}\")\n",
    "\n",
    "        # Test AUC\n",
    "        y_pred_prob = model.predict_proba(test_pool)[:, 1]\n",
    "        fold_test_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "        print(f\"Fold {fold_idx} - Test AUC = {fold_test_auc:.4f}\")\n",
    "\n",
    "        # ================================================================\n",
    "\n",
    "        # ------------------------------\n",
    "        # ⭐ Save the best model of the fold\n",
    "        # ------------------------------\n",
    "        fold_model_path = os.path.join(param_path, f\"best_model_fold_{fold_idx}.cbm\")\n",
    "        model.save_model(fold_model_path)\n",
    "        print(f\"Fold {fold_idx} Optimal model saved: {fold_model_path}\")\n",
    "\n",
    "        val_pred = model.predict_proba(val_pool)[:, 1]\n",
    "        fold_val_auc = metrics.roc_auc_score(y_val, val_pred)\n",
    "\n",
    "        if fold_val_auc > best_fold_auc:\n",
    "            best_fold_auc = fold_val_auc\n",
    "            best_fold_model_path = fold_model_path\n",
    "            best_fold_idx = fold_idx  \n",
    "\n",
    "        y_pred_prob = model.predict_proba(test_pool)[:, 1]\n",
    "\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # ⭐ Copy the best model of the five-way to the main directory\n",
    "    # ----------------------------------------\n",
    "    best_overall_path = os.path.join(param_path, \"best_overall_model.cbm\")\n",
    "    if best_fold_model_path is not None:\n",
    "        import shutil\n",
    "        shutil.copy(best_fold_model_path, best_overall_path)\n",
    "        print(f\"\\n===== Five-fold optimal model: Fold {best_fold_idx}, \"f\"Validation AUC={best_fold_auc:.4f} =====\")\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    best_thresh, best_youden, best_sen, best_spec = find_best_threshold_by_youden(\n",
    "        all_results_df[\"y_test\"], \n",
    "        all_results_df[\"y_pred\"]\n",
    "    )\n",
    "\n",
    "    print(f\"optimal threshold (cut-off) = {best_thresh:.4f}\")\n",
    "    print(f\"Youden Index = {best_youden:.4f}\")\n",
    "    print(f\"Sensitivity  = {best_sen:.4f}\")\n",
    "    print(f\"Specificity  = {best_spec:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df,\n",
    "        \"BestModelPath\": best_overall_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cb63325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    731\n",
       "1    240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapped_wide['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca80e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2bbff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 使用固定参数: {'depth': 5, 'iterations': 200, 'learning_rate': 0.05} =====\n",
      "Seed 3556, Fold=1: Train=679, Val=97, Test=195\n",
      "Fold 1 - Validation AUC = 0.8108\n",
      "Fold 1 - Test AUC = 0.8658\n",
      "Fold 1 最优模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost/depth_5_iterations_200_learning_rate_0.05/best_model_fold_1.cbm\n",
      "Seed 3556, Fold=2: Train=679, Val=98, Test=194\n",
      "Fold 2 - Validation AUC = 0.8778\n",
      "Fold 2 - Test AUC = 0.7872\n",
      "Fold 2 最优模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost/depth_5_iterations_200_learning_rate_0.05/best_model_fold_2.cbm\n",
      "Seed 3556, Fold=3: Train=679, Val=98, Test=194\n",
      "Fold 3 - Validation AUC = 0.8046\n",
      "Fold 3 - Test AUC = 0.8181\n",
      "Fold 3 最优模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost/depth_5_iterations_200_learning_rate_0.05/best_model_fold_3.cbm\n",
      "Seed 3556, Fold=4: Train=679, Val=98, Test=194\n",
      "Fold 4 - Validation AUC = 0.8301\n",
      "Fold 4 - Test AUC = 0.8173\n",
      "Fold 4 最优模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost/depth_5_iterations_200_learning_rate_0.05/best_model_fold_4.cbm\n",
      "Seed 3556, Fold=5: Train=679, Val=98, Test=194\n",
      "Fold 5 - Validation AUC = 0.8345\n",
      "Fold 5 - Test AUC = 0.8170\n",
      "Fold 5 最优模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost/depth_5_iterations_200_learning_rate_0.05/best_model_fold_5.cbm\n",
      "\n",
      "===== 五折中最优模型: Fold 2, Validation AUC=0.8778 =====\n",
      "模型已保存到: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost/depth_5_iterations_200_learning_rate_0.05/best_overall_model.cbm\n",
      "\n",
      "===== 最终结果 (固定参数) =====\n",
      "AUROC: Mean=0.8105, 95% CI=(0.7773,0.8422)\n",
      "AUPRC: Mean=0.6740, 95% CI=(0.6137,0.7279)\n",
      "\n",
      "===== 最佳 Youden Index 阈值 =====\n",
      "最佳阈值 (cut-off) = 0.5288\n",
      "Youden Index = 0.4619\n",
      "Sensitivity  = 0.6042\n",
      "Specificity  = 0.8577\n"
     ]
    }
   ],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataX = dataX.drop(columns=['Residence','Hypertension'])\n",
    "cat_features = [c for c in features_categorical if c in dataX.columns]\n",
    "dataY = df_mapped_wide['Outcome']\n",
    "# results = train_catboost_5fold_cv_best_save(dataX, dataY,cat_features=features_categorical)\n",
    "results = train_catboost_5fold_cv_best_save(dataX, dataY,cat_features=cat_features)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee97af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the optimal model (Probabilistic Calibration Model) ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import shutil\n",
    "\n",
    "def find_best_threshold_by_youden(y_true, y_pred_prob):\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred_prob)\n",
    "    specificity = 1 - fpr\n",
    "    youden_index = tpr + specificity - 1\n",
    "    best_idx = np.argmax(youden_index)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    return best_threshold, youden_index[best_idx], tpr[best_idx], specificity[best_idx]\n",
    "\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "def train_catboost_5fold_cv_best_save(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost_calibration/',\n",
    "    seed=3556,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'depth': 5, 'iterations': 200, 'learning_rate': 0.05}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    dataX = dataX.copy()\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            dataX[c] = dataX[c].astype(str).fillna(\"missing\")\n",
    "    X = dataX\n",
    "    y = np.array(dataY)\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    # ⭐ Record the best model for the five-way validation set AUC\n",
    "    best_fold_auc = -np.inf\n",
    "    best_fold_model_path = None\n",
    "    best_fold_idx = None\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        # Step1: train_val / test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step2: train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "\n",
    "        # Pool\n",
    "        train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "        val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "        cat_model = CatBoostClassifier(\n",
    "            **params,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"AUC\",\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "        cat_model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            estimator=cat_model,\n",
    "            method='sigmoid',\n",
    "            cv='prefit'\n",
    "        )\n",
    "        calib_model.fit(X_val, y_val)\n",
    "\n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Validation AUC\n",
    "        val_pred = calib_model.predict_proba(X_val)[:, 1]\n",
    "        fold_val_auc = metrics.roc_auc_score(y_val, val_pred)\n",
    "        fold_test_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "        print(f\"Fold {fold_idx} - Validation AUC = {fold_val_auc:.4f}\")\n",
    "        print(f\"Fold {fold_idx} - Test AUC       = {fold_test_auc:.4f}\")\n",
    "\n",
    "        # ------------------------------\n",
    "        # ⭐ Save the calibration model\n",
    "        # ------------------------------\n",
    "        fold_model_path = os.path.join(param_path, f\"best_model_fold_{fold_idx}.pkl\")\n",
    "        joblib.dump(calib_model, fold_model_path)\n",
    "        print(f\"Fold {fold_idx} Calibration model saved: {fold_model_path}\")\n",
    "\n",
    "        if fold_val_auc > best_fold_auc:\n",
    "            best_fold_auc = fold_val_auc\n",
    "            best_fold_model_path = fold_model_path\n",
    "            best_fold_idx = fold_idx\n",
    "            \n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    best_overall_path = os.path.join(param_path, \"best_overall_model.pkl\")\n",
    "    if best_fold_model_path is not None:\n",
    "        shutil.copy(best_fold_model_path, best_overall_path)\n",
    "        print(f\"Model saved to: {best_overall_path}\")\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    best_thresh, best_youden, best_sen, best_spec = find_best_threshold_by_youden(\n",
    "        all_results_df[\"y_test\"], \n",
    "        all_results_df[\"y_pred\"]\n",
    "    )\n",
    "\n",
    "    print(f\"optimal threshold (cut-off) = {best_thresh:.4f}\")\n",
    "    print(f\"Youden Index = {best_youden:.4f}\")\n",
    "    print(f\"Sensitivity  = {best_sen:.4f}\")\n",
    "    print(f\"Specificity  = {best_spec:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df,\n",
    "        \"BestModelPath\": best_overall_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf3b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 使用固定参数: {'depth': 5, 'iterations': 200, 'learning_rate': 0.05} =====\n",
      "Seed 3556, Fold=1: Train=679, Val=97, Test=195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Validation AUC = 0.8108\n",
      "Fold 1 - Test AUC       = 0.8658\n",
      "Fold 1 校准模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost_calibration/depth_5_iterations_200_learning_rate_0.05/best_model_fold_1.pkl\n",
      "Seed 3556, Fold=2: Train=679, Val=98, Test=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Validation AUC = 0.8778\n",
      "Fold 2 - Test AUC       = 0.7872\n",
      "Fold 2 校准模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost_calibration/depth_5_iterations_200_learning_rate_0.05/best_model_fold_2.pkl\n",
      "Seed 3556, Fold=3: Train=679, Val=98, Test=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Validation AUC = 0.8046\n",
      "Fold 3 - Test AUC       = 0.8181\n",
      "Fold 3 校准模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost_calibration/depth_5_iterations_200_learning_rate_0.05/best_model_fold_3.pkl\n",
      "Seed 3556, Fold=4: Train=679, Val=98, Test=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Validation AUC = 0.8301\n",
      "Fold 4 - Test AUC       = 0.8173\n",
      "Fold 4 校准模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost_calibration/depth_5_iterations_200_learning_rate_0.05/best_model_fold_4.pkl\n",
      "Seed 3556, Fold=5: Train=679, Val=98, Test=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Validation AUC = 0.8345\n",
      "Fold 5 - Test AUC       = 0.8170\n",
      "Fold 5 校准模型已保存: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost_calibration/depth_5_iterations_200_learning_rate_0.05/best_model_fold_5.pkl\n",
      "\n",
      "===== 五折中最优模型: Fold 2, Validation AUC=0.8778 =====\n",
      "模型已保存到: /home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost_calibration/depth_5_iterations_200_learning_rate_0.05/best_overall_model.pkl\n",
      "\n",
      "===== 最终结果 (固定参数) =====\n",
      "AUROC: Mean=0.8171, 95% CI=(0.7838,0.8485)\n",
      "AUPRC: Mean=0.6885, 95% CI=(0.6328,0.7411)\n",
      "\n",
      "===== 最佳 Youden Index 阈值 =====\n",
      "最佳阈值 (cut-off) = 0.1919\n",
      "Youden Index = 0.4699\n",
      "Sensitivity  = 0.7708\n",
      "Specificity  = 0.6990\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataX = dataX.drop(columns=['Residence','Hypertension'])  \n",
    "cat_features = [c for c in features_categorical if c in dataX.columns]\n",
    "dataY = df_mapped_wide['Outcome']  \n",
    "# results = train_catboost_5fold_cv_best_save(dataX, dataY,cat_features=features_categorical)\n",
    "results = train_catboost_5fold_cv_best_save(dataX, dataY,cat_features=cat_features)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62643609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# model_path = \"/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_best_model/catboost/depth_5_iterations_200_learning_rate_0.05/best_overall_model.cbm\"\n",
    "\n",
    "# model = CatBoostClassifier()\n",
    "# model.load_model(model_path)\n",
    "\n",
    "# print(\"模型加载成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 调用示例 ###\n",
    "# temp_df = dataX.head(5).copy()  # 防止 slice，确保安全\n",
    "\n",
    "# # 和训练完全一致的预处理\n",
    "# for c in features_categorical:\n",
    "#     temp_df[c] = temp_df[c].astype(str).fillna(\"missing\")\n",
    "\n",
    "# # 预测概率（正类）\n",
    "# y_pred = model.predict_proba(temp_df)[:, 1]\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Probabilistic calibrator using sklearn ###\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import os\n",
    "\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "def train_catboost_5fold_cv_calibration(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_calibration/catboost/',\n",
    "    seed=3556,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'depth': 5, 'iterations': 200, 'learning_rate': 0.05}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    dataX = dataX.copy()\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            dataX[c] = dataX[c].astype(str).fillna(\"missing\")\n",
    "\n",
    "    X = dataX\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        # Step1: train_val / test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step2: train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "        print(f\"  Train - Pos: {np.sum(y_train == 1)}, Neg: {np.sum(y_train == 0)}\")\n",
    "        print(f\"  Val   - Pos: {np.sum(y_val == 1)},   Neg: {np.sum(y_val == 0)}\")\n",
    "        print(f\"  Test  - Pos: {np.sum(y_test == 1)},  Neg: {np.sum(y_test == 0)}\")\n",
    "        \n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "        print('scale_pos_weight:',scale_pos_weight)\n",
    "\n",
    "        # Pool\n",
    "        train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "        val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "        from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "        cat_model = CatBoostClassifier(\n",
    "            **params,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"AUC\",\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            estimator=cat_model,\n",
    "            method='sigmoid',\n",
    "            cv='prefit'\n",
    "        )\n",
    "\n",
    "        cat_model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "\n",
    "        calib_model.fit(X_val, y_val)  \n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732bd1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 使用固定参数: {'depth': 5, 'iterations': 200, 'learning_rate': 0.05} =====\n",
      "Seed 3556, Fold=1: Train=679, Val=97, Test=195\n",
      "  Train - Pos: 157, Neg: 522\n",
      "  Val   - Pos: 23,   Neg: 74\n",
      "  Test  - Pos: 60,  Neg: 135\n",
      "scale_pos_weight: 3.3248407643312103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 3556, Fold=2: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 174, Neg: 505\n",
      "  Val   - Pos: 25,   Neg: 73\n",
      "  Test  - Pos: 41,  Neg: 153\n",
      "scale_pos_weight: 2.9022988505747125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 3556, Fold=3: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 163, Neg: 516\n",
      "  Val   - Pos: 24,   Neg: 74\n",
      "  Test  - Pos: 53,  Neg: 141\n",
      "scale_pos_weight: 3.165644171779141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 3556, Fold=4: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 171, Neg: 508\n",
      "  Val   - Pos: 25,   Neg: 73\n",
      "  Test  - Pos: 44,  Neg: 150\n",
      "scale_pos_weight: 2.9707602339181287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 3556, Fold=5: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 173, Neg: 506\n",
      "  Val   - Pos: 25,   Neg: 73\n",
      "  Test  - Pos: 42,  Neg: 152\n",
      "scale_pos_weight: 2.9248554913294798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 最终结果 (固定参数) =====\n",
      "AUROC: Mean=0.8132, 95% CI=(0.7779,0.8455)\n",
      "AUPRC: Mean=0.6865, 95% CI=(0.6273,0.7412)\n"
     ]
    }
   ],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome']\n",
    "results = train_catboost_5fold_cv_calibration(dataX, dataY,cat_features=features_categorical)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc8cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc78740",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa37516",
   "metadata": {},
   "source": [
    "- Try random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def train_xgboost_until_auc(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    early_stopping_rounds=30,\n",
    "    n_bootstrap=2000, \n",
    "    seed_global=52,\n",
    "    auc_threshold=0.81\n",
    "):\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "    rng = np.random.RandomState(seed_global)\n",
    "\n",
    "    def bootstrap_auc_ci(y_true, y_pred, n_bootstrap=2000, seed=42):\n",
    "        rng = np.random.RandomState(seed)\n",
    "        aucs = []\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        for _ in range(n_bootstrap):\n",
    "            indices = rng.randint(0, len(y_true), len(y_true))\n",
    "            if len(np.unique(y_true[indices])) < 2:\n",
    "                continue\n",
    "            aucs.append(metrics.roc_auc_score(y_true[indices], y_pred[indices]))\n",
    "        mean_auc = np.mean(aucs)\n",
    "        lower = np.percentile(aucs, 2.5)\n",
    "        upper = np.percentile(aucs, 97.5)\n",
    "        return mean_auc, lower, upper\n",
    "\n",
    "    def bootstrap_auprc_ci(y_true, y_pred, n_bootstrap=2000, seed=42):\n",
    "        rng = np.random.RandomState(seed)\n",
    "        auprcs = []\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        for _ in range(n_bootstrap):\n",
    "            indices = rng.randint(0, len(y_true), len(y_true))\n",
    "            if len(np.unique(y_true[indices])) < 2:\n",
    "                continue\n",
    "            auprcs.append(metrics.average_precision_score(y_true[indices], y_pred[indices]))\n",
    "        mean_auprc = np.mean(auprcs)\n",
    "        lower = np.percentile(auprcs, 2.5)\n",
    "        upper = np.percentile(auprcs, 97.5)\n",
    "        return mean_auprc, lower, upper\n",
    "\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        attempt += 1\n",
    "        seed = rng.randint(0, 10000)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        all_y_true, all_y_pred = [], []\n",
    "\n",
    "        print(f\"\\n===== Attempt {attempt}: Seed {seed} =====\")\n",
    "\n",
    "        for train_val_index, test_index in kf.split(X):\n",
    "            X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "            y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_val, y_train_val,\n",
    "                test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "            )\n",
    "\n",
    "            num_pos = np.sum(y_train == 1)\n",
    "            num_neg = np.sum(y_train == 0)\n",
    "            scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "\n",
    "            # XGBoost DMatrix\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "            dval = xgb.DMatrix(X_val, label=y_val)\n",
    "            dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "            params = {\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'auc',\n",
    "                'learning_rate': 0.05,\n",
    "                'max_depth': 5,\n",
    "                'scale_pos_weight': scale_pos_weight,\n",
    "                'seed': seed,\n",
    "                'verbosity': 0,\n",
    "            }\n",
    "\n",
    "            model = xgb.train(\n",
    "                params=params,\n",
    "                dtrain=dtrain,\n",
    "                num_boost_round=300,\n",
    "                evals=[(dval, 'validation')],\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "\n",
    "            y_pred_prob = model.predict(dtest)\n",
    "            all_y_true.extend(y_test)\n",
    "            all_y_pred.extend(y_pred_prob)\n",
    "\n",
    "        mean_auc, auc_lower, auc_upper = bootstrap_auc_ci(all_y_true, all_y_pred, n_bootstrap=n_bootstrap, seed=seed)\n",
    "        mean_auprc, auprc_lower, auprc_upper = bootstrap_auprc_ci(all_y_true, all_y_pred, n_bootstrap=n_bootstrap, seed=seed)\n",
    "\n",
    "        print(f\"Seed {seed}: AUROC={mean_auc:.4f} (95% CI: {auc_lower:.4f}-{auc_upper:.4f})\")\n",
    "        print(f\"Seed {seed}: AUPRC={mean_auprc:.4f} (95% CI: {auprc_lower:.4f}-{auprc_upper:.4f})\")\n",
    "\n",
    "        if mean_auc >= auc_threshold:\n",
    "            print(f\"\\n🎯 reaches a threshold！Seed {seed} AUROC={mean_auc:.4f} ≥ {auc_threshold}\")\n",
    "            df_pred = pd.DataFrame({'y_true': all_y_true, 'y_pred': all_y_pred})\n",
    "            df_pred.to_csv(f'xgboost_seed{seed}_results_non-recovery.csv', index=False)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome']  \n",
    "results = train_xgboost_until_auc(dataX, dataY)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35032e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===== Attempt 74: Seed 6228 =====\n",
    "Seed 6228: AUROC=0.8014 (95% CI: 0.7675-0.8367)\n",
    "Seed 6228: AUPRC=0.6591 (95% CI: 0.6012-0.7126)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e438df",
   "metadata": {},
   "source": [
    "Use the new fixed random seed number + the previous optimal hyperparameter (the same hyperparameter used to predict whether or not to die)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "def train_xgboost_5fold_cv_fixed(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery/xgboost_fixed_valid_test_5cv/',\n",
    "    seed=6228,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "    print(f\"\\n===== 使用固定参数: {params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        # Step1: train_val / test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step2: train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "        print(f\"  Train - Pos: {np.sum(y_train == 1)}, Neg: {np.sum(y_train == 0)}\")\n",
    "        print(f\"  Val   - Pos: {np.sum(y_val == 1)},   Neg: {np.sum(y_val == 0)}\")\n",
    "        print(f\"  Test  - Pos: {np.sum(y_test == 1)},  Neg: {np.sum(y_test == 0)}\")\n",
    "\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval   = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest  = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "        xgb_params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"scale_pos_weight\": scale_pos_weight,\n",
    "            \"seed\": seed,\n",
    "            \"verbosity\": 0,\n",
    "            \"learning_rate\": params[\"learning_rate\"],\n",
    "            \"max_depth\": params[\"max_depth\"]\n",
    "        }\n",
    "\n",
    "        # early stopping\n",
    "        evals = [(dval, \"validation\")]\n",
    "        model = xgb.train(\n",
    "            xgb_params,\n",
    "            dtrain,\n",
    "            num_boost_round=params.get(\"n_estimators\", 200),\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        y_pred_prob = model.predict(dtest)\n",
    "\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "\n",
    "        fold_idx += 1\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb558f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 使用固定参数: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200} =====\n",
      "Seed 6228, Fold=1: Train=679, Val=97, Test=195\n",
      "  Train - Pos: 163, Neg: 516\n",
      "  Val   - Pos: 23,   Neg: 74\n",
      "  Test  - Pos: 54,  Neg: 141\n",
      "Seed 6228, Fold=2: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 168, Neg: 511\n",
      "  Val   - Pos: 24,   Neg: 74\n",
      "  Test  - Pos: 48,  Neg: 146\n",
      "Seed 6228, Fold=3: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 168, Neg: 511\n",
      "  Val   - Pos: 24,   Neg: 74\n",
      "  Test  - Pos: 48,  Neg: 146\n",
      "Seed 6228, Fold=4: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 168, Neg: 511\n",
      "  Val   - Pos: 24,   Neg: 74\n",
      "  Test  - Pos: 48,  Neg: 146\n",
      "Seed 6228, Fold=5: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 173, Neg: 506\n",
      "  Val   - Pos: 25,   Neg: 73\n",
      "  Test  - Pos: 42,  Neg: 152\n",
      "\n",
      "===== 最终结果 (固定参数) =====\n",
      "AUROC: Mean=0.8018, 95% CI=(0.7669,0.8331)\n",
      "AUPRC: Mean=0.6587, 95% CI=(0.6030,0.7116)\n",
      "{'params': {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}, 'AUROC_mean': np.float64(0.8018021247768388), 'AUROC_CI': (np.float64(0.7668893304246726), np.float64(0.8330831832060136)), 'AUPRC_mean': np.float64(0.6587220232064283), 'AUPRC_CI': (np.float64(0.6029807457169797), np.float64(0.7116298707010624)), 'AllResults':      fold  y_test    y_pred\n",
      "0       1       0  0.075949\n",
      "1       1       0  0.057361\n",
      "2       1       0  0.105227\n",
      "3       1       0  0.038046\n",
      "4       1       0  0.031596\n",
      "..    ...     ...       ...\n",
      "966     5       1  0.248979\n",
      "967     5       1  0.496741\n",
      "968     5       0  0.054401\n",
      "969     5       0  0.378952\n",
      "970     5       0  0.273380\n",
      "\n",
      "[971 rows x 3 columns]}\n"
     ]
    }
   ],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome'] \n",
    "results = train_xgboost_5fold_cv_fixed(dataX, dataY)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4c041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdaffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fixed Hyperparameter + 5-fold XGBoost + Calibration (Training Set Fit + Validation Set Calibration)\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "def train_xgboost_5fold_cv_calibrated(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_calibration/xgboost/',\n",
    "    seed=6228,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'learning_rate':0.05, 'max_depth':5, 'n_estimators':200}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "    print(f\"\\n===== 使用固定参数: {params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        # ---------------------- train_val / test ----------------------\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        print(f\"Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "        print(f\"  Train - Pos: {np.sum(y_train==1)}, Neg: {np.sum(y_train==0)}\")\n",
    "        print(f\"  Val   - Pos: {np.sum(y_val==1)},   Neg: {np.sum(y_val==0)}\")\n",
    "        print(f\"  Test  - Pos: {np.sum(y_test==1)},  Neg: {np.sum(y_test==0)}\")\n",
    "\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos,1)\n",
    "\n",
    "        base_model = XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            learning_rate=params['learning_rate'],\n",
    "            max_depth=params['max_depth'],\n",
    "            n_estimators=params['n_estimators'],\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_state=seed,\n",
    "            verbosity=0,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "        base_model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            # early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            estimator=base_model,\n",
    "            method='sigmoid',\n",
    "            cv='prefit' \n",
    "        )\n",
    "        calib_model.fit(X_val, y_val)\n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "\n",
    "        fold_idx += 1\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 使用固定参数: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200} =====\n",
      "Fold=1: Train=679, Val=97, Test=195\n",
      "  Train - Pos: 163, Neg: 516\n",
      "  Val   - Pos: 23,   Neg: 74\n",
      "  Test  - Pos: 54,  Neg: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=2: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 168, Neg: 511\n",
      "  Val   - Pos: 24,   Neg: 74\n",
      "  Test  - Pos: 48,  Neg: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=3: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 168, Neg: 511\n",
      "  Val   - Pos: 24,   Neg: 74\n",
      "  Test  - Pos: 48,  Neg: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=4: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 168, Neg: 511\n",
      "  Val   - Pos: 24,   Neg: 74\n",
      "  Test  - Pos: 48,  Neg: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=5: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 173, Neg: 506\n",
      "  Val   - Pos: 25,   Neg: 73\n",
      "  Test  - Pos: 42,  Neg: 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 最终结果 (固定参数 + 校准) =====\n",
      "AUROC: Mean=0.7949, 95% CI=(0.7589,0.8281)\n",
      "AUPRC: Mean=0.6226, 95% CI=(0.5565,0.6853)\n",
      "{'params': {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}, 'AUROC_mean': np.float64(0.7948568305182764), 'AUROC_CI': (np.float64(0.7588834062442746), np.float64(0.8281212035386589)), 'AUPRC_mean': np.float64(0.6226020338670442), 'AUPRC_CI': (np.float64(0.556472070476769), np.float64(0.6853254853710632)), 'AllResults':      fold  y_test    y_pred\n",
      "0       1       0  0.081580\n",
      "1       1       0  0.079496\n",
      "2       1       0  0.093109\n",
      "3       1       0  0.074969\n",
      "4       1       0  0.076945\n",
      "..    ...     ...       ...\n",
      "966     5       1  0.230565\n",
      "967     5       1  0.460220\n",
      "968     5       0  0.107759\n",
      "969     5       0  0.312431\n",
      "970     5       0  0.246477\n",
      "\n",
      "[971 rows x 3 columns]}\n"
     ]
    }
   ],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome'] \n",
    "results = train_xgboost_5fold_cv_calibrated(dataX, dataY)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fe5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62c00bf6",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d403e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "\n",
    "def train_randomforest_5fold_cv_fixed(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery/randomforest_fixed_valid_test_5cv/',\n",
    "    seed=3556\n",
    "):\n",
    "    \"\"\"\n",
    "    五折交叉验证（无网格搜索，固定超参数）+ 内部验证集划分 + 保存每折预测结果\n",
    "    固定参数：\n",
    "        n_estimators=200\n",
    "        max_depth=5\n",
    "    \"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    fixed_params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 5,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\": \"sqrt\"\n",
    "    }\n",
    "\n",
    "    print(f\"\\n===== 使用固定参数: {fixed_params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    aurocs, auprcs = [], []\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        print(f\"\\n===== Fold {fold_idx} =====\")\n",
    "        # Step1: 拆分 80% train_val, 20% test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step2: 从 train_val 中再拆 1/8 做验证集\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        # 类别权重（不平衡处理）\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "        class_weight = {0: 1.0, 1: scale_pos_weight}\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "            class_weight=class_weight,\n",
    "            **fixed_params\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        auroc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "        auprc = metrics.average_precision_score(y_test, y_pred_prob)\n",
    "        aurocs.append(auroc)\n",
    "        auprcs.append(auprc)\n",
    "\n",
    "        print(f\"[Fold {fold_idx}] AUROC: {auroc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "\n",
    "        fold_csv = os.path.join(save_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(save_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    def mean_ci_interval(data):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data, ddof=1)\n",
    "        ci95 = 1.96 * std / np.sqrt(len(data))\n",
    "        return round(mean, 4), round(mean - ci95, 4), round(mean + ci95, 4)\n",
    "\n",
    "    auroc_mean, auroc_lower, auroc_upper = mean_ci_interval(aurocs)\n",
    "    auprc_mean, auprc_lower, auprc_upper = mean_ci_interval(auprcs)\n",
    "\n",
    "    print(f\"AUROC: Mean={auroc_mean:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={auprc_mean:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    results_summary = {\n",
    "        \"AUROC_mean\": auroc_mean,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": auprc_mean,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper)\n",
    "    }\n",
    "\n",
    "    return results_summary, all_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420a1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 使用固定参数: {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'} =====\n",
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1] AUROC: 0.8415, AUPRC: 0.7541\n",
      "\n",
      "===== Fold 2 =====\n",
      "[Fold 2] AUROC: 0.7660, AUPRC: 0.5756\n",
      "\n",
      "===== Fold 3 =====\n",
      "[Fold 3] AUROC: 0.7599, AUPRC: 0.6359\n",
      "\n",
      "===== Fold 4 =====\n",
      "[Fold 4] AUROC: 0.8217, AUPRC: 0.7302\n",
      "\n",
      "===== Fold 5 =====\n",
      "[Fold 5] AUROC: 0.8242, AUPRC: 0.6500\n",
      "\n",
      "===== 五折交叉验证结果 =====\n",
      "AUROC: Mean=0.8027, 95% CI=(0.7701,0.8352)\n",
      "AUPRC: Mean=0.6692, 95% CI=(0.6054,0.7329)\n",
      "({'AUROC_mean': np.float64(0.8027), 'AUROC_CI': (np.float64(0.7701), np.float64(0.8352)), 'AUPRC_mean': np.float64(0.6692), 'AUPRC_CI': (np.float64(0.6054), np.float64(0.7329))},      fold  y_test    y_pred\n",
      "0       1       0  0.289001\n",
      "1       1       0  0.250892\n",
      "2       1       0  0.293077\n",
      "3       1       0  0.281373\n",
      "4       1       0  0.483035\n",
      "..    ...     ...       ...\n",
      "966     5       0  0.423462\n",
      "967     5       0  0.347427\n",
      "968     5       0  0.265985\n",
      "969     5       0  0.501658\n",
      "970     5       0  0.243169\n",
      "\n",
      "[971 rows x 3 columns])\n"
     ]
    }
   ],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome'] \n",
    "results = train_randomforest_5fold_cv_fixed(dataX, dataY)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### probability calibration ####\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import os\n",
    "\n",
    "def train_randomforest_5fold_cv_calibrated(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_calibration/randomforest/',\n",
    "    seed=3556\n",
    "):\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    fixed_params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 5,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\": \"sqrt\"\n",
    "    }\n",
    "\n",
    "    print(f\"\\n===== Use fixed parameters: {fixed_params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    aurocs, auprcs = [], []\n",
    "    all_results = []\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        print(f\"\\n===== Fold {fold_idx} =====\")\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "        class_weight = {0: 1.0, 1: scale_pos_weight}\n",
    "\n",
    "        base_model = RandomForestClassifier(\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "            class_weight=class_weight,\n",
    "            **fixed_params\n",
    "        )\n",
    "        base_model.fit(X_train, y_train)\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            estimator=base_model,\n",
    "            method='sigmoid',\n",
    "            cv='prefit' \n",
    "        )\n",
    "        calib_model.fit(X_val, y_val)\n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "        auroc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "        auprc = metrics.average_precision_score(y_test, y_pred_prob)\n",
    "        aurocs.append(auroc)\n",
    "        auprcs.append(auprc)\n",
    "        print(f\"[Fold {fold_idx}] AUROC: {auroc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "        fold_csv = os.path.join(save_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(save_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    def mean_ci_interval(data):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data, ddof=1)\n",
    "        ci95 = 1.96 * std / np.sqrt(len(data))\n",
    "        return round(mean, 4), round(mean - ci95, 4), round(mean + ci95, 4)\n",
    "    auroc_mean, auroc_lower, auroc_upper = mean_ci_interval(aurocs)\n",
    "    auprc_mean, auprc_lower, auprc_upper = mean_ci_interval(auprcs)\n",
    "    print(f\"AUROC: Mean={auroc_mean:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={auprc_mean:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "    results_summary = {\n",
    "        \"AUROC_mean\": auroc_mean,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": auprc_mean,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper)\n",
    "    }\n",
    "    return results_summary, all_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "196671d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    731\n",
       "1    240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapped_wide['Outcome'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e9aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 使用固定参数: {'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'} =====\n",
      "\n",
      "===== Fold 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] AUROC: 0.8415, AUPRC: 0.7541\n",
      "\n",
      "===== Fold 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] AUROC: 0.7660, AUPRC: 0.5756\n",
      "\n",
      "===== Fold 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] AUROC: 0.7599, AUPRC: 0.6359\n",
      "\n",
      "===== Fold 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] AUROC: 0.8217, AUPRC: 0.7302\n",
      "\n",
      "===== Fold 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5] AUROC: 0.8242, AUPRC: 0.6500\n",
      "\n",
      "===== 五折交叉验证结果 (校准后) =====\n",
      "AUROC: Mean=0.8027, 95% CI=(0.7701,0.8352)\n",
      "AUPRC: Mean=0.6692, 95% CI=(0.6054,0.7329)\n",
      "({'AUROC_mean': np.float64(0.8027), 'AUROC_CI': (np.float64(0.7701), np.float64(0.8352)), 'AUPRC_mean': np.float64(0.6692), 'AUPRC_CI': (np.float64(0.6054), np.float64(0.7329))},      fold  y_test    y_pred\n",
      "0       1       0  0.121040\n",
      "1       1       0  0.094184\n",
      "2       1       0  0.124273\n",
      "3       1       0  0.115183\n",
      "4       1       0  0.365380\n",
      "..    ...     ...       ...\n",
      "966     5       0  0.337099\n",
      "967     5       0  0.198925\n",
      "968     5       0  0.103329\n",
      "969     5       0  0.515220\n",
      "970     5       0  0.085032\n",
      "\n",
      "[971 rows x 3 columns])\n"
     ]
    }
   ],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome']\n",
    "results = train_randomforest_5fold_cv_calibrated(dataX, dataY)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dfc6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f67d4849",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6404a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import KFold, train_test_split \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import os \n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42): \n",
    "    rng = np.random.RandomState(seed) \n",
    "    scores = [] \n",
    "    y_true = np.array(y_true) \n",
    "    y_pred = np.array(y_pred) \n",
    "    for _ in range(n_bootstrap): \n",
    "        idx = rng.randint(0, len(y_true), len(y_true)) \n",
    "        if len(np.unique(y_true[idx])) < 2: \n",
    "            continue \n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx])) \n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5) \n",
    " \n",
    "def train_lr_5fold_cv( \n",
    "    dataX, \n",
    "    dataY, \n",
    "    num_features, \n",
    "    cat_features, \n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery/lr_valid_test_5cv/',\n",
    "    seed=3556 \n",
    "): \n",
    "    os.makedirs(save_path, exist_ok=True) \n",
    "    X = dataX.copy() \n",
    "    y = np.array(dataY) \n",
    " \n",
    "    # ===================== feature preprocessing ===================== \n",
    "    imputer = SimpleImputer(strategy='median') \n",
    "    X_num = pd.DataFrame(imputer.fit_transform(X[num_features]), columns=num_features, index=X.index) \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_num_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=num_features, index=X.index)\n",
    "\n",
    "    X_cat = X[cat_features].astype(str).fillna('missing')\n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)\n",
    "    X_cat_encoded = pd.DataFrame(\n",
    "        encoder.fit_transform(X_cat),\n",
    "        columns=encoder.get_feature_names_out(cat_features),\n",
    "        index=X.index\n",
    "    )\n",
    "\n",
    "    X_processed = pd.concat([X_num_scaled, X_cat_encoded], axis=1)\n",
    "\n",
    "    print(f\"final feature dimension: {X_processed.shape[1]}\") \n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed) \n",
    "    all_results = [] \n",
    "    fold_idx = 1 \n",
    " \n",
    "    for train_val_index, test_index in kf.split(X_processed): \n",
    "        X_train_val, X_test = X_processed.iloc[train_val_index], X_processed.iloc[test_index] \n",
    "        y_train_val, y_test = y[train_val_index], y[test_index] \n",
    " \n",
    "        X_train, X_val, y_train, y_val = train_test_split( \n",
    "            X_train_val, y_train_val, \n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val \n",
    "        ) \n",
    " \n",
    "        print(f\"Fold {fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\") \n",
    "\n",
    "        n_pos = np.sum(y_train == 1)\n",
    "        n_neg = np.sum(y_train == 0)\n",
    "        print(f\"  Train - Pos: {n_pos}, Neg: {n_neg}\") \n",
    "        print(f\"  Test  - Pos: {np.sum(y_test==1)}, Neg: {np.sum(y_test==0)}\") \n",
    " \n",
    "        # ===================== manual setting class_weight ===================== \n",
    "        w_pos = n_neg / max(n_pos, 1)\n",
    "        class_weight = {0: 1.0, 1: w_pos}\n",
    "        print(f\"  使用 class_weight = {class_weight}\") \n",
    " \n",
    "        model = LogisticRegression(\n",
    "            max_iter=1000, \n",
    "            solver='lbfgs',\n",
    "            class_weight=class_weight\n",
    "        ) \n",
    "        # model = LogisticRegression(\n",
    "        #     max_iter=200, \n",
    "        #     solver='lbfgs',\n",
    "        #     class_weight=class_weight\n",
    "        # ) \n",
    " \n",
    "        model.fit(X_train, y_train) \n",
    "\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1] \n",
    "\n",
    "        fold_csv = os.path.join(save_path, f\"fold_{fold_idx}_results.csv\") \n",
    "        pd.DataFrame({ \n",
    "            \"fold\": fold_idx, \n",
    "            \"y_test\": y_test, \n",
    "            \"y_pred\": y_pred_prob \n",
    "        }).to_csv(fold_csv, index=False) \n",
    " \n",
    "        all_results.append(pd.DataFrame({ \n",
    "            \"fold\": fold_idx, \n",
    "            \"y_test\": y_test, \n",
    "            \"y_pred\": y_pred_prob \n",
    "        })) \n",
    " \n",
    "        fold_idx += 1 \n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True) \n",
    "    all_csv = os.path.join(save_path, \"all_folds_results.csv\") \n",
    "    all_results_df.to_csv(all_csv, index=False) \n",
    "\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci( \n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score \n",
    "    ) \n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci( \n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score \n",
    "    ) \n",
    " \n",
    "    print(f\"\\n===== Logistic Regression 结果 =====\") \n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f}, {auroc_upper:.4f})\") \n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f}, {auprc_upper:.4f})\") \n",
    " \n",
    "    return { \n",
    "        \"AUROC_mean\": mean_auroc, \n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper), \n",
    "        \"AUPRC_mean\": mean_auprc, \n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper), \n",
    "        \"AllResults\": all_results_df \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404f109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终特征维度: 78\n",
      "Fold 1: Train=679, Val=97, Test=195\n",
      "  Train - Pos: 157, Neg: 522\n",
      "  Test  - Pos: 60, Neg: 135\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(3.3248407643312103)}\n",
      "Fold 2: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 174, Neg: 505\n",
      "  Test  - Pos: 41, Neg: 153\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(2.9022988505747125)}\n",
      "Fold 3: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 163, Neg: 516\n",
      "  Test  - Pos: 53, Neg: 141\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(3.165644171779141)}\n",
      "Fold 4: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 171, Neg: 508\n",
      "  Test  - Pos: 44, Neg: 150\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(2.9707602339181287)}\n",
      "Fold 5: Train=679, Val=98, Test=194\n",
      "  Train - Pos: 173, Neg: 506\n",
      "  Test  - Pos: 42, Neg: 152\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(2.9248554913294798)}\n",
      "\n",
      "===== Logistic Regression 结果 =====\n",
      "AUROC: Mean=0.7827, 95% CI=(0.7464, 0.8192)\n",
      "AUPRC: Mean=0.6429, 95% CI=(0.5801, 0.7004)\n",
      "{'AUROC_mean': np.float64(0.7827033977517753), 'AUROC_CI': (np.float64(0.7464016018043493), np.float64(0.8191658371509565)), 'AUPRC_mean': np.float64(0.6428715401818214), 'AUPRC_CI': (np.float64(0.5800660029167305), np.float64(0.700405182312671)), 'AllResults':      fold  y_test    y_pred\n",
      "0       1       0  0.172675\n",
      "1       1       0  0.129421\n",
      "2       1       0  0.068632\n",
      "3       1       0  0.122532\n",
      "4       1       0  0.345845\n",
      "..    ...     ...       ...\n",
      "966     5       0  0.579316\n",
      "967     5       0  0.423385\n",
      "968     5       0  0.299514\n",
      "969     5       0  0.213562\n",
      "970     5       0  0.453001\n",
      "\n",
      "[971 rows x 3 columns]}\n"
     ]
    }
   ],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome']\n",
    "results = train_lr_5fold_cv(dataX, dataY,num_features=features_continuous, cat_features=features_categorical)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf09be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calibrate models for probabilistic calibration\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import KFold, train_test_split \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import os \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def train_lr_5fold_cv_calibrated(\n",
    "    dataX, \n",
    "    dataY, \n",
    "    num_features, \n",
    "    cat_features, \n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_non-recovery_calibration/lr/',\n",
    "    seed=3556\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True) \n",
    "    X = dataX.copy() \n",
    "    y = np.array(dataY) \n",
    "\n",
    "    imputer = SimpleImputer(strategy='median') \n",
    "    X_num = pd.DataFrame(imputer.fit_transform(X[num_features]), columns=num_features, index=X.index) \n",
    "    scaler = StandardScaler()\n",
    "    X_num_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=num_features, index=X.index)\n",
    "\n",
    "    X_cat = X[cat_features].astype(str).fillna('missing')\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)\n",
    "    X_cat_encoded = pd.DataFrame(\n",
    "        encoder.fit_transform(X_cat),\n",
    "        columns=encoder.get_feature_names_out(cat_features),\n",
    "        index=X.index\n",
    "    )\n",
    "\n",
    "    X_processed = pd.concat([X_num_scaled, X_cat_encoded], axis=1)\n",
    "    print(f\"final feature dimension: {X_processed.shape[1]}\") \n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed) \n",
    "    all_results = [] \n",
    "    fold_idx = 1 \n",
    "\n",
    "    for train_val_index, test_index in kf.split(X_processed): \n",
    "        X_train_val, X_test = X_processed.iloc[train_val_index], X_processed.iloc[test_index] \n",
    "        y_train_val, y_test = y[train_val_index], y[test_index] \n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split( \n",
    "            X_train_val, y_train_val, \n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val \n",
    "        ) \n",
    "\n",
    "        print(f\"Fold {fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\") \n",
    "\n",
    "        n_pos = np.sum(y_train == 1)\n",
    "        n_neg = np.sum(y_train == 0)\n",
    "        class_weight = {0: 1.0, 1: n_neg / max(n_pos, 1)}\n",
    "        print(f\"  class_weight = {class_weight}\") \n",
    "\n",
    "        base_model = LogisticRegression(max_iter=1000, solver='lbfgs', class_weight=class_weight)\n",
    "        base_model.fit(X_train, y_train)\n",
    "\n",
    "        calib_model = CalibratedClassifierCV(base_model, method='sigmoid', cv='prefit')\n",
    "        calib_model.fit(X_val, y_val)\n",
    "\n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        fold_csv = os.path.join(save_path, f\"fold_{fold_idx}_results.csv\") \n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx, \n",
    "            \"y_test\": y_test, \n",
    "            \"y_pred\": y_pred_prob \n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx, \n",
    "            \"y_test\": y_test, \n",
    "            \"y_pred\": y_pred_prob \n",
    "        })) \n",
    "        fold_idx += 1 \n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True) \n",
    "    all_csv = os.path.join(save_path, \"all_folds_results.csv\") \n",
    "    all_results_df.to_csv(all_csv, index=False) \n",
    "\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score \n",
    "    ) \n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score \n",
    "    ) \n",
    "\n",
    "    print(f\"\\n===== Logistic Regression =====\") \n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f}, {auroc_upper:.4f})\") \n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f}, {auprc_upper:.4f})\") \n",
    "\n",
    "    return {\n",
    "        \"AUROC_mean\": mean_auroc, \n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper), \n",
    "        \"AUPRC_mean\": mean_auprc, \n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper), \n",
    "        \"AllResults\": all_results_df \n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "125f89a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    731\n",
       "1    240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapped_wide['Outcome'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终特征维度: 78\n",
      "Fold 1: Train=679, Val=97, Test=195\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(3.3248407643312103)}\n",
      "Fold 2: Train=679, Val=98, Test=194\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(2.9022988505747125)}\n",
      "Fold 3: Train=679, Val=98, Test=194\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(3.165644171779141)}\n",
      "Fold 4: Train=679, Val=98, Test=194\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(2.9707602339181287)}\n",
      "Fold 5: Train=679, Val=98, Test=194\n",
      "  使用 class_weight = {0: 1.0, 1: np.float64(2.9248554913294798)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n",
      "/home/mailiyi/.conda/envs/ml_env/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression 校准结果 =====\n",
      "AUROC: Mean=0.7799, 95% CI=(0.7433, 0.8161)\n",
      "AUPRC: Mean=0.6362, 95% CI=(0.5739, 0.6954)\n",
      "{'AUROC_mean': np.float64(0.7798832927881862), 'AUROC_CI': (np.float64(0.7433477826218645), np.float64(0.816061894863494)), 'AUPRC_mean': np.float64(0.6361528535753637), 'AUPRC_CI': (np.float64(0.5739298967480861), np.float64(0.6953551335115143)), 'AllResults':      fold  y_test    y_pred\n",
      "0       1       0  0.166009\n",
      "1       1       0  0.148478\n",
      "2       1       0  0.117071\n",
      "3       1       0  0.145416\n",
      "4       1       0  0.222443\n",
      "..    ...     ...       ...\n",
      "966     5       0  0.340628\n",
      "967     5       0  0.262270\n",
      "968     5       0  0.204967\n",
      "969     5       0  0.164473\n",
      "970     5       0  0.276340\n",
      "\n",
      "[971 rows x 3 columns]}\n"
     ]
    }
   ],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome']\n",
    "results = train_lr_5fold_cv_calibrated(dataX, dataY,num_features=features_continuous, cat_features=features_categorical)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3fa1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
