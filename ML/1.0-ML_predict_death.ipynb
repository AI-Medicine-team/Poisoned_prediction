{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07edb83f",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_albumin_clean = pd.read_excel('./Poisoning_Prediction/all_poisoning_data_wide_clean_albumin_20251106.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7863fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical = ['Gender',\n",
    " 'Education Level',\n",
    " 'Type of Poisoning',\n",
    " 'Hypertension',\n",
    " 'Hyperlipidemia',\n",
    " 'Diabetes Mellitus',\n",
    " 'Cerebrovascular Disease',\n",
    " 'Heart Disease',\n",
    " 'Allergy History',\n",
    " 'Cancer',\n",
    " 'Poisoning',\n",
    " 'degree of poisoning',\n",
    " 'Smoking Status',\n",
    " 'Alcohol Consumption Status',\n",
    " 'Shortness of Breath',\n",
    " 'Chest Pain',\n",
    " 'Cough',\n",
    " 'Pre-syncope',\n",
    " 'Altered Consciousness or Syncope',\n",
    " 'Sore Throat',\n",
    " 'Fever',\n",
    " 'Fatigue',\n",
    " 'Lower Limb Edema',\n",
    " 'Palpitations',\n",
    " 'Vomiting',\n",
    " 'Nausea',\n",
    " 'Weakness',\n",
    " 'Headache',\n",
    " 'Residence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c39555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_mappings_en = {\n",
    "    \"Gender\": {\n",
    "        1: \"Male\",\n",
    "        0: \"Female\"\n",
    "    },\n",
    "    \"Education Level\": {\n",
    "        1: \"Illiterate\",\n",
    "        2: \"Primary School\",\n",
    "        3: \"Junior High School\",\n",
    "        4: \"Senior High School\",\n",
    "        5: \"University Degree\"\n",
    "    },\n",
    "    \"Type of Poisoning\": {\n",
    "        1: \"Industrial\",\n",
    "        2: \"Pharmaceutical\",\n",
    "        3: \"Pesticide\",\n",
    "        4: \"Alcohol\",\n",
    "        0: \"Uncertain\"\n",
    "    },\n",
    "    \"Hypertension\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Hyperlipidemia\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Diabetes Mellitus\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Cerebrovascular Disease\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Heart Disease\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Allergy History\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Cancer\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Poisoning\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"degree of poisoning\": {\n",
    "        0: \"Undetermined\",\n",
    "        1: \"Low\",\n",
    "        2: \"Moderate\",\n",
    "        3: \"High\"\n",
    "    },\n",
    "    \"Smoking\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Alcohol Consumption Status\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Shortness of Breath\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Chest Pain\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Cough\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Pre-syncope\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Altered Mental Status or Syncope(AMS or Sync)\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Sore Throat\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Fever\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Fatigue\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Lower Limb Edema\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Palpitations\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Vomiting\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Nausea\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Weakness\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Headache\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Residence\": {\n",
    "        1: \"Rural\",\n",
    "        2: \"Urban\"\n",
    "    },\n",
    "    \"Smoking Status\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    'Altered Consciousness or Syncope': {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inverse mapping (English label → numerical value)\n",
    "df_mapped_wide = df_albumin_clean.copy()\n",
    "for col in features_categorical:\n",
    "    if col in value_mappings_en and col in df_mapped_wide.columns:\n",
    "        # Build inverse mapping dictionary: {English label: original value}\n",
    "        inv_map = {v: k for k, v in value_mappings_en[col].items()}\n",
    "        df_mapped_wide[col] = df_mapped_wide[col].map(inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1221ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the distribution of each categorical variable (for subsequent analysis or printing)\n",
    "category_distributions = {}\n",
    "\n",
    "for col in features_categorical:\n",
    "    if col in df_mapped_wide.columns:\n",
    "        # Count the frequency of non-missing values in descending order of occurrence\n",
    "        counts = df_mapped_wide[col].value_counts(dropna=False)  # dropna=False 可显示 NaN 的数量（如有）\n",
    "        category_distributions[col] = counts\n",
    "        \n",
    "        # Optional: Print results\n",
    "        print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e120bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcome_other 分布（是否死亡）：\n",
      "Outcome_other\n",
      "0    889\n",
      "1     82\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome 分布（是否未治愈）：\n",
      "Outcome\n",
      "0    731\n",
      "1    240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the distribution of Outcome_other and Outcome\n",
    "print(\"\\nOutcome_other distribution (whether death occurred):\")\n",
    "print(df_mapped_wide[\"Outcome_other\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nOutcome distribution (whether not cured):\")\n",
    "print(df_mapped_wide[\"Outcome\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518dd6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_continuous = ['Age',\n",
    " 'Length of Stay',\n",
    " 'Weight',\n",
    " 'Systolic Blood Pressure',\n",
    " 'Diastolic Blood Pressure',\n",
    " 'Respiratory Rate',\n",
    " 'Heart Rate',\n",
    " 'White Blood Cell Count',\n",
    " 'Red Blood Cell Count',\n",
    " 'Hemoglobin Concentration',\n",
    " 'Mean Corpuscular Volume',\n",
    " 'Mean Corpuscular Hemoglobin',\n",
    " 'Mean Corpuscular Hemoglobin Concentration',\n",
    " 'Platelet Count',\n",
    " 'Mean Platelet Volume',\n",
    " 'Alanine Aminotransferase (ALT)',\n",
    " 'Total Bilirubin',\n",
    " 'Direct Bilirubin',\n",
    " 'Lactate Dehydrogenase (LDH)',\n",
    " 'Urea',\n",
    " 'Serum Creatinine',\n",
    " 'Uric Acid',\n",
    " 'Creatine Kinase (CK)',\n",
    " 'Creatine Kinase-MB Isoenzyme',\n",
    " 'Troponin I',\n",
    " 'High-Sensitivity C-Reactive Protein (hs-CRP)',\n",
    " 'Homocysteine',\n",
    " 'Potassium',\n",
    " 'Sodium',\n",
    " 'Chloride',\n",
    " 'Carbon Dioxide',\n",
    " 'Prothrombin Time',\n",
    " 'D-Dimer',\n",
    " 'Lactate',\n",
    " 'Blood Cholinesterase Test Results',\n",
    " 'Albumin (First Measurement)',\n",
    " 'Albumin (Last Measurement)',\n",
    " 'Number of Hemoperfusion Sessions',\n",
    " 'Number of Blood Purification Sessions',\n",
    " 'Hyperbaric Oxygen Therapy Duration and Frequency',\n",
    " 'Atropine Dosage',\n",
    " 'Long-acting Nitroglycerin Dosage',\n",
    " 'Pralidoxime Dosage',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe95684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "变量缺失比例（%）:\n",
      "Lactate                                             96.81\n",
      "Carbon Dioxide                                      94.95\n",
      "Potassium                                           94.75\n",
      "Sodium                                              94.75\n",
      "Chloride                                            94.75\n",
      "Prothrombin Time                                    94.64\n",
      "D-Dimer                                             94.64\n",
      "Atropine Dosage                                     93.92\n",
      "Long-acting Nitroglycerin Dosage                    92.48\n",
      "Hyperbaric Oxygen Therapy Duration and Frequency    92.38\n",
      "Pralidoxime Dosage                                  92.17\n",
      "Serum Creatinine                                    89.70\n",
      "Blood Cholinesterase Test Results                   89.29\n",
      "Number of Blood Purification Sessions               84.55\n",
      "Number of Hemoperfusion Sessions                    84.04\n",
      "Homocysteine                                        62.20\n",
      "Systolic Blood Pressure                             54.89\n",
      "Diastolic Blood Pressure                            54.89\n",
      "Troponin I                                          54.69\n",
      "Direct Bilirubin                                    54.07\n",
      "Weight                                              38.93\n",
      "High-Sensitivity C-Reactive Protein (hs-CRP)        37.80\n",
      "Albumin (First Measurement)                          6.80\n",
      "Albumin (Last Measurement)                           6.80\n",
      "Creatine Kinase-MB Isoenzyme                         5.87\n",
      "Length of Stay                                       5.15\n",
      "Respiratory Rate                                     4.53\n",
      "Urea                                                 2.88\n",
      "Uric Acid                                            2.78\n",
      "Creatine Kinase (CK)                                 2.57\n",
      "Mean Platelet Volume                                 2.47\n",
      "White Blood Cell Count                               1.96\n",
      "Hemoglobin Concentration                             1.96\n",
      "Red Blood Cell Count                                 1.96\n",
      "Mean Corpuscular Volume                              1.96\n",
      "Platelet Count                                       1.96\n",
      "Mean Corpuscular Hemoglobin                          1.96\n",
      "Mean Corpuscular Hemoglobin Concentration            1.96\n",
      "Lactate Dehydrogenase (LDH)                          1.75\n",
      "Alanine Aminotransferase (ALT)                       1.54\n",
      "Total Bilirubin                                      1.44\n",
      "Heart Rate                                           0.00\n",
      "Age                                                  0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Calculate the missing ratio for continuous variables\n",
    "\n",
    "# Calculate the missing ratio (by column)\n",
    "missing_ratios = df_mapped_wide[features_continuous].isnull().mean()\n",
    "\n",
    "# Convert to percentage and sort (from high to low)\n",
    "missing_summary = (missing_ratios * 100).round(2).sort_values(ascending=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Missing ratio of variables (%):\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585448e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失率 > 90% 的连续变量:\n",
      "Potassium: 94.75%\n",
      "Sodium: 94.75%\n",
      "Chloride: 94.75%\n",
      "Carbon Dioxide: 94.95%\n",
      "Prothrombin Time: 94.64%\n",
      "D-Dimer: 94.64%\n",
      "Lactate: 96.81%\n",
      "Hyperbaric Oxygen Therapy Duration and Frequency: 92.38%\n",
      "Atropine Dosage: 93.92%\n",
      "Long-acting Nitroglycerin Dosage: 92.48%\n",
      "Pralidoxime Dosage: 92.17%\n"
     ]
    }
   ],
   "source": [
    "# Feature names screened for deletion rates> 90%\n",
    "high_missing_features = missing_ratios[missing_ratios > 0.90].index.tolist()\n",
    "\n",
    "# Optional: Print these features\n",
    "print(\"Continuous variables with missing rate> 90%:\")\n",
    "for feat in high_missing_features:\n",
    "    print(f\"{feat}: {missing_ratios[feat]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe57207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "11\n",
      "32\n",
      "(971, 95)\n"
     ]
    }
   ],
   "source": [
    "print(len(features_continuous))\n",
    "print(len(high_missing_features))\n",
    "features_continuous = [feat for feat in features_continuous if feat not in high_missing_features]\n",
    "print(len(features_continuous))\n",
    "\n",
    "# df2 Remove variables from high_missing_features\n",
    "df_mapped_wide = df_mapped_wide.drop(columns=high_missing_features)\n",
    "print(df_mapped_wide.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f75a9",
   "metadata": {},
   "source": [
    "#### Five-fold cross-validation: Further divide 1/8 of the training set into a validation set (i.e., the training set accounts for 70%, the validation set for 10%, and the test set for 20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3465a",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split, ParameterGrid\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import os\n",
    "\n",
    "# ===================== bootstrap  =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "# ===================== CatBoost =====================\n",
    "def train_catboost_5fold_cv_gridsearch_save(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    save_path='./Poisoning_Prediction/ML/predict_death/catboost_gridsearch_valid_test_5cv/',\n",
    "    seed=42,\n",
    "    early_stopping_rounds=30,\n",
    "    param_grid=None\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    dataX = dataX.copy()\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            dataX[c] = dataX[c].astype(str).fillna(\"missing\")\n",
    "    X = dataX\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    if param_grid is None:\n",
    "        param_grid = {\"depth\":[5], \"learning_rate\":[0.05], \"iterations\":[300]}\n",
    "\n",
    "    grid_results = []\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        param_name = \"_\".join([f\"{k}_{v}\" for k,v in params.items()])\n",
    "        param_path = os.path.join(save_path, param_name)\n",
    "        os.makedirs(param_path, exist_ok=True)\n",
    "        print(f\"\\n===== params: {params} =====\")\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        all_results = []\n",
    "\n",
    "        fold_idx = 1\n",
    "        for train_val_index, test_index in kf.split(X):\n",
    "            # Step1:  train_val / test\n",
    "            X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "            y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "            # Step2: train / val\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_val, y_train_val,\n",
    "                test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "            )\n",
    "\n",
    "            # print training/validation/test sizes\n",
    "            print(f\"Seed {seed}, Fold: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "            print(f\"  Train - Pos: {np.sum(y_train == 1)}, Neg: {np.sum(y_train == 0)}\")\n",
    "            print(f\"  Val   - Pos: {np.sum(y_val == 1)},   Neg: {np.sum(y_val == 0)}\")\n",
    "            print(f\"  Test  - Pos: {np.sum(y_test == 1)},  Neg: {np.sum(y_test == 0)}\")\n",
    "\n",
    "            # class weights\n",
    "            num_pos = np.sum(y_train==1)\n",
    "            num_neg = np.sum(y_train==0)\n",
    "            scale_pos_weight = num_neg / max(num_pos,1)\n",
    "\n",
    "            # Pool\n",
    "            train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "            val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "            test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "            # train model\n",
    "            model = CatBoostClassifier(\n",
    "                **params,\n",
    "                loss_function=\"Logloss\",\n",
    "                eval_metric=\"AUC\",\n",
    "                # eval_metric=\"PRAUC:type=Classic\",  # PR AUC\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "                random_seed=seed,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # train + early stopping\n",
    "            # model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds, verbose=100)\n",
    "            model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "\n",
    "            # test predictions\n",
    "            y_pred_prob = model.predict_proba(test_pool)[:,1]\n",
    "\n",
    "            # save CSV\n",
    "            fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "            pd.DataFrame({\n",
    "                \"fold\": fold_idx,\n",
    "                \"y_test\": y_test,\n",
    "                \"y_pred\": y_pred_prob\n",
    "            }).to_csv(fold_csv, index=False)\n",
    "            all_results.append(pd.DataFrame({\"fold\": fold_idx,\"y_test\": y_test,\"y_pred\": y_pred_prob}))\n",
    "\n",
    "            fold_idx += 1\n",
    "\n",
    "        # recombine all folds\n",
    "        all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "        all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "        all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "        # ===================== bootstrap AUROC/AUPRC =====================\n",
    "        mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "            all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "        )\n",
    "        mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "            all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "        )\n",
    "\n",
    "        print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "        print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "        grid_results.append({\n",
    "            \"params\": params,\n",
    "            \"AUROC_mean\": mean_auroc,\n",
    "            \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "            \"AUPRC_mean\": mean_auprc,\n",
    "            \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "            \"AllResults\": all_results_df\n",
    "        })\n",
    "\n",
    "    # best parameters\n",
    "    best = max(grid_results, key=lambda x: x[\"AUROC_mean\"])\n",
    "    print(f\"\\n===== best params =====\\n{best['params']}\")\n",
    "    print(f\"AUROC Mean={best['AUROC_mean']:.4f}, 95% CI={best['AUROC_CI']}\")\n",
    "    print(f\"AUPRC Mean={best['AUPRC_mean']:.4f}, 95% CI={best['AUPRC_CI']}\")\n",
    "\n",
    "    return grid_results, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc42181",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"iterations\": [200, 300, 400],\n",
    "    \"depth\": [4, 5, 6],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    # \"l2_leaf_reg\": [1, 3, 5],\n",
    "    # \"border_count\": [32, 64, 128],\n",
    "    # \"random_strength\": [1, 5, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4441e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other']  \n",
    "results = train_catboost_5fold_cv_gridsearch_save(dataX, dataY,cat_features=features_categorical, param_grid=param_grid)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c97b5e",
   "metadata": {},
   "source": [
    "#### fixed best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b09f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fixed hyperparameter ####\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# ===================== bootstrap calculation function =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "\n",
    "# ===================== 5-fold CatBoost（fixed parameters） =====================\n",
    "def train_catboost_5fold_cv_fixed(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    save_path='./Poisoning_Prediction/ML/predict_death/catboost_gridsearch_valid_test_5cv/',\n",
    "    seed=42,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'depth': 5, 'iterations': 200, 'learning_rate': 0.05}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    dataX = dataX.copy()\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            dataX[c] = dataX[c].astype(str).fillna(\"missing\")\n",
    "\n",
    "    X = dataX\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "    print(f\"\\n===== use fixed params: {params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        # Step1: train_val / test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step2: train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        # size of training/validation/test sets\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "        print(f\"  Train - Pos: {np.sum(y_train == 1)}, Neg: {np.sum(y_train == 0)}\")\n",
    "        print(f\"  Val   - Pos: {np.sum(y_val == 1)},   Neg: {np.sum(y_val == 0)}\")\n",
    "        print(f\"  Test  - Pos: {np.sum(y_test == 1)},  Neg: {np.sum(y_test == 0)}\")\n",
    "\n",
    "        # class weights\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "        print('scale_pos_weight:',scale_pos_weight)\n",
    "\n",
    "        # Pool\n",
    "        train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "        val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "        # model training\n",
    "        model = CatBoostClassifier(\n",
    "            **params,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"AUC\",\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # train model + early stopping\n",
    "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "\n",
    "        # test predictions\n",
    "        y_pred_prob = model.predict_proba(test_pool)[:, 1]\n",
    "\n",
    "        \n",
    "        # save\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    # merge all folds\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    # ===================== bootstrap AUROC/AUPRC =====================\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"\\n===== results (fixed params) =====\")\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "902a9ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome_other\n",
       "0    889\n",
       "1     82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapped_wide['Outcome_other'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43427214",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other']  # Predicting death\n",
    "results = train_catboost_5fold_cv_fixed(dataX, dataY,cat_features=features_categorical)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e61e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Probabilistic Calibrators Using Sklearn \n",
    "## CatBoost's raw output probability tends to drift toward 0/1 after class imbalance, small data sets, or early stops, resulting in decision curve analysis (DCA) or AUROC/AUPRC curves deviating from ideal probabilities\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# ===================== bootstrap calculation function =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "\n",
    "# ===================== 5-fold CatBoost（fixed parameters） =====================\n",
    "def train_catboost_5fold_cv_calibration(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    save_path='/home/mailiyi/Poisoning_Prediction/ML/predict_death_calibration/catboost/',\n",
    "    seed=42,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'depth': 5, 'iterations': 200, 'learning_rate': 0.05}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    dataX = dataX.copy()\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            dataX[c] = dataX[c].astype(str).fillna(\"missing\")\n",
    "\n",
    "    X = dataX\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "    print(f\"\\n===== fixed params: {params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        # Step1: train_val / test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step2: train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "        print(f\"  Train - Pos: {np.sum(y_train == 1)}, Neg: {np.sum(y_train == 0)}\")\n",
    "        print(f\"  Val   - Pos: {np.sum(y_val == 1)},   Neg: {np.sum(y_val == 0)}\")\n",
    "        print(f\"  Test  - Pos: {np.sum(y_test == 1)},  Neg: {np.sum(y_test == 0)}\")\n",
    "\n",
    "        # category weights\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "        print('scale_pos_weight:',scale_pos_weight)\n",
    "\n",
    "        # Pool\n",
    "        train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "        val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "\n",
    "        from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "        cat_model = CatBoostClassifier(\n",
    "            **params,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"AUC\",\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Calibration via sigmoid or isotonic\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            estimator=cat_model, \n",
    "            method='sigmoid',\n",
    "            cv='prefit'\n",
    "        )\n",
    "\n",
    "        # Train the original model first\n",
    "        cat_model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "\n",
    "        calib_model.fit(X_val, y_val)  \n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Save current fold result\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    # ===================== bootstrap calculate AUROC/AUPRC =====================\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37dc46f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome_other\n",
       "0    889\n",
       "1     82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapped_wide['Outcome_other'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other']\n",
    "results = train_catboost_5fold_cv_calibration(dataX, dataY,cat_features=features_categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cde9c7",
   "metadata": {},
   "source": [
    "#### model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ad36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the optimal model \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import os\n",
    "\n",
    "# ===================== Calculate Youden Index optimal threshold =====================\n",
    "def find_best_threshold_by_youden(y_true, y_pred_prob):\n",
    "    \"\"\"\n",
    "    根据 Youden Index (Sensitivity + Specificity - 1)\n",
    "    计算最佳切分阈值\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred_prob)\n",
    "    specificity = 1 - fpr\n",
    "    youden_index = tpr + specificity - 1\n",
    "    best_idx = np.argmax(youden_index)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "\n",
    "    return best_threshold, youden_index[best_idx], tpr[best_idx], specificity[best_idx]\n",
    "\n",
    "# ===================== bootstrap calculation function =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "\n",
    "# ===================== 5-fold CatBoost（fixed parameters） =====================\n",
    "def train_catboost_5fold_cv_best_save(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    save_path='./Poisoning_Prediction/ML/predict_death_best_model/catboost/',\n",
    "    seed=42,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'depth': 5, 'iterations': 200, 'learning_rate': 0.05}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    dataX = dataX.copy()\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            dataX[c] = dataX[c].astype(str).fillna(\"missing\")\n",
    "\n",
    "    X = dataX\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "    print(f\"\\n===== Use fixed parameters: {params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    # ⭐ Record the model with the best AUC in the five-compromise validation set\n",
    "    best_fold_auc = -np.inf\n",
    "    best_fold_model_path = None\n",
    "    best_fold_idx = None\n",
    "\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "\n",
    "        # Step1: train_val / test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step2: train / val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "\n",
    "        # category weights\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "\n",
    "        # Pool\n",
    "        train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "        val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "        model = CatBoostClassifier(\n",
    "            **params,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"AUC\",\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # train + early stopping\n",
    "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "        \n",
    "        # ============================ AUC output ============================\n",
    "\n",
    "        # Validation AUC\n",
    "        val_pred = model.predict_proba(val_pool)[:, 1]\n",
    "        fold_val_auc = metrics.roc_auc_score(y_val, val_pred)\n",
    "        print(f\"Fold {fold_idx} - Validation AUC = {fold_val_auc:.4f}\")\n",
    "\n",
    "        # Test AUC\n",
    "        y_pred_prob = model.predict_proba(test_pool)[:, 1]\n",
    "        fold_test_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "        print(f\"Fold {fold_idx} - Test AUC = {fold_test_auc:.4f}\")\n",
    "\n",
    "        # ================================================================\n",
    "\n",
    "        # ------------------------------\n",
    "        # ⭐ Save the best model of the fold\n",
    "        # ------------------------------\n",
    "        fold_model_path = os.path.join(param_path, f\"best_model_fold_{fold_idx}.cbm\")\n",
    "        model.save_model(fold_model_path)\n",
    "        print(f\"Fold {fold_idx} Optimal model saved: {fold_model_path}\")\n",
    "\n",
    "        # Validation Set Performance\n",
    "        val_pred = model.predict_proba(val_pool)[:, 1]\n",
    "        fold_val_auc = metrics.roc_auc_score(y_val, val_pred)\n",
    "\n",
    "        if fold_val_auc > best_fold_auc:\n",
    "            best_fold_auc = fold_val_auc\n",
    "            best_fold_model_path = fold_model_path\n",
    "            best_fold_idx = fold_idx   # ⭐ Record which discount is best\n",
    "\n",
    "        y_pred_prob = model.predict_proba(test_pool)[:, 1]\n",
    "\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # ⭐ Copy the best model of the five-way to the main directory\n",
    "    # ----------------------------------------\n",
    "    best_overall_path = os.path.join(param_path, \"best_overall_model.cbm\")\n",
    "    if best_fold_model_path is not None:\n",
    "        import shutil\n",
    "        shutil.copy(best_fold_model_path, best_overall_path)\n",
    "        print(f\"\\n===== Five-compromise optimal model: Fold {best_fold_idx}, \"f\"Validation AUC={best_fold_auc:.4f} =====\")\n",
    "        print(f\"Model saved to: {best_overall_path}\")\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    # ===================== bootstrap calculate AUROC/AUPRC =====================\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    # Calculating the Best Youden Index Threshold\n",
    "    best_thresh, best_youden, best_sen, best_spec = find_best_threshold_by_youden(\n",
    "        all_results_df[\"y_test\"], \n",
    "        all_results_df[\"y_pred\"]\n",
    "    )\n",
    "\n",
    "    print(f\"optimal threshold (cut-off) = {best_thresh:.4f}\")\n",
    "    print(f\"Youden Index = {best_youden:.4f}\")\n",
    "    print(f\"Sensitivity  = {best_sen:.4f}\")\n",
    "    print(f\"Specificity  = {best_spec:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df,\n",
    "        \"BestModelPath\": best_overall_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other']  # Predicting death\n",
    "results = train_catboost_5fold_cv_best_save(dataX, dataY,cat_features=features_categorical)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa1d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd950cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the optimal model (Probabilistic Calibration Model) ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import shutil\n",
    "\n",
    "# ===================== Calculate Youden Index optimal threshold  =====================\n",
    "def find_best_threshold_by_youden(y_true, y_pred_prob):\n",
    "    \"\"\"\n",
    "    Youden Index (Sensitivity + Specificity - 1)\n",
    "    Calculate the optimal segmentation threshold\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred_prob)\n",
    "    specificity = 1 - fpr\n",
    "    youden_index = tpr + specificity - 1\n",
    "    best_idx = np.argmax(youden_index)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "\n",
    "    return best_threshold, youden_index[best_idx], tpr[best_idx], specificity[best_idx]\n",
    "\n",
    "\n",
    "# ===================== bootstrap calculation function =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "# ===================== 5-fold CatBoost + calibration model =====================\n",
    "def train_catboost_5fold_cv_best_save(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    cat_features=None,\n",
    "    save_path='./Poisoning_Prediction/ML/predict_death_best_model/catboost_calibration/',\n",
    "    seed=42,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'depth': 5, 'iterations': 200, 'learning_rate': 0.05}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    dataX = dataX.copy()\n",
    "    if cat_features is not None:\n",
    "        for c in cat_features:\n",
    "            dataX[c] = dataX[c].astype(str).fillna(\"missing\")\n",
    "\n",
    "    X = dataX\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "    print(f\"\\n===== with fixed parameters: {params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    # ⭐ Record the model with the best AUC in the five-compromise validation set\n",
    "    best_fold_auc = -np.inf\n",
    "    best_fold_model_path = None\n",
    "    best_fold_idx = None\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "        # Pool\n",
    "        train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "        val_pool = Pool(X_val, label=y_val, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "        cat_model = CatBoostClassifier(\n",
    "            **params,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"AUC\",\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_seed=seed,\n",
    "            verbose=False\n",
    "        )\n",
    "        cat_model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "\n",
    "        # calibration model\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            estimator=cat_model,\n",
    "            method='sigmoid',\n",
    "            cv='prefit'\n",
    "        )\n",
    "        calib_model.fit(X_val, y_val)\n",
    "\n",
    "        # test set prediction\n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Validation AUC\n",
    "        val_pred = calib_model.predict_proba(X_val)[:, 1]\n",
    "        fold_val_auc = metrics.roc_auc_score(y_val, val_pred)\n",
    "        fold_test_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "        print(f\"Fold {fold_idx} - Validation AUC = {fold_val_auc:.4f}\")\n",
    "        print(f\"Fold {fold_idx} - Test AUC       = {fold_test_auc:.4f}\")\n",
    "\n",
    "        # ------------------------------\n",
    "        # ⭐ Save the calibration model\n",
    "        # ------------------------------\n",
    "        fold_model_path = os.path.join(param_path, f\"best_model_fold_{fold_idx}.pkl\")\n",
    "        joblib.dump(calib_model, fold_model_path)\n",
    "        print(f\"Fold {fold_idx} Calibration model saved: {fold_model_path}\")\n",
    "\n",
    "        if fold_val_auc > best_fold_auc:\n",
    "            best_fold_auc = fold_val_auc\n",
    "            best_fold_model_path = fold_model_path\n",
    "            best_fold_idx = fold_idx\n",
    "\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    # ⭐ Reproduction of the Five-compromise Optimal Model\n",
    "    best_overall_path = os.path.join(param_path, \"best_overall_model.pkl\")\n",
    "    if best_fold_model_path is not None:\n",
    "        shutil.copy(best_fold_model_path, best_overall_path)\n",
    "        print(f\"\\n===== Five-compromise optimal model: Fold {best_fold_idx}, \"f\"Validation AUC={best_fold_auc:.4f} =====\")\n",
    "        print(f\"Model saved to: {best_overall_path}\")\n",
    "        \n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    # ===================== bootstrap calculate AUROC/AUPRC =====================\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    # optimal threshold\n",
    "    best_thresh, best_youden, best_sen, best_spec = find_best_threshold_by_youden(\n",
    "        all_results_df[\"y_test\"], \n",
    "        all_results_df[\"y_pred\"]\n",
    "    )\n",
    "\n",
    "    print(f\"optimal threshold (cut-off) = {best_thresh:.4f}\")\n",
    "    print(f\"Youden Index = {best_youden:.4f}\")\n",
    "    print(f\"Sensitivity  = {best_sen:.4f}\")\n",
    "    print(f\"Specificity  = {best_spec:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df,\n",
    "        \"BestModelPath\": best_overall_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e65147",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other']\n",
    "results = train_catboost_5fold_cv_best_save(dataX, dataY,cat_features=features_categorical)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be0d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1e128f",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f885dae6",
   "metadata": {},
   "source": [
    "#### params search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ad095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split, ParameterGrid\n",
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "# ===================== bootstrap =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "# ===================== XGBoost =====================\n",
    "def train_xgboost_5fold_cv_gridsearch_save(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    save_path='./Poisoning_Prediction/ML/predict_death/xgboost_gridsearch_valid_test_5cv/',\n",
    "    seed=42,\n",
    "    early_stopping_rounds=30,\n",
    "    param_grid=None\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    if param_grid is None:\n",
    "        param_grid = {\"max_depth\":[5], \"learning_rate\":[0.05], \"n_estimators\":[300]}\n",
    "\n",
    "    grid_results = []\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        param_name = \"_\".join([f\"{k}_{v}\" for k,v in params.items()])\n",
    "        param_path = os.path.join(save_path, param_name)\n",
    "        os.makedirs(param_path, exist_ok=True)\n",
    "        print(f\"\\n===== params: {params} =====\")\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        all_results = []\n",
    "\n",
    "        fold_idx = 1\n",
    "        for train_val_index, test_index in kf.split(X):\n",
    "            # Step1: train_val / test\n",
    "            X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "            y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "            # Step2: train / val\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_val, y_train_val,\n",
    "                test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "            )\n",
    "\n",
    "            # size print\n",
    "            print(f\"Seed {seed}, Fold: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "            print(f\"  Train - Pos: {np.sum(y_train == 1)}, Neg: {np.sum(y_train == 0)}\")\n",
    "            print(f\"  Val   - Pos: {np.sum(y_val == 1)},   Neg: {np.sum(y_val == 0)}\")\n",
    "            print(f\"  Test  - Pos: {np.sum(y_test == 1)},  Neg: {np.sum(y_test == 0)}\")\n",
    "\n",
    "            # class weights\n",
    "            num_pos = np.sum(y_train == 1)\n",
    "            num_neg = np.sum(y_train == 0)\n",
    "            scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "\n",
    "            # DMatrix\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "            dval   = xgb.DMatrix(X_val, label=y_val)\n",
    "            dtest  = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "            # setup params\n",
    "            xgb_params = {\n",
    "                \"objective\": \"binary:logistic\",\n",
    "                \"eval_metric\": \"auc\",\n",
    "                \"scale_pos_weight\": scale_pos_weight,\n",
    "                \"seed\": seed,\n",
    "                \"verbosity\": 0,\n",
    "                **params\n",
    "            }\n",
    "\n",
    "            \n",
    "            evals=[(dval, 'validation')]\n",
    "            model = xgb.train(\n",
    "                xgb_params,\n",
    "                dtrain,\n",
    "                num_boost_round=params.get(\"n_estimators\", 300),\n",
    "                evals=evals,\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "\n",
    "            # test predictions\n",
    "            y_pred_prob = model.predict(dtest)\n",
    "\n",
    "            # save current fold results\n",
    "            fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "            pd.DataFrame({\n",
    "                \"fold\": fold_idx,\n",
    "                \"y_test\": y_test,\n",
    "                \"y_pred\": y_pred_prob\n",
    "            }).to_csv(fold_csv, index=False)\n",
    "            all_results.append(pd.DataFrame({\"fold\": fold_idx,\"y_test\": y_test,\"y_pred\": y_pred_prob}))\n",
    "\n",
    "            fold_idx += 1\n",
    "\n",
    "        # merge all folds\n",
    "        all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "        all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "        all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "        # ===================== bootstrap AUROC/AUPRC =====================\n",
    "        mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "            all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "        )\n",
    "        mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "            all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "        )\n",
    "\n",
    "        print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "        print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "        grid_results.append({\n",
    "            \"params\": params,\n",
    "            \"AUROC_mean\": mean_auroc,\n",
    "            \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "            \"AUPRC_mean\": mean_auprc,\n",
    "            \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "            \"AllResults\": all_results_df\n",
    "        })\n",
    "\n",
    "    # best params\n",
    "    best = max(grid_results, key=lambda x: x[\"AUROC_mean\"])\n",
    "    print(f\"\\n===== 最优参数 =====\\n{best['params']}\")\n",
    "    print(f\"AUROC Mean={best['AUROC_mean']:.4f}, 95% CI={best['AUROC_CI']}\")\n",
    "    print(f\"AUPRC Mean={best['AUPRC_mean']:.4f}, 95% CI={best['AUPRC_CI']}\")\n",
    "\n",
    "    return grid_results, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be573b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [200, 300, 400],\n",
    "    \"max_depth\": [4, 5, 6],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other']  \n",
    "results = train_xgboost_5fold_cv_gridsearch_save(dataX, dataY, param_grid=param_grid)  \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cf291",
   "metadata": {},
   "source": [
    "#### use fixed parameters to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fixed Hyperparameters\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import xgboost as xgb\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "# from xgboost import XGBClassifier\n",
    "import os\n",
    "\n",
    "# ===================== Bootstrap Calculation Function =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "\n",
    "# ===================== 5-Fold XGBoost (Fixed Parameters) =====================\n",
    "def train_xgboost_5fold_cv_fixed(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    save_path='./Poisoning_Prediction/ML/predict_death/xgboost_gridsearch_valid_test_5cv/',\n",
    "    seed=42,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "    print(f\"\\n===== Using Fixed Parameters: {params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        # Step 1: Split train_val / test\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # Step 2: Split validation set\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        # Output the number of samples in train, test, and validation sets\n",
    "        print(f\"Seed {seed}, Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "        print(f\"  Train - Pos: {np.sum(y_train == 1)}, Neg: {np.sum(y_train == 0)}\")\n",
    "        print(f\"  Val   - Pos: {np.sum(y_val == 1)},   Neg: {np.sum(y_val == 0)}\")\n",
    "        print(f\"  Test  - Pos: {np.sum(y_test == 1)},  Neg: {np.sum(y_test == 0)}\")\n",
    "\n",
    "        # Class weights\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "\n",
    "        # DMatrix\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval   = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest  = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "        # Parameter configuration\n",
    "        xgb_params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"scale_pos_weight\": scale_pos_weight,\n",
    "            \"seed\": seed,\n",
    "            \"verbosity\": 0,\n",
    "            \"learning_rate\": params[\"learning_rate\"],\n",
    "            \"max_depth\": params[\"max_depth\"]\n",
    "        }\n",
    "\n",
    "        # Early stopping\n",
    "        evals = [(dval, \"validation\")]\n",
    "        model = xgb.train(\n",
    "            xgb_params,\n",
    "            dtrain,\n",
    "            num_boost_round=params.get(\"n_estimators\", 200),\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        # Test predictions\n",
    "        y_pred_prob = model.predict(dtest)\n",
    "\n",
    "\n",
    "        # Save current fold results\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "\n",
    "        fold_idx += 1\n",
    "\n",
    "    # Combine fold results\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    # ===================== Bootstrap Calculation of AUROC/AUPRC =====================\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"\\n===== Final Results (Fixed Parameters) =====\")\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73afc109",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other'] \n",
    "results = train_xgboost_5fold_cv_fixed(dataX, dataY)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d843f4",
   "metadata": {},
   "source": [
    "#### Fixed Hyperparameter + 5-fold XGBoost + Calibration (Training Set Fit + Validation Set Calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fixed Hyperparameter + 5-fold XGBoost + Calibration (Training Set Fit + Validation Set Calibration)\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "\n",
    "# ===================== bootstrap calculation function =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "\n",
    "# ===================== 5-fold XGBoost（Training Set Fit + Validation Set Calibration） =====================\n",
    "def train_xgboost_5fold_cv_calibrated(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    save_path='./Poisoning_Prediction/ML/predict_death_calibration/xgboost/',\n",
    "    seed=42,\n",
    "    early_stopping_rounds=30,\n",
    "    params={'learning_rate':0.05, 'max_depth':5, 'n_estimators':200}\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    param_path = os.path.join(save_path, param_name)\n",
    "    os.makedirs(param_path, exist_ok=True)\n",
    "    print(f\"\\n===== Use fixed parameters: {params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        print(f\"Fold={fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\")\n",
    "        print(f\"  Train - Pos: {np.sum(y_train==1)}, Neg: {np.sum(y_train==0)}\")\n",
    "        print(f\"  Val   - Pos: {np.sum(y_val==1)},   Neg: {np.sum(y_val==0)}\")\n",
    "        print(f\"  Test  - Pos: {np.sum(y_test==1)},  Neg: {np.sum(y_test==0)}\")\n",
    "\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos,1)\n",
    "\n",
    "        # ---------------------- training-based model ----------------------\n",
    "        base_model = XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            learning_rate=params['learning_rate'],\n",
    "            max_depth=params['max_depth'],\n",
    "            n_estimators=params['n_estimators'],\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_state=seed,\n",
    "            verbosity=0,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "        # Fit with Training Set\n",
    "        base_model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            # early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # ---------------------- Validation Set Calibration ----------------------\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            estimator=base_model,\n",
    "            method='sigmoid',\n",
    "            cv='prefit'\n",
    "        )\n",
    "        calib_model.fit(X_val, y_val)\n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # ---------------------- Deposit book result ----------------------\n",
    "        fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "\n",
    "        fold_idx += 1\n",
    "\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    # ===================== bootstrap calculate AUROC/AUPRC =====================\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score\n",
    "    )\n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score\n",
    "    )\n",
    "\n",
    "    print(f\"\\n===== Final results (fixed parameters + calibration) =====\")\n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"AUROC_mean\": mean_auroc,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": mean_auprc,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "        \"AllResults\": all_results_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other'] \n",
    "results = train_xgboost_5fold_cv_calibrated(dataX, dataY)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7215c08",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fce8e4",
   "metadata": {},
   "source": [
    "- grid search optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1828a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "\n",
    "def train_randomforest_5fold_cv_gridsearch_save(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    save_path='./Poisoning_Prediction/ML/predict_death/randomforest_gridsearch_valid_test_5cv/',\n",
    "    seed=42,\n",
    "    param_grid=None\n",
    "):\n",
    "    \"\"\"\n",
    "    param_grid: dict\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [200, 300, 400],\n",
    "            \"max_depth\": [4, 5, 6],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4],\n",
    "            \"max_features\": [\"sqrt\", \"log2\"]\n",
    "        }\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import KFold, train_test_split, ParameterGrid\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import os\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [300],\n",
    "            \"max_depth\": [5],\n",
    "            \"min_samples_split\": [2],\n",
    "            \"min_samples_leaf\": [1],\n",
    "            \"max_features\": [\"sqrt\"]\n",
    "        }\n",
    "\n",
    "    grid_results = []\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        param_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "        param_path = os.path.join(save_path, param_name)\n",
    "        os.makedirs(param_path, exist_ok=True)\n",
    "        print(f\"\\n===== params: {params} =====\")\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=seed)  # 修改为五折\n",
    "        aurocs, auprcs = [], []\n",
    "        all_results = []\n",
    "\n",
    "        fold_idx = 1\n",
    "        for train_val_index, test_index in kf.split(X):\n",
    "            # Step1:  80% train_val, 20% test\n",
    "            X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "            y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "            # Step2: train_val / val\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_val, y_train_val,\n",
    "                test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "            )\n",
    "\n",
    "            # class weights\n",
    "            num_pos = np.sum(y_train == 1)\n",
    "            num_neg = np.sum(y_train == 0)\n",
    "            scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "            class_weight = {0: 1.0, 1: scale_pos_weight}\n",
    "\n",
    "            # train model\n",
    "            model = RandomForestClassifier(\n",
    "                random_state=seed,\n",
    "                n_jobs=-1,\n",
    "                class_weight=class_weight,\n",
    "                **params\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # test predictions\n",
    "            y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "            auroc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "            auprc = metrics.average_precision_score(y_test, y_pred_prob)\n",
    "            aurocs.append(auroc)\n",
    "            auprcs.append(auprc)\n",
    "\n",
    "            # save current fold results\n",
    "            fold_csv = os.path.join(param_path, f\"fold_{fold_idx}_results.csv\")\n",
    "            pd.DataFrame({\n",
    "                \"fold\": fold_idx,\n",
    "                \"y_test\": y_test,\n",
    "                \"y_pred\": y_pred_prob\n",
    "            }).to_csv(fold_csv, index=False)\n",
    "            all_results.append(pd.DataFrame({\n",
    "                \"fold\": fold_idx,\n",
    "                \"y_test\": y_test,\n",
    "                \"y_pred\": y_pred_prob\n",
    "            }))\n",
    "            fold_idx += 1\n",
    "\n",
    "        # merge all folds\n",
    "        all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "        all_csv = os.path.join(param_path, \"all_folds_results.csv\")\n",
    "        all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "        # calculate mean and 95% CI\n",
    "        def mean_ci_interval(data):\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data, ddof=1)\n",
    "            ci95 = 1.96 * std / np.sqrt(len(data))\n",
    "            return round(mean, 4), round(mean - ci95, 4), round(mean + ci95, 4)\n",
    "\n",
    "        auroc_mean, auroc_lower, auroc_upper = mean_ci_interval(aurocs)\n",
    "        auprc_mean, auprc_lower, auprc_upper = mean_ci_interval(auprcs)\n",
    "\n",
    "        print(f\"AUROC: Mean={auroc_mean:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "        print(f\"AUPRC: Mean={auprc_mean:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "        grid_results.append({\n",
    "            \"params\": params,\n",
    "            \"AUROC_mean\": auroc_mean,\n",
    "            \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "            \"AUPRC_mean\": auprc_mean,\n",
    "            \"AUPRC_CI\": (auprc_lower, auprc_upper),\n",
    "            \"AllResults\": all_results_df\n",
    "        })\n",
    "\n",
    "    # select best params\n",
    "    best = max(grid_results, key=lambda x: x[\"AUROC_mean\"])\n",
    "    print(f\"\\n===== 最优参数 =====\\n{best['params']}\")\n",
    "    print(f\"AUROC Mean={best['AUROC_mean']:.4f}, 95% CI={best['AUROC_CI']}\")\n",
    "    print(f\"AUPRC Mean={best['AUPRC_mean']:.4f}, 95% CI={best['AUPRC_CI']}\")\n",
    "\n",
    "    return grid_results, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [200, 300, 400],   \n",
    "    \"max_depth\": [4, 5, 6],            \n",
    "    # \"min_samples_split\": [2, 5, 10],   \n",
    "    # \"min_samples_leaf\": [1, 2, 4],     \n",
    "    # \"max_features\": [\"sqrt\", \"log2\", None]  \n",
    "}  # RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other']  \n",
    "results = train_randomforest_5fold_cv_gridsearch_save(dataX, dataY, param_grid=param_grid)  \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eaebc2",
   "metadata": {},
   "source": [
    "- probability calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import os\n",
    "\n",
    "def train_randomforest_5fold_cv_calibrated(\n",
    "    dataX,\n",
    "    dataY,\n",
    "    save_path='./Poisoning_Prediction/ML/predict_death_calibration/randomforest/',\n",
    "    seed=42\n",
    "):\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    X = dataX.copy()\n",
    "    y = np.array(dataY)\n",
    "\n",
    "    fixed_params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 5,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\": \"sqrt\"\n",
    "    }\n",
    "\n",
    "    print(f\"\\n===== fixed_params: {fixed_params} =====\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    aurocs, auprcs = [], []\n",
    "    all_results = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_val_index, test_index in kf.split(X):\n",
    "        print(f\"\\n===== Fold {fold_idx} =====\")\n",
    "        X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
    "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "        # validation set\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val,\n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val\n",
    "        )\n",
    "\n",
    "        # class weights\n",
    "        num_pos = np.sum(y_train == 1)\n",
    "        num_neg = np.sum(y_train == 0)\n",
    "        scale_pos_weight = num_neg / max(num_pos, 1)\n",
    "        class_weight = {0: 1.0, 1: scale_pos_weight}\n",
    "\n",
    "        # ---------------------- train base model ----------------------\n",
    "        base_model = RandomForestClassifier(\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "            class_weight=class_weight,\n",
    "            **fixed_params\n",
    "        )\n",
    "        base_model.fit(X_train, y_train)\n",
    "\n",
    "        # ---------------------- validate model calibration ----------------------\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            estimator=base_model,\n",
    "            method='sigmoid',\n",
    "            cv='prefit'  # base_model \n",
    "        )\n",
    "        calib_model.fit(X_val, y_val)\n",
    "\n",
    "        # ---------------------- test prediction ----------------------\n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "        auroc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "        auprc = metrics.average_precision_score(y_test, y_pred_prob)\n",
    "        aurocs.append(auroc)\n",
    "        auprcs.append(auprc)\n",
    "\n",
    "        print(f\"[Fold {fold_idx}] AUROC: {auroc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "\n",
    "        # save results\n",
    "        fold_csv = os.path.join(save_path, f\"fold_{fold_idx}_results.csv\")\n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred_prob\n",
    "        }))\n",
    "        fold_idx += 1\n",
    "\n",
    "    # merge all folds results\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    all_csv = os.path.join(save_path, \"all_folds_results.csv\")\n",
    "    all_results_df.to_csv(all_csv, index=False)\n",
    "\n",
    "    # calculate mean and 95% CI\n",
    "    def mean_ci_interval(data):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data, ddof=1)\n",
    "        ci95 = 1.96 * std / np.sqrt(len(data))\n",
    "        return round(mean, 4), round(mean - ci95, 4), round(mean + ci95, 4)\n",
    "\n",
    "    auroc_mean, auroc_lower, auroc_upper = mean_ci_interval(aurocs)\n",
    "    auprc_mean, auprc_lower, auprc_upper = mean_ci_interval(auprcs)\n",
    "\n",
    "    print(\"\\n===== random forest 5-fold CV results (calibrated) =====\")\n",
    "    print(f\"AUROC: Mean={auroc_mean:.4f}, 95% CI=({auroc_lower:.4f},{auroc_upper:.4f})\")\n",
    "    print(f\"AUPRC: Mean={auprc_mean:.4f}, 95% CI=({auprc_lower:.4f},{auprc_upper:.4f})\")\n",
    "\n",
    "    results_summary = {\n",
    "        \"AUROC_mean\": auroc_mean,\n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper),\n",
    "        \"AUPRC_mean\": auprc_mean,\n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper)\n",
    "    }\n",
    "\n",
    "    return results_summary, all_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other']  \n",
    "results = train_randomforest_5fold_cv_calibrated(dataX, dataY)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98684bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c67df31b",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import KFold, train_test_split \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import os \n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# ===================== Bootstrap calculation function ===================== \n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42): \n",
    "    rng = np.random.RandomState(seed) \n",
    "    scores = [] \n",
    "    y_true = np.array(y_true) \n",
    "    y_pred = np.array(y_pred) \n",
    "    for _ in range(n_bootstrap): \n",
    "        idx = rng.randint(0, len(y_true), len(y_true)) \n",
    "        if len(np.unique(y_true[idx])) < 2: \n",
    "            continue \n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx])) \n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5) \n",
    " \n",
    " \n",
    "# ===================== Five-fold Logistic Regression ===================== \n",
    "def train_lr_5fold_cv( \n",
    "    dataX, \n",
    "    dataY, \n",
    "    num_features, \n",
    "    cat_features, \n",
    "    save_path='./Poisoning_Prediction/ML/predict_death/lr_valid_test_5cv/',\n",
    "    seed=42\n",
    "): \n",
    "    os.makedirs(save_path, exist_ok=True) \n",
    "    X = dataX.copy() \n",
    "    y = np.array(dataY) \n",
    " \n",
    "    # ===================== Feature preprocessing ===================== \n",
    "    # Fill missing values in continuous variables with the median \n",
    "    imputer = SimpleImputer(strategy='median') \n",
    "    X_num = pd.DataFrame(imputer.fit_transform(X[num_features]), columns=num_features, index=X.index) \n",
    "\n",
    "    # ✅ Normalize continuous variables (standardization)\n",
    "    scaler = StandardScaler()\n",
    "    X_num_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=num_features, index=X.index)\n",
    " \n",
    "    \n",
    "    # For categorical variables: fill missing values with 'missing'\n",
    "    X_cat = X[cat_features].astype(str).fillna('missing')\n",
    "\n",
    "    # OneHot encoding (drop the first category to avoid collinearity)\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)\n",
    "    X_cat_encoded = pd.DataFrame(\n",
    "        encoder.fit_transform(X_cat),\n",
    "        columns=encoder.get_feature_names_out(cat_features),\n",
    "        index=X.index\n",
    "    )\n",
    "\n",
    "    # Combine the encoded features\n",
    "    X_processed = pd.concat([X_num_scaled, X_cat_encoded], axis=1)\n",
    "\n",
    "    print(f\"Final feature dimension: {X_processed.shape[1]}\") \n",
    " \n",
    "    # ===================== Five-fold cross-validation ===================== \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed) \n",
    "    all_results = [] \n",
    "    fold_idx = 1 \n",
    " \n",
    "    for train_val_index, test_index in kf.split(X_processed): \n",
    "        X_train_val, X_test = X_processed.iloc[train_val_index], X_processed.iloc[test_index] \n",
    "        y_train_val, y_test = y[train_val_index], y[test_index] \n",
    " \n",
    "        # Split validation set (1/8) \n",
    "        X_train, X_val, y_train, y_val = train_test_split( \n",
    "            X_train_val, y_train_val, \n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val \n",
    "        ) \n",
    " \n",
    "        print(f\"Fold {fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\") \n",
    " \n",
    "        # Check class balance \n",
    "        n_pos = np.sum(y_train == 1)\n",
    "        n_neg = np.sum(y_train == 0)\n",
    "        print(f\"  Train - Pos: {n_pos}, Neg: {n_neg}\") \n",
    "        print(f\"  Test  - Pos: {np.sum(y_test==1)}, Neg: {np.sum(y_test==0)}\") \n",
    " \n",
    "        # ===================== Manually set class_weight ===================== \n",
    "        w_pos = n_neg / max(n_pos, 1)\n",
    "        class_weight = {0: 1.0, 1: w_pos}\n",
    "        print(f\"  Using class_weight = {class_weight}\") \n",
    " \n",
    "        # Model definition (with weights)\n",
    "        model = LogisticRegression(\n",
    "            max_iter=1000, \n",
    "            solver='lbfgs',\n",
    "            class_weight=class_weight\n",
    "        ) \n",
    "        # model = LogisticRegression(\n",
    "        #     max_iter=200, \n",
    "        #     solver='lbfgs',\n",
    "        #     class_weight=class_weight\n",
    "        # ) \n",
    " \n",
    "        # Train \n",
    "        model.fit(X_train, y_train) \n",
    " \n",
    "        # Predict \n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1] \n",
    " \n",
    "        # Save results for the current fold \n",
    "        fold_csv = os.path.join(save_path, f\"fold_{fold_idx}_results.csv\") \n",
    "        pd.DataFrame({ \n",
    "            \"fold\": fold_idx, \n",
    "            \"y_test\": y_test, \n",
    "            \"y_pred\": y_pred_prob \n",
    "        }).to_csv(fold_csv, index=False) \n",
    " \n",
    "        all_results.append(pd.DataFrame({ \n",
    "            \"fold\": fold_idx, \n",
    "            \"y_test\": y_test, \n",
    "            \"y_pred\": y_pred_prob \n",
    "        })) \n",
    " \n",
    "        fold_idx += 1 \n",
    " \n",
    "    # ===================== Combine results from all folds ===================== \n",
    "    all_results_df = pd.concat(all_results, ignore_index=True) \n",
    "    all_csv = os.path.join(save_path, \"all_folds_results.csv\") \n",
    "    all_results_df.to_csv(all_csv, index=False) \n",
    " \n",
    "    # ===================== Bootstrap calculation for AUROC/AUPRC ===================== \n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci( \n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score \n",
    "    ) \n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci( \n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score \n",
    "    ) \n",
    " \n",
    "    print(f\"\\n===== Logistic Regression Results =====\") \n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f}, {auroc_upper:.4f})\") \n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f}, {auprc_upper:.4f})\") \n",
    " \n",
    "    return { \n",
    "        \"AUROC_mean\": mean_auroc, \n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper), \n",
    "        \"AUPRC_mean\": mean_auprc, \n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper), \n",
    "        \"AllResults\": all_results_df \n",
    "    } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb35856",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other'] \n",
    "results = train_lr_5fold_cv(dataX, dataY,num_features=features_continuous, cat_features=features_categorical)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c5185",
   "metadata": {},
   "source": [
    "- Calibrate models for probabilistic calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4028642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import KFold, train_test_split \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import os \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def train_lr_5fold_cv_calibrated(\n",
    "    dataX, \n",
    "    dataY, \n",
    "    num_features, \n",
    "    cat_features, \n",
    "    save_path='./Poisoning_Prediction/ML/predict_death_calibration/lr/',\n",
    "    seed=42\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True) \n",
    "    X = dataX.copy() \n",
    "    y = np.array(dataY) \n",
    "\n",
    "    # Fill missing values for numerical variables + standardization\n",
    "    imputer = SimpleImputer(strategy='median') \n",
    "    X_num = pd.DataFrame(imputer.fit_transform(X[num_features]), columns=num_features, index=X.index) \n",
    "    scaler = StandardScaler()\n",
    "    X_num_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=num_features, index=X.index)\n",
    "\n",
    "    # Fill missing values for categorical variables + OneHot encoding\n",
    "    X_cat = X[cat_features].astype(str).fillna('missing')\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)\n",
    "    X_cat_encoded = pd.DataFrame(\n",
    "        encoder.fit_transform(X_cat),\n",
    "        columns=encoder.get_feature_names_out(cat_features),\n",
    "        index=X.index\n",
    "    )\n",
    "\n",
    "    # Combine processed numerical and categorical features\n",
    "    X_processed = pd.concat([X_num_scaled, X_cat_encoded], axis=1)\n",
    "    print(f\"Final feature dimension: {X_processed.shape[1]}\") \n",
    "\n",
    "    # 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed) \n",
    "    all_results = [] \n",
    "    fold_idx = 1 \n",
    "\n",
    "    for train_val_index, test_index in kf.split(X_processed): \n",
    "        X_train_val, X_test = X_processed.iloc[train_val_index], X_processed.iloc[test_index] \n",
    "        y_train_val, y_test = y[train_val_index], y[test_index] \n",
    "\n",
    "        # Split validation set\n",
    "        X_train, X_val, y_train, y_val = train_test_split( \n",
    "            X_train_val, y_train_val, \n",
    "            test_size=1/8, random_state=seed, stratify=y_train_val \n",
    "        ) \n",
    "\n",
    "        print(f\"Fold {fold_idx}: Train={len(y_train)}, Val={len(y_val)}, Test={len(y_test)}\") \n",
    "\n",
    "        # Class weights\n",
    "        n_pos = np.sum(y_train == 1)\n",
    "        n_neg = np.sum(y_train == 0)\n",
    "        class_weight = {0: 1.0, 1: n_neg / max(n_pos, 1)}\n",
    "        print(f\"  Using class_weight = {class_weight}\") \n",
    "\n",
    "        # Train base model\n",
    "        base_model = LogisticRegression(max_iter=1000, solver='lbfgs', class_weight=class_weight)\n",
    "        base_model.fit(X_train, y_train)\n",
    "\n",
    "        # Calibration on validation set\n",
    "        calib_model = CalibratedClassifierCV(base_model, method='sigmoid', cv='prefit')\n",
    "        calib_model.fit(X_val, y_val)\n",
    "\n",
    "        # Predictions on test set\n",
    "        y_pred_prob = calib_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Save fold results\n",
    "        fold_csv = os.path.join(save_path, f\"fold_{fold_idx}_results.csv\") \n",
    "        pd.DataFrame({\n",
    "            \"fold\": fold_idx, \n",
    "            \"y_test\": y_test, \n",
    "            \"y_pred\": y_pred_prob \n",
    "        }).to_csv(fold_csv, index=False)\n",
    "\n",
    "        all_results.append(pd.DataFrame({\n",
    "            \"fold\": fold_idx, \n",
    "            \"y_test\": y_test, \n",
    "            \"y_pred\": y_pred_prob \n",
    "        })) \n",
    "        fold_idx += 1 \n",
    "\n",
    "    # Combine results from all folds\n",
    "    all_results_df = pd.concat(all_results, ignore_index=True) \n",
    "    all_csv = os.path.join(save_path, \"all_folds_results.csv\") \n",
    "    all_results_df.to_csv(all_csv, index=False) \n",
    "\n",
    "    # Bootstrap to calculate AUROC/AUPRC\n",
    "    mean_auroc, auroc_lower, auroc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.roc_auc_score \n",
    "    ) \n",
    "    mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(\n",
    "        all_results_df[\"y_test\"], all_results_df[\"y_pred\"], metrics.average_precision_score \n",
    "    ) \n",
    "\n",
    "    print(f\"\\n===== Logistic Regression Calibration Results =====\") \n",
    "    print(f\"AUROC: Mean={mean_auroc:.4f}, 95% CI=({auroc_lower:.4f}, {auroc_upper:.4f})\") \n",
    "    print(f\"AUPRC: Mean={mean_auprc:.4f}, 95% CI=({auprc_lower:.4f}, {auprc_upper:.4f})\") \n",
    "\n",
    "    return {\n",
    "        \"AUROC_mean\": mean_auroc, \n",
    "        \"AUROC_CI\": (auroc_lower, auroc_upper), \n",
    "        \"AUPRC_mean\": mean_auprc, \n",
    "        \"AUPRC_CI\": (auprc_lower, auprc_upper), \n",
    "        \"AllResults\": all_results_df \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df_mapped_wide[features_categorical + features_continuous]\n",
    "dataY = df_mapped_wide['Outcome_other']\n",
    "results = train_lr_5fold_cv_calibrated(dataX, dataY,num_features=features_continuous, cat_features=features_categorical)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90347d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
