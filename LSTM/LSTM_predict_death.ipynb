{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b3894a",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fea6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Time series data: multiple examinations of a patient (examination time)\n",
    "df_series = pd.read_csv('./Poisoning_Prediction/LSTM/all_poisoning_data_sequence.csv')\n",
    "df_series = df_series.rename(columns={'住院号': 'Hospital ID','居住地（1农村 2城市）':'Residence'})\n",
    "\n",
    "## Wide table data: one row per patient (final wash data)\n",
    "df_wide = pd.read_excel('./Poisoning_Prediction/rawdata_中毒数据_patient_last_1114.xlsx')\n",
    "df_wide = df_wide.rename(columns={'居住地（1农村 2城市）':'Residence'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731006e9",
   "metadata": {},
   "source": [
    "- Distinguish between continuous and categorical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ccd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical = ['Gender',\n",
    " 'Education Level',\n",
    " 'Type of Poisoning',\n",
    " 'Hypertension',\n",
    " 'Hyperlipidemia',\n",
    " 'Diabetes Mellitus',\n",
    " 'Cerebrovascular Disease',\n",
    " 'Heart Disease',\n",
    " 'Allergy History',\n",
    " 'Cancer',\n",
    " 'Poisoning',\n",
    " 'degree of poisoning',\n",
    " 'Smoking Status',\n",
    " 'Alcohol Consumption Status',\n",
    " 'Shortness of Breath',\n",
    " 'Chest Pain',\n",
    " 'Cough',\n",
    " 'Pre-syncope',\n",
    " 'Altered Consciousness or Syncope',\n",
    " 'Sore Throat',\n",
    " 'Fever',\n",
    " 'Fatigue',\n",
    " 'Lower Limb Edema',\n",
    " 'Palpitations',\n",
    " 'Vomiting',\n",
    " 'Nausea',\n",
    " 'Weakness',\n",
    " 'Headache',\n",
    " 'Residence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dad0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_mappings_en = {\n",
    "    \"Gender\": {\n",
    "        1: \"Male\",\n",
    "        0: \"Female\"\n",
    "    },\n",
    "    \"Education Level\": {\n",
    "        1: \"Illiterate\",\n",
    "        2: \"Primary School\",\n",
    "        3: \"Junior High School\",\n",
    "        4: \"Senior High School\",\n",
    "        5: \"University Degree\"\n",
    "    },\n",
    "    \"Type of Poisoning\": {\n",
    "        1: \"Industrial\",\n",
    "        2: \"Pharmaceutical\",\n",
    "        3: \"Pesticide\",\n",
    "        4: \"Alcohol\",\n",
    "        0: \"Uncertain\"\n",
    "    },\n",
    "    \"Hypertension\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Hyperlipidemia\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Diabetes Mellitus\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Cerebrovascular Disease\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Heart Disease\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Allergy History\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Cancer\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Poisoning\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"degree of poisoning\": {\n",
    "        0: \"Undetermined\",\n",
    "        1: \"Low\",\n",
    "        2: \"Moderate\",\n",
    "        3: \"High\"\n",
    "    },\n",
    "    \"Smoking\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Alcohol Consumption Status\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Shortness of Breath\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Chest Pain\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Cough\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Pre-syncope\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Altered Mental Status or Syncope(AMS or Sync)\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Sore Throat\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Fever\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Fatigue\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Lower Limb Edema\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Palpitations\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Vomiting\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Nausea\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Weakness\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Headache\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    \"Residence\": {\n",
    "        1: \"Rural\",\n",
    "        2: \"Urban\"\n",
    "    },\n",
    "    \"Smoking Status\": {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },\n",
    "    'Altered Consciousness or Syncope': {\n",
    "        1: \"Yes\",\n",
    "        0: \"No\"\n",
    "    },    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Circular mapping (numerical value → English label)\n",
    "df_mapped_wide = df_wide.copy()\n",
    "for col in features_categorical:\n",
    "    if col in value_mappings_en and col in df_mapped_wide.columns:\n",
    "        df_mapped_wide[col] = df_mapped_wide[col].map(value_mappings_en[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep useful fields for wide tables\n",
    "useful_cols_from_wide_df = [\n",
    "    'Hospital ID',\n",
    "    'Age',\n",
    "    'Length of Stay',\n",
    "    'Weight',\n",
    "] + features_categorical  ## Add all the classification features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba3299d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_remain = df_mapped_wide[useful_cols_from_wide_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f86473d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Length of Stay</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Type of Poisoning</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Hyperlipidemia</th>\n",
       "      <th>Diabetes Mellitus</th>\n",
       "      <th>...</th>\n",
       "      <th>Sore Throat</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Lower Limb Edema</th>\n",
       "      <th>Palpitations</th>\n",
       "      <th>Vomiting</th>\n",
       "      <th>Nausea</th>\n",
       "      <th>Weakness</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5305990</td>\n",
       "      <td>48</td>\n",
       "      <td>6.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Junior High School</td>\n",
       "      <td>Pesticide</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5483805</td>\n",
       "      <td>69</td>\n",
       "      <td>6.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Illiterate</td>\n",
       "      <td>Pesticide</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5386113</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Junior High School</td>\n",
       "      <td>Pesticide</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5069871</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Junior High School</td>\n",
       "      <td>Pesticide</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5173751</td>\n",
       "      <td>65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Junior High School</td>\n",
       "      <td>Pesticide</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hospital ID  Age  Length of Stay  Weight  Gender     Education Level  \\\n",
       "0      5305990   48             6.0    65.0    Male  Junior High School   \n",
       "1      5483805   69             6.0    65.0  Female          Illiterate   \n",
       "2      5386113   21             3.0    90.0    Male  Junior High School   \n",
       "3      5069871   25             3.0    60.0  Female  Junior High School   \n",
       "4      5173751   65             3.0    65.0    Male  Junior High School   \n",
       "\n",
       "  Type of Poisoning Hypertension Hyperlipidemia Diabetes Mellitus  ...  \\\n",
       "0         Pesticide           No             No                No  ...   \n",
       "1         Pesticide          Yes             No                No  ...   \n",
       "2         Pesticide           No             No                No  ...   \n",
       "3         Pesticide           No             No                No  ...   \n",
       "4         Pesticide           No             No                No  ...   \n",
       "\n",
       "  Sore Throat Fever Fatigue Lower Limb Edema Palpitations Vomiting Nausea  \\\n",
       "0          No    No      No               No           No      Yes    Yes   \n",
       "1          No    No      No               No           No      Yes    Yes   \n",
       "2          No    No      No               No           No      Yes    Yes   \n",
       "3          No    No      No               No           No       No     No   \n",
       "4          No    No      No               No           No       No    Yes   \n",
       "\n",
       "  Weakness Headache Residence  \n",
       "0       No       No     Rural  \n",
       "1       No       No     Rural  \n",
       "2       No       No     Rural  \n",
       "3       No       No     Rural  \n",
       "4      Yes      Yes       NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide_remain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Useful fields for preserving time series data\n",
    "useful_cols_from_series_df = [\n",
    "    'Hospital ID',\n",
    "    '检验时间',\n",
    "\n",
    "    ## Vital signs\n",
    "    '收缩压',\n",
    "    '舒张压',\n",
    "    '心率',\n",
    "    '呼吸频率',\n",
    "    \n",
    "    ## Lab tests\n",
    "    '血胆碱酯酶检测结果',\n",
    "    '白细胞计数',\n",
    "    '红细胞计数',\n",
    "    '血红蛋白浓度',\n",
    "    '平均红细胞体积',\n",
    "    '平均红细胞血红蛋白含量',\n",
    "    '平均红细胞血红蛋白浓度',\n",
    "    '血小板计数',\n",
    "    '平均血小板体积',\n",
    "    '白蛋白',\n",
    "    '谷丙转氨酶',\n",
    "    '谷草转氨酶',\n",
    "    '总胆红素',\n",
    "    '直接胆红素',\n",
    "    '乳酸脱氢酶',\n",
    "    '尿素',\n",
    "    '血肌酐',\n",
    "    '尿酸',\n",
    "    '肌酸激酶',\n",
    "    '肌酸激酶-MB 同工酶',\n",
    "    '肌钙蛋白Ⅰ',\n",
    "    '血沉',\n",
    "    '超敏C反应蛋白',\n",
    "    '同型半胱氨酸',\n",
    "\n",
    "    '降钙素原',\n",
    "    '氨基末端脑利钠肽前体测定',\n",
    "    '钾',\n",
    "    '钠',\n",
    "    '氯',\n",
    "    '二氧化碳',\n",
    "    '凝血酶原时间',\n",
    "    'D二聚体',\n",
    "    '乳酸',\n",
    "    # '血红蛋白',  ## 数据格式不对（129,30.5,328），填写错误\n",
    "    '红细胞压积',\n",
    "    \n",
    "    ## Interventions\n",
    "    '血液灌流（次数）',\n",
    "    '血液净化（次数）',\n",
    "    '阿托品使用剂量',\n",
    "    '长托宁使用剂量',\n",
    "    '碘解磷定使用剂量、频次',\n",
    "    '高压氧治疗时间、频次',\n",
    "\n",
    "    'Outcome_other',\n",
    "    'Outcome',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d358d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_mapping = {\n",
    "    # Vital signs\n",
    "    '收缩压': 'Systolic Blood Pressure',\n",
    "    '舒张压': 'Diastolic Blood Pressure',\n",
    "    '心率': 'Heart Rate',\n",
    "    '呼吸频率': 'Respiratory Rate',\n",
    "\n",
    "    # Lab tests\n",
    "    '血胆碱酯酶检测结果': 'Blood Cholinesterase Test Results',\n",
    "    '白细胞计数': 'White Blood Cell Count',\n",
    "    '红细胞计数': 'Red Blood Cell Count',\n",
    "    '血红蛋白浓度': 'Hemoglobin Concentration',\n",
    "    '平均红细胞体积': 'Mean Corpuscular Volume',\n",
    "    '平均红细胞血红蛋白含量': 'Mean Corpuscular Hemoglobin',\n",
    "    '平均红细胞血红蛋白浓度': 'Mean Corpuscular Hemoglobin Concentration',\n",
    "    '血小板计数': 'Platelet Count',\n",
    "    '平均血小板体积': 'Mean Platelet Volume',\n",
    "    '白蛋白': 'Albumin',  # Note: The actual data may be divided into First/Last, which is a common name here.\n",
    "    '谷丙转氨酶': 'Alanine Aminotransferase',\n",
    "    '谷草转氨酶': 'Aspartate Aminotransferase',\n",
    "    '总胆红素': 'Total Bilirubin',\n",
    "    '直接胆红素': 'Direct Bilirubin',\n",
    "    '乳酸脱氢酶': 'Lactate Dehydrogenase',\n",
    "    '尿素': 'Urea',\n",
    "    '血肌酐': 'Serum Creatinine',\n",
    "    '尿酸': 'Uric Acid',\n",
    "    '肌酸激酶': 'Creatine Kinase',\n",
    "    '肌酸激酶-MB 同工酶': 'Creatine Kinase-MB',\n",
    "    '肌钙蛋白Ⅰ': 'Troponin I',\n",
    "    '血沉': 'Erythrocyte Sedimentation Rate',\n",
    "    '超敏C反应蛋白': 'High-Sensitivity C-Reactive Protein',\n",
    "    '同型半胱氨酸': 'Homocysteine',\n",
    "    '降钙素原': 'Procalcitonin',\n",
    "    '氨基末端脑利钠肽前体测定': 'Amino-Terminal Pro-B-Type Natriuretic Peptide',\n",
    "    '钾': 'Potassium',\n",
    "    '钠': 'Sodium',\n",
    "    '氯': 'Chloride',\n",
    "    '二氧化碳': 'Carbon Dioxide',\n",
    "    '凝血酶原时间': 'Prothrombin Time',\n",
    "    'D二聚体': 'D-Dimer',\n",
    "    '乳酸': 'Lactate',\n",
    "    '红细胞压积': 'Hematocrit',\n",
    "\n",
    "    # Interventions\n",
    "    '血液灌流（次数）': 'Number of Hemoperfusion Sessions',\n",
    "    '血液净化（次数）': 'Number of Blood Purification Sessions',\n",
    "    '阿托品使用剂量': 'Atropine Dosage',\n",
    "    '长托宁使用剂量': 'Long-acting Nitroglycerin Dosage',\n",
    "    '碘解磷定使用剂量、频次': 'Pralidoxime Dosage',\n",
    "    '高压氧治疗时间、频次': 'Hyperbaric Oxygen Therapy Duration and Frequency',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b238eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Useful fields for preserving time series data\n",
    "df_series_remain = df_series[useful_cols_from_series_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24700c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable renamed to English\n",
    "df_series_remain = df_series_remain.rename(columns=rename_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42896930",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_continuous = [\n",
    "    'Age',\n",
    "    'Length of Stay',\n",
    "    'Weight',\n",
    "] + list(rename_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Right link (left: wide table, right: timing table)\n",
    "df_merged = pd.merge(df_wide_remain, df_series_remain, on='Hospital ID', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check whether all continuous indicators are numbers, and set them to blank if they are not\n",
    "# Ensure that columns in features_continuous exist in df_merged\n",
    "continuous_cols = [col for col in features_continuous if col in df_merged.columns]\n",
    "\n",
    "# Numerical cleaning of each column: non-numerical → NaN\n",
    "for col in continuous_cols:\n",
    "    df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate missing proportions for continuous variables\n",
    "# Ensure that only continuous variables present in df_merged are processed\n",
    "continuous_cols = [col for col in features_continuous if col in df_merged.columns]\n",
    "\n",
    "# Calculate Missing Proportion (by Column)\n",
    "missing_ratios = df_merged[continuous_cols].isnull().mean()\n",
    "\n",
    "# Convert to percentage and sort (high to low)\n",
    "missing_summary = (missing_ratios * 100).round(2).sort_values(ascending=False)\n",
    "\n",
    "print(\"Proportion of missing continuous variables ( %):\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names screened for deletion rates> 90%\n",
    "high_missing_features = missing_ratios[missing_ratios > 0.90].index.tolist()\n",
    "\n",
    "# Optional: Print these features\n",
    "print(\"Continuous variables with missing rate> 90%:\")\n",
    "for feat in high_missing_features:\n",
    "    print(f\"{feat}: {missing_ratios[feat]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous variables with deletion rate ≤ 90% were retained\n",
    "features_continuous_clean = [col for col in features_continuous if col not in high_missing_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged Remove variables from high_missing_features\n",
    "df_merged_clean = df_merged.drop(columns=high_missing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537801b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_clean[\"检验时间\"] = pd.to_datetime(df_merged_clean[\"检验时间\"], errors=\"coerce\")\n",
    "df_merged_clean = df_merged_clean.sort_values([\"Hospital ID\", \"检验时间\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd72bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前数据维度：(4267, 63)\n",
      "去重后数据维度：(3074, 63)\n"
     ]
    }
   ],
   "source": [
    "## De-weight according to admission number (only one for each patient)\n",
    "print(f\"Data dimension before demultiplexing：{df_merged_clean.shape}\")\n",
    "df_merged_clean = df_merged_clean.drop_duplicates(subset=[\"Hospital ID\", \"检验时间\"], keep=\"first\").reset_index(drop=True)\n",
    "print(f\"Data dimension after demultiplexing：{df_merged_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32df551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates based on the hospital ID (keep only one record per patient)\n",
    "df_unique = df_merged_clean.drop_duplicates(subset=['Hospital ID']).reset_index(drop=True)\n",
    "\n",
    "# Count the distribution of Outcome_other and Outcome\n",
    "print(\"\\nOutcome_other Distribution (Mortality):\")\n",
    "print(df_unique[\"Outcome_other\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nOutcome Distribution (Not Cured):\")\n",
    "print(df_unique[\"Outcome\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdeb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Added: Statistics by Poisoning Type Group Outcome_other Distribution ----------------------\n",
    "outcome_by_type = (\n",
    "    df_unique.groupby(\"Type of Poisoning\")[\"Outcome_other\"]\n",
    "    .value_counts()\n",
    "    .unstack(fill_value=0)\n",
    "    .rename(columns={0: \"非死亡\", 1: \"死亡\"})\n",
    ")\n",
    "\n",
    "# Increase Proportion Column (Percentage)\n",
    "outcome_by_type[\"死亡比例(%)\"] = (\n",
    "    outcome_by_type[\"死亡\"] / outcome_by_type.sum(axis=1) * 100\n",
    ").round(2)\n",
    "\n",
    "print(outcome_by_type)\n",
    "\n",
    "# If you also want to calculate the Outcome distribution, it can be similar to:\n",
    "outcome_by_type2 = (\n",
    "    df_unique.groupby(\"Type of Poisoning\")[\"Outcome\"]\n",
    "    .value_counts()\n",
    "    .unstack(fill_value=0)\n",
    "    .rename(columns={0: \"治愈/好转\", 1: \"死亡或未愈\"})\n",
    ")\n",
    "outcome_by_type2[\"不良结局比例(%)\"] = (\n",
    "    outcome_by_type2[\"死亡或未愈\"] / outcome_by_type2.sum(axis=1) * 100\n",
    ").round(2)\n",
    "\n",
    "print(outcome_by_type2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "785bc1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(971, 106)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapped_wide.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61fd978",
   "metadata": {},
   "source": [
    "- Save unfilled time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_clean.to_csv('./Poisoning_Prediction/LSTM/clean_data/poisoning_data_sequence_clean_without_filled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbc6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filling missing values in time series data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_merged_clean = pd.read_csv('/home/mailiyi/Poisoning_Prediction/LSTM/clean_data/poisoning_data_sequence_clean_without_filled.csv')\n",
    "\n",
    "## Fill missing values for continuous indicators: Sort data by Hospital ID and Test Time\n",
    "df_merged_clean = df_merged_clean.sort_values([\"Hospital ID\", \"检验时间\"]).reset_index(drop=True)\n",
    "\n",
    "# Create a copy for filling\n",
    "df_filled = df_merged_clean.copy()\n",
    "\n",
    "# Perform linear interpolation for continuous variables for each patient\n",
    "# common_continuous_cols: Fill with median\n",
    "common_continuous_cols = [\n",
    "    'Age',\n",
    "    'Length of Stay',\n",
    "    'Weight',\n",
    "    ]\n",
    "\n",
    "## series_continuous_cols: Fill using linear interpolation\n",
    "series_continuous_cols = [\n",
    "    'Systolic Blood Pressure',\n",
    "    'Diastolic Blood Pressure',\n",
    "    'Heart Rate',\n",
    "    'Respiratory Rate',\n",
    "    'White Blood Cell Count',\n",
    "    'Red Blood Cell Count',\n",
    "    'Hemoglobin Concentration',\n",
    "    'Mean Corpuscular Volume',\n",
    "    'Mean Corpuscular Hemoglobin',\n",
    "    'Mean Corpuscular Hemoglobin Concentration',\n",
    "    'Platelet Count',\n",
    "    'Mean Platelet Volume',\n",
    "    'Albumin',\n",
    "    'Alanine Aminotransferase',\n",
    "    'Aspartate Aminotransferase',\n",
    "    'Total Bilirubin',\n",
    "    'Direct Bilirubin',\n",
    "    'Lactate Dehydrogenase',\n",
    "    'Urea',\n",
    "    'Uric Acid',\n",
    "    'Creatine Kinase',\n",
    "    'Creatine Kinase-MB',\n",
    "    'Troponin I',\n",
    "    'High-Sensitivity C-Reactive Protein',\n",
    "    'Homocysteine',\n",
    "    'Number of Hemoperfusion Sessions',\n",
    "    'Number of Blood Purification Sessions',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e51414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Global median fill (static variable)\n",
    "for col in common_continuous_cols:\n",
    "    if col in df_filled.columns:\n",
    "        median_val = df_filled[col].median()\n",
    "        df_filled[col] = df_filled[col].fillna(median_val)\n",
    "\n",
    "# 2. Sequential variable: forward fill by patient (Hospital ID)\n",
    "for col in series_continuous_cols:\n",
    "    if col in df_filled.columns:\n",
    "        df_filled[col] = df_filled.groupby('Hospital ID')[col].ffill()\n",
    "\n",
    "# 3. Sequential variables: bfill by patient--supplement this step\n",
    "for col in series_continuous_cols:\n",
    "    if col in df_filled.columns:\n",
    "        df_filled[col] = df_filled.groupby('Hospital ID')[col].bfill()\n",
    "\n",
    "# 4. Final Bottom: Fill in missing values with global median\n",
    "for col in series_continuous_cols:\n",
    "    if col in df_filled.columns:\n",
    "        if df_filled[col].isna().any():\n",
    "            global_median = df_filled[col].median()\n",
    "            print(f\"{df_filled[col].isna().sum()} : {global_median:.2f}\")\n",
    "            df_filled[col] = df_filled[col].fillna(global_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ca7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in common_continuous_cols if col in df_merged_clean.columns]\n",
    "\n",
    "# 1. Number of missing\n",
    "missing_counts = df_merged_clean[cols].isnull().sum()\n",
    "print(\"Missing value statistics:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# 2. Find missing rows\n",
    "mask = df_merged_clean[cols].isnull().any(axis=1)\n",
    "df_missing = df_merged_clean[mask]\n",
    "\n",
    "print(f\"\\n {df_missing.shape[0]} row missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ddb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of missing values for each column\n",
    "missing_counts = df_filled.isnull().sum()\n",
    "\n",
    "# Filter columns with missing values > 0\n",
    "missing_cols = missing_counts[missing_counts > 0]\n",
    "\n",
    "# Output the result\n",
    "if missing_cols.empty:\n",
    "    print(\"✅ No missing values in df_filled.\")\n",
    "else:\n",
    "    print(\"⚠️ The following columns still contain missing values:\")\n",
    "    for col, count in missing_cols.items():\n",
    "        print(f\"  {col}: {count} missing values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification index one-hot coding\n",
    "\n",
    "features_categorical = [\n",
    "    'Gender',\n",
    "    'Education Level',\n",
    "    'Type of Poisoning',\n",
    "    'Hypertension',\n",
    "    'Hyperlipidemia',\n",
    "    'Diabetes Mellitus',\n",
    "    'Cerebrovascular Disease',\n",
    "    'Heart Disease',\n",
    "    'Allergy History',\n",
    "    'Cancer',\n",
    "    'Poisoning',\n",
    "    'degree of poisoning',\n",
    "    'Smoking Status',\n",
    "    'Alcohol Consumption Status',\n",
    "    'Shortness of Breath',\n",
    "    'Chest Pain',\n",
    "    'Cough',\n",
    "    'Pre-syncope',\n",
    "    'Altered Consciousness or Syncope',\n",
    "    'Sore Throat',\n",
    "    'Fever',\n",
    "    'Fatigue',\n",
    "    'Lower Limb Edema',\n",
    "    'Palpitations',\n",
    "    'Vomiting',\n",
    "    'Nausea',\n",
    "    'Weakness',\n",
    "    'Headache',\n",
    "    'Residence',\n",
    "]\n",
    "\n",
    "## Categorical variables are populated first (missing values are populated as Unknown)\n",
    "for col in features_categorical:\n",
    "    if col in df_filled.columns:\n",
    "        df_filled[col] = df_filled[col].fillna('Unknown')\n",
    "\n",
    "# df_final_filled = pd.get_dummies(df_filled, columns=features_categorical, drop_first=True) ## Delete the first category column\n",
    "\n",
    "df_final_filled = pd.get_dummies(df_filled, columns=features_categorical, drop_first=False)  ## Keep all category columns\n",
    "# df_final_filled = df_final_filled.astype(float)\n",
    "df_final_filled[df_final_filled.select_dtypes(include=['bool', 'int', 'float']).columns] = \\\n",
    "    df_final_filled.select_dtypes(include=['bool', 'int', 'float']).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_cols = ['Outcome_other','Outcome',]\n",
    "df_final_filled = df_final_filled[[col for col in df_final_filled.columns if col not in outcome_cols] + outcome_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992dac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_filled.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b97387",
   "metadata": {},
   "source": [
    "Save Missing Value Fill +one-hot encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ced48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_filled.to_csv('./Poisoning_Prediction/LSTM/clean_data/poisoning_data_sequence_filled_onehot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c422c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14e6095d",
   "metadata": {},
   "source": [
    "## Step 2: Precondition for LSTM (Sequence Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddcf6bf",
   "metadata": {},
   "source": [
    "Each patient is a time series, sorted by \"test time\"; each time point is a set of numerical feature vectors; corresponds to a final label (e.g.\"hospital death\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "df_series_filled = pd.read_csv('./Poisoning_Prediction/LSTM/clean_data/poisoning_data_sequence_filled_onehot.csv')\n",
    "\n",
    "# De-weight according to admission number (only one for each patient)\n",
    "df_unique = df_series_filled.drop_duplicates(subset=['Hospital ID']).reset_index(drop=True)\n",
    "\n",
    "# Statistics Distribution of Outcome_other and Outcome\n",
    "print(\"\\nStatistics Distribution of Outcome_other（是否死亡）：\")\n",
    "print(df_unique[\"Outcome_other\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nStatistics Distribution of Outcome（是否未治愈）：\")\n",
    "print(df_unique[\"Outcome\"].value_counts(dropna=False))\n",
    "\n",
    "df_series_filled['检验时间'] = pd.to_datetime(df_series_filled['检验时间'], errors='coerce')\n",
    "\n",
    "## Define static feature columns\n",
    "static_cols = [\n",
    "    'Age',\n",
    "    'Length of Stay',\n",
    "    'Weight',\n",
    "    ] + [\n",
    "    'Gender_Female',\n",
    "    'Gender_Male',\n",
    "    'Education Level_Illiterate',\n",
    "    'Education Level_Junior High School',\n",
    "    'Education Level_Primary School',\n",
    "    'Education Level_Senior High School',\n",
    "    'Education Level_University Degree',\n",
    "    'Education Level_Unknown',\n",
    "    'Type of Poisoning_Alcohol',\n",
    "    'Type of Poisoning_Industrial',\n",
    "    'Type of Poisoning_Pesticide',\n",
    "    'Type of Poisoning_Pharmaceutical',\n",
    "    'Hypertension_No',\n",
    "    'Hypertension_Unknown',\n",
    "    'Hypertension_Yes',\n",
    "    'Hyperlipidemia_No',\n",
    "    'Hyperlipidemia_Unknown',\n",
    "    'Hyperlipidemia_Yes',\n",
    "    'Diabetes Mellitus_No',\n",
    "    'Diabetes Mellitus_Unknown',\n",
    "    'Diabetes Mellitus_Yes',\n",
    "    'Cerebrovascular Disease_No',\n",
    "    'Cerebrovascular Disease_Unknown',\n",
    "    'Cerebrovascular Disease_Yes',\n",
    "    'Heart Disease_No',\n",
    "    'Heart Disease_Unknown',\n",
    "    'Heart Disease_Yes',\n",
    "    'Allergy History_No',\n",
    "    'Allergy History_Unknown',\n",
    "    'Allergy History_Yes',\n",
    "    'Cancer_No',\n",
    "    'Cancer_Unknown',\n",
    "    'Cancer_Yes',\n",
    "    'Poisoning_No',\n",
    "    'Poisoning_Unknown',\n",
    "    'Poisoning_Yes',\n",
    "    'degree of poisoning_High',\n",
    "    'degree of poisoning_Low',\n",
    "    'degree of poisoning_Moderate',\n",
    "    'degree of poisoning_Undetermined',\n",
    "    'Smoking Status_No',\n",
    "    'Smoking Status_Yes',\n",
    "    'Alcohol Consumption Status_No',\n",
    "    'Alcohol Consumption Status_Yes',\n",
    "    'Shortness of Breath_No',\n",
    "    'Shortness of Breath_Yes',\n",
    "    'Chest Pain_No',\n",
    "    'Chest Pain_Yes',\n",
    "    'Cough_No',\n",
    "    'Cough_Yes',\n",
    "    'Pre-syncope_No',\n",
    "    'Pre-syncope_Yes',\n",
    "    'Altered Consciousness or Syncope_No',\n",
    "    'Altered Consciousness or Syncope_Yes',\n",
    "    'Sore Throat_No',\n",
    "    'Sore Throat_Yes',\n",
    "    'Fever_No',\n",
    "    'Fever_Yes',\n",
    "    'Fatigue_No',\n",
    "    'Fatigue_Yes',\n",
    "    'Lower Limb Edema_No',\n",
    "    'Lower Limb Edema_Yes',\n",
    "    'Palpitations_No',\n",
    "    'Palpitations_Yes',\n",
    "    'Vomiting_No',\n",
    "    'Vomiting_Yes',\n",
    "    'Nausea_No',\n",
    "    'Nausea_Yes',\n",
    "    'Weakness_No',\n",
    "    'Weakness_Yes',\n",
    "    'Headache_No',\n",
    "    'Headache_Yes',\n",
    "    'Residence_Rural',\n",
    "    'Residence_Unknown',\n",
    "    'Residence_Urban',\n",
    "    ]\n",
    "\n",
    "## Define dynamic feature columns\n",
    "dynamic_cols = [\n",
    "    'Systolic Blood Pressure',\n",
    "    'Diastolic Blood Pressure',\n",
    "    'Heart Rate',\n",
    "    'Respiratory Rate',\n",
    "    'White Blood Cell Count',\n",
    "    'Red Blood Cell Count',\n",
    "    'Hemoglobin Concentration',\n",
    "    'Mean Corpuscular Volume',\n",
    "    'Mean Corpuscular Hemoglobin',\n",
    "    'Mean Corpuscular Hemoglobin Concentration',\n",
    "    'Platelet Count',\n",
    "    'Mean Platelet Volume',\n",
    "    'Albumin',\n",
    "    'Alanine Aminotransferase',\n",
    "    'Aspartate Aminotransferase',\n",
    "    'Total Bilirubin',\n",
    "    'Direct Bilirubin',\n",
    "    'Lactate Dehydrogenase',\n",
    "    'Urea',\n",
    "    'Uric Acid',\n",
    "    'Creatine Kinase',\n",
    "    'Creatine Kinase-MB',\n",
    "    'Troponin I',\n",
    "    'High-Sensitivity C-Reactive Protein',\n",
    "    'Homocysteine',\n",
    "    'Number of Hemoperfusion Sessions',\n",
    "    'Number of Blood Purification Sessions',\n",
    "]\n",
    "\n",
    "## Standardize ['Age','Length of Stay','Weight',]\n",
    "scaler = StandardScaler()\n",
    "df_series_filled[['Age','Length of Stay','Weight',]] = scaler.fit_transform(df_series_filled[['Age','Length of Stay','Weight',]])\n",
    "\n",
    "## Classified variables have been one-hot coded before，omitted here\n",
    "## static feature coding\n",
    "static_df = df_series_filled.groupby(\"Hospital ID\")[static_cols].first().reset_index()\n",
    "\n",
    "# 9. build sequence\n",
    "# 1️⃣ First overall fit normalizer\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_series_filled[dynamic_cols])  # global standardization\n",
    "all_sequences, all_statics, all_labels = [], [], []\n",
    "\n",
    "# 2️⃣ patient-by-patient transformation\n",
    "for pid, group in df_series_filled.groupby(\"Hospital ID\"):\n",
    "    group_sorted = group.sort_values(\"检验时间\")\n",
    "    # X_dyn = group_sorted[dynamic_cols].values\n",
    "    X_dyn = scaler.transform(group_sorted[dynamic_cols])  \n",
    "    y = group_sorted[\"Outcome_other\"].iloc[-1]  \n",
    "    # X_dyn = scaler.fit_transform(X_dyn)  \n",
    "\n",
    "    static_values = static_df.loc[static_df[\"Hospital ID\"] == pid, static_cols].values\n",
    "    if len(static_values) == 0:\n",
    "        continue\n",
    "\n",
    "    all_sequences.append(torch.tensor(X_dyn, dtype=torch.float32))\n",
    "    all_statics.append(torch.tensor(static_values.squeeze(), dtype=torch.float32))\n",
    "    all_labels.append(y)\n",
    "\n",
    "# 10. Padding\n",
    "X_padded = pad_sequence(all_sequences, batch_first=True, padding_value=0.0)\n",
    "X_static = torch.stack(all_statics)\n",
    "y_tensor = torch.tensor(all_labels, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(f\"number of patients: {len(all_sequences)}\")\n",
    "print(f\"Dynamic Feature Input Shape: {X_padded.shape}\")  # (num_patients, seq_len, dyn_features)\n",
    "print(f\"static feature input shape: {X_static.shape}\")   # (num_patients, static_features)\n",
    "print(f\"tag shape: {y_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbac725",
   "metadata": {},
   "source": [
    "##### Five-fold cross-validation: Further divide 1/8 of the training set into a validation set (i.e., the training set accounts for 70%, the validation set for 10%, and the test set for 20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041aa9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# ===================== fixed random seed =====================\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)\n",
    "\n",
    "# ===================== save path =====================\n",
    "save_path = './Poisoning_Prediction/LSTM/predict_death_valid_test_5cv/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# ===================== model definition =====================\n",
    "class LSTMWithStatic(nn.Module):\n",
    "    def __init__(self, input_dim, static_dim, hidden_dim=64, num_layers=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + static_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x_seq, x_static):\n",
    "        _, (h_n, _) = self.lstm(x_seq)\n",
    "        h_last = h_n[-1]\n",
    "        combined = torch.cat([h_last, x_static], dim=1)\n",
    "        out = self.fc(combined)\n",
    "        return out\n",
    "\n",
    "# ===================== Bootstrap function =====================\n",
    "def bootstrap_metric_ci(y_true, y_pred, metric_fn, n_bootstrap=2000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    scores = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "\n",
    "# ===================== five-fold cross-validation =====================\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "all_results = []\n",
    "\n",
    "max_epochs = 100\n",
    "batch_size = 16\n",
    "lr = 5e-4\n",
    "weight_decay = 5e-4\n",
    "patience = 12\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(X_padded)):\n",
    "    print(f\"\\n===== Fold {fold+1}/{n_splits} =====\")\n",
    "    set_seed(42 + fold)\n",
    "\n",
    "    X_train_val_seq, X_test_seq = X_padded[train_val_idx], X_padded[test_idx]\n",
    "    X_train_val_static, X_test_static = X_static[train_val_idx], X_static[test_idx]\n",
    "    y_train_val, y_test = y_tensor[train_val_idx], y_tensor[test_idx]\n",
    "\n",
    "    X_train_seq, X_val_seq, X_train_static, X_val_static, y_train, y_val = train_test_split(\n",
    "        X_train_val_seq, X_train_val_static, y_train_val,\n",
    "        test_size=1/8, random_state=42, stratify=y_train_val\n",
    "    )\n",
    "\n",
    "    # pos_weight\n",
    "    num_pos = (y_train == 1).sum().item()\n",
    "    num_neg = (y_train == 0).sum().item()\n",
    "    pos_weight = torch.tensor(num_neg / max(num_pos,1), dtype=torch.float32).to(device)\n",
    "    print(f\"pos_weight = {pos_weight:.2f}  (neg={num_neg}, pos={num_pos})\")\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train_seq, X_train_static, y_train),\n",
    "                              batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = LSTMWithStatic(\n",
    "        input_dim=X_padded.shape[2],\n",
    "        static_dim=X_static.shape[1],\n",
    "        hidden_dim=64,  # hidden_dim\n",
    "        dropout=0.5     # add dropout\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_auroc = 0\n",
    "    wait = 0\n",
    "    best_model_path = os.path.join(save_path, f\"fold_{fold+1}_best_model.pt\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch_seq, batch_static, batch_y in train_loader:\n",
    "            batch_seq, batch_static, batch_y = batch_seq.to(device), batch_static.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_seq, batch_static)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(X_val_seq.to(device), X_val_static.to(device)).cpu().numpy().flatten()\n",
    "            y_pred = 1 / (1 + np.exp(-logits))\n",
    "            y_true = y_val.numpy().reshape(-1)\n",
    "            auroc_val = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03d} | Loss: {avg_loss:.4f} | Val AUROC: {auroc_val:.4f}\")\n",
    "\n",
    "        if auroc_val > best_auroc:\n",
    "            best_auroc = auroc_val\n",
    "            wait = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1} (best Val AUROC={best_auroc:.4f})\")\n",
    "                break\n",
    "\n",
    "    # test set evaluation\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_test_seq.to(device), X_test_static.to(device)).cpu().numpy().flatten()\n",
    "        y_pred = 1 / (1 + np.exp(-logits))\n",
    "        y_true = y_test.numpy().reshape(-1)\n",
    "        result_df = pd.DataFrame({\"y_test\": y_true, \"y_pred\": y_pred})\n",
    "        result_df.to_csv(save_path + f\"fold_{fold+1}_results.csv\", index=False)\n",
    "        all_results.append(result_df)\n",
    "\n",
    "# ===================== summary results =====================\n",
    "all_results_df = pd.concat(all_results, axis=0).reset_index(drop=True)\n",
    "y_all_true = all_results_df[\"y_test\"].values\n",
    "y_all_pred = all_results_df[\"y_pred\"].values\n",
    "\n",
    "mean_auroc, auc_lower, auc_upper = bootstrap_metric_ci(y_all_true, y_all_pred, roc_auc_score)\n",
    "mean_auprc, auprc_lower, auprc_upper = bootstrap_metric_ci(y_all_true, y_all_pred, average_precision_score)\n",
    "\n",
    "print(\"\\n===== 5-Fold Cross Validation Results (Bootstrap) =====\")\n",
    "print(f\"AUROC: Mean = {mean_auroc:.4f}, 95% CI = ({auc_lower:.4f}–{auc_upper:.4f})\")\n",
    "print(f\"AUPRC: Mean = {mean_auprc:.4f}, 95% CI = ({auprc_lower:.4f}–{auprc_upper:.4f})\")\n",
    "\n",
    "all_results_path = os.path.join(save_path, \"all_folds_results.csv\")\n",
    "all_results_df.to_csv(all_results_path, index=False)\n",
    "print(f\"\\n✅ 5-Fold Cross Validation Results as：{all_results_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
